import os
import types
from dataclasses import dataclass
from functools import wraps
from typing import Dict, Any

_LANG = os.getenv("HYDRAVOX_UI_LANG", "en").lower()
if _LANG not in ("zh", "en"):
    _LANG = "zh"

_TRANSLATIONS: Dict[str, Dict[str, str]] = {
    # main_ui.py
    "Multi-Head AR TTS (HTTP)": {"en": "Multi-Head AR TTS (HTTP)"},
    "### Multi-Head AR TTS Â· HTTP Only Â· Gradio Frontend": {
        "en": "### Multi-Head AR TTS Â· HTTP Only Â· Gradio Frontend"
    },
    "Text": {"en": "Text"},
    "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäº HTTP çš„ TTS æ¼”ç¤ºã€‚": {
        "en": "Hello, this is an HTTP-based TTS demo."
    },
    "Speaker": {"en": "Speaker"},
    "Audio": {"en": "Audio"},
    "Synthesize": {"en": "Synthesize"},
    "Backend: `{backend}`": {"en": "Backend: `{backend}`"},
    "HydraVox TTS System": {"en": "HydraVox TTS System"},
    "æ”¯æŒå¤šTokené¢„æµ‹çš„è¯­éŸ³åˆæˆç³»ç»Ÿ": {
        "en": "A TTS system with multi-token prediction support"
    },
    "ğŸ”— åç«¯æœåŠ¡: {backend}": {"en": "ğŸ”— Backend: {backend}"},
    "ğŸ’¡ HydraVox - è®©è¯­éŸ³åˆæˆæ›´ç®€å•": {
        "en": "ğŸ’¡ HydraVox - Make TTS simpler"
    },
    "CUDA ä¸å¯ç”¨ï¼Œé»˜è®¤ CPU x1": {"en": "CUDA unavailable, defaulting to CPU x1"},
    "CUDA å¯ç”¨ï¼ŒGPU æ•°: {count}": {"en": "CUDA available, GPU count: {count}"},
    "ğŸ¤ è¯­éŸ³åˆæˆ": {"en": "ğŸ¤ Speech synthesis"},
    "è¯­è¨€": {"en": "Language"},
    "è¯­è¨€å·²æ›´æ–°ã€‚": {"en": "Language updated."},
    # inference_tab.py
    "å¯ç”¨è¯´è¯äººï¼š{count} ä¸ª": {"en": "Available speakers: {count}"},
    "è¯·é€‰æ‹© LLM ä¸ Flow æƒé‡æ–‡ä»¶åå†åŠ è½½ã€‚": {
        "en": "Please select LLM and Flow weights before loading."
    },
    "â— è¯·å…ˆé€‰æ‹© LLM ä¸ Flow æƒé‡æ–‡ä»¶ã€‚": {
        "en": "â— Please select LLM and Flow weights first."
    },
    "æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ": {"en": "Model weights loaded successfully"},
    "âœ… åŠ è½½æˆåŠŸ\nLLM: {llm}\nFlow: {flow}\næ¶ˆæ¯: {msg}": {
        "en": "âœ… Loaded\nLLM: {llm}\nFlow: {flow}\nMessage: {msg}"
    },
    "åŠ è½½å¤±è´¥: {error}": {"en": "Load failed: {error}"},
    "âŒ åŠ è½½å¤±è´¥: {error}": {"en": "âŒ Load failed: {error}"},
    "TTS è¯­éŸ³åˆæˆ": {"en": "TTS Synthesis"},
    "å³æ—¶æ–‡æœ¬è½¬è¯­éŸ³ Â· æ”¯æŒå¤šè¯´è¯äºº": {
        "en": "Instant text-to-speech Â· Multi-speaker"
    },
    "LLM æƒé‡ (llm.pt)": {"en": "LLM weights (llm.pt)"},
    "Flow æƒé‡ (flow.pt)": {"en": "Flow weights (flow.pt)"},
    "ğŸ”„ åŠ è½½æ¨¡å‹": {"en": "ğŸ”„ Load model"},
    "è¾“å…¥æ–‡æœ¬": {"en": "Input text"},
    "è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬...": {"en": "Enter text to synthesize..."},
    "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå‡ºå»èµ°èµ°ã€‚": {
        "en": "The weather is great today. Perfect for a walk."
    },
    "æ¬¢è¿ä½¿ç”¨ HydraVox,å¤šå¤´é¢„æµ‹è®©è¯­éŸ³æ›´è‡ªç„¶ã€‚": {
        "en": "Welcome to HydraVox. Multi-head prediction makes speech more natural."
    },
    "è¯·åœ¨æç¤ºæ¡†ä¸­è¾“å…¥ä½ æƒ³è¦åˆæˆçš„æ–‡æœ¬å†…å®¹ã€‚": {
        "en": "Type the text you want to synthesize."
    },
    "ç¤ºä¾‹": {"en": "Examples"},
    "é¢„è®¾è¯´è¯äºº": {"en": "Preset speaker"},
    "Zero-shot": {"en": "Zero-shot"},
    "åˆæˆæ¨¡å¼": {"en": "Synthesis mode"},
    "*é€‰æ‹©ä½¿ç”¨é¢„è®¾è¯´è¯äººæˆ–Zero-shotè¯­éŸ³å…‹éš†*": {
        "en": "*Choose a preset speaker or zero-shot voice cloning*"
    },
    "é€‰æ‹©é¢„è®­ç»ƒçš„å‘éŸ³äºº": {"en": "Choose a pre-trained speaker"},
    "â†» åˆ·æ–°": {"en": "â†» Refresh"},
    "Zero-shot è¯­éŸ³å…‹éš†": {"en": "Zero-shot voice cloning"},
    "é€‰æ‹©æˆ–ä¸Šä¼ å‚è€ƒéŸ³é¢‘è¿›è¡Œè¯­éŸ³å…‹éš†": {
        "en": "Select or upload a reference audio for cloning"
    },
    "é¢„è®¾å‚è€ƒéŸ³é¢‘": {"en": "Preset reference audio"},
    "*é€‰æ‹©ä¸€ä¸ªé¢„è®¾çš„å‚è€ƒéŸ³é¢‘ï¼Œæˆ–è€…ä¸Šä¼ è‡ªå·±çš„éŸ³é¢‘æ–‡ä»¶*": {
        "en": "*Choose a preset reference or upload your own audio*"
    },
    "å‚è€ƒéŸ³é¢‘å¯¹åº”æ–‡æœ¬ (ASRå†…å®¹)": {
        "en": "Reference transcript (ASR content)"
    },
    "è¯·è¾“å…¥å‚è€ƒéŸ³é¢‘ä¸­è¯´è¯äººè¯´çš„å†…å®¹...": {
        "en": "Enter what the speaker says in the reference audio..."
    },
    "*è¯·å‡†ç¡®è¾“å…¥å‚è€ƒéŸ³é¢‘ä¸­çš„æ–‡å­—å†…å®¹ï¼Œè¿™å°†ç”¨äºè¯­éŸ³å…‹éš†*": {
        "en": "*Please enter the exact transcript; it is used for cloning*"
    },
    "å‚è€ƒéŸ³é¢‘": {"en": "Reference audio"},
    "*ä½ å¯ä»¥ä»ä¸Šæ–¹é€‰æ‹©é¢„è®¾éŸ³é¢‘ï¼Œæˆ–è€…ç›´æ¥ä¸Šä¼ è‡ªå·±çš„éŸ³é¢‘æ–‡ä»¶*": {
        "en": "*Choose a preset above or upload your own audio*"
    },
    "é«˜çº§è®¾ç½®": {"en": "Advanced settings"},
    "ğŸµ åˆæˆ": {"en": "ğŸµ Synthesize"},
    "ğŸ§¹ æ¸…ç©º": {"en": "ğŸ§¹ Clear"},
    "åˆæˆéŸ³é¢‘": {"en": "Synthesized audio"},
    "**åç«¯åœ°å€**: `{backend}`": {"en": "**Backend**: `{backend}`"},
    # data_tab.py
    "ğŸ“Š æ•°æ®å¤„ç†": {"en": "ğŸ“Š Data processing"},
    "# ğŸ› ï¸ éŸ³é¢‘æ•°æ®é¢„å¤„ç†å·¥ä½œæµ": {
        "en": "# ğŸ› ï¸ Audio data preprocessing workflow"
    },
    "**ä¸‰ä¸ªé˜¶æ®µçš„å¤„ç†æµç¨‹ï¼š** æ ¼å¼è½¬æ¢ â†’ VADåˆ†æ®µ â†’ ASRè½¬å½•": {
        "en": "**Three stages:** Format conversion â†’ VAD â†’ ASR transcription"
    },
    "**å¯é€‰é˜¶æ®µï¼š** æ•°æ®é›†åˆå¹¶": {"en": "**Optional stage:** Dataset merge"},
    "ğŸµ é˜¶æ®µ 1 - æ ¼å¼è½¬æ¢ä¸é‡é‡‡æ ·": {
        "en": "ğŸµ Stage 1 - Format conversion & resampling"
    },
    "**åŠŸèƒ½ï¼š** å°†å„ç§éŸ³é¢‘/è§†é¢‘æ ¼å¼ç»Ÿä¸€è½¬æ¢ä¸º 16kHz WAV æ ¼å¼": {
        "en": "**Function:** Convert audio/video formats to 16kHz WAV"
    },
    "ğŸ“ è¾“å…¥ç›®å½•": {"en": "ğŸ“ Input directory"},
    "/path/to/input_dir": {"en": "/path/to/input_dir"},
    "ğŸ”„ è‡ªåŠ¨åŒæ­¥è¾“å‡ºè·¯å¾„": {"en": "ğŸ”„ Auto-sync output path"},
    "æ·»åŠ _resampleåç¼€": {"en": "Add _resample suffix"},
    "ğŸ“‚ è¾“å‡ºç›®å½•": {"en": "ğŸ“‚ Output directory"},
    "è‡ªåŠ¨åŒæ­¥æˆ–æ‰‹åŠ¨å¡«å†™": {"en": "Auto-sync or enter manually"},
    "ğŸ¤ é‡‡æ ·ç‡ (Hz)": {"en": "ğŸ¤ Sample rate (Hz)"},
    "âš ï¸ è¦†ç›–å·²å­˜åœ¨æ–‡ä»¶": {"en": "âš ï¸ Overwrite existing files"},
    "ğŸ‘€ é¢„è§ˆå˜æ›´": {"en": "ğŸ‘€ Preview changes"},
    "â–¶ï¸ å¼€å§‹å¤„ç†": {"en": "â–¶ï¸ Start"},
    "ğŸ“‹ æ˜ å°„é¢„è§ˆï¼ˆå‰50æ¡ï¼‰": {"en": "ğŸ“‹ Mapping preview (first 50)"},
    "æºæ–‡ä»¶": {"en": "Source file"},
    "ç›®æ ‡æ–‡ä»¶": {"en": "Target file"},
    "ğŸ“Š å¾…å¤„ç†æ–‡ä»¶æ•°": {"en": "ğŸ“Š Files to process"},
    "ğŸ“ˆ è¿›åº¦ (%)": {"en": "ğŸ“ˆ Progress (%)"},
    "ğŸ“‹ çŠ¶æ€": {"en": "ğŸ“‹ Status"},
    "ğŸ“ è¿è¡Œæ—¥å¿—": {"en": "ğŸ“ Logs"},
    "ğŸ”Š é˜¶æ®µ 2 - VAD è¯­éŸ³æ´»åŠ¨æ£€æµ‹": {
        "en": "ğŸ”Š Stage 2 - VAD speech activity detection"
    },
    "**åŠŸèƒ½ï¼š** ä½¿ç”¨ Silero VAD æ£€æµ‹å¹¶åˆ†å‰²è¯­éŸ³ç‰‡æ®µï¼Œå»é™¤é™éŸ³éƒ¨åˆ†": {
        "en": "**Function:** Use Silero VAD to segment speech and remove silence"
    },
    "é»˜è®¤è¡”æ¥é˜¶æ®µ1è¾“å‡º": {"en": "Default to Stage 1 output"},
    "æ·»åŠ _vadåç¼€": {"en": "Add _vad suffix"},
    "âš™ï¸ VAD å‚æ•°è®¾ç½®": {"en": "âš™ï¸ VAD settings"},
    "ğŸ¯ ç½®ä¿¡åº¦é˜ˆå€¼": {"en": "ğŸ¯ Confidence threshold"},
    "è¶Šé«˜è¶Šä¸¥æ ¼": {"en": "Higher is stricter"},
    "ğŸ—£ï¸ æœ€çŸ­è¯­éŸ³ (ms)": {"en": "ğŸ—£ï¸ Min speech (ms)"},
    "ğŸ”‡ æœ€çŸ­é™éŸ³ (ms)": {"en": "ğŸ”‡ Min silence (ms)"},
    "ğŸ”§ å‰åå¡«å…… (ms)": {"en": "ğŸ”§ Padding (ms)"},
    "â±ï¸ æœ€çŸ­ç‰‡æ®µ (s)": {"en": "â±ï¸ Min segment (s)"},
    "â° æœ€é•¿ç‰‡æ®µ (s)": {"en": "â° Max segment (s)"},
    "ğŸ‘€ é¢„è§ˆ": {"en": "ğŸ‘€ Preview"},
    "ğŸ™ï¸ é˜¶æ®µ 3 - ASR è¯­éŸ³è¯†åˆ«è½¬å½•": {
        "en": "ğŸ™ï¸ Stage 3 - ASR transcription"
    },
    "**åŠŸèƒ½ï¼š** ä½¿ç”¨è¯­éŸ³è¯†åˆ«æŠ€æœ¯å°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡æœ¬ï¼Œç”Ÿæˆè®­ç»ƒæ•°æ®é›†": {
        "en": "**Function:** Transcribe audio to text to build training data"
    },
    "é»˜è®¤è¡”æ¥é˜¶æ®µ2è¾“å‡º": {"en": "Default to Stage 2 output"},
    "æ·»åŠ _asråç¼€": {"en": "Add _asr suffix"},
    "âš™ï¸ è®¡ç®—èµ„æºè®¾ç½®": {"en": "âš™ï¸ Compute settings"},
    "è‡ªåŠ¨": {"en": "Auto"},
    "ğŸ’» è®¡ç®—è®¾å¤‡": {"en": "ğŸ’» Device"},
    "ğŸ”„ å¹¶è¡Œè¿›ç¨‹æ•°": {"en": "ğŸ”„ Parallel processes"},
    "ğŸ”„ åˆ·æ–°è®¾å¤‡æ£€æµ‹": {"en": "ğŸ”„ Refresh device detection"},
    "â„¹ï¸ è®¾å¤‡æ£€æµ‹ä¿¡æ¯": {"en": "â„¹ï¸ Device info"},
    "ğŸ§© é˜¶æ®µ 4 - æ•°æ®é›†åˆå¹¶ (å¯é€‰)": {
        "en": "ğŸ§© Stage 4 - Dataset merge (optional)"
    },
    "**åŠŸèƒ½ï¼š** å°†å¤šä¸ªå‰é¢é˜¶æ®µç”Ÿæˆçš„æ•°æ®é›†ç›®å½•åˆå¹¶ä¸ºä¸€ä¸ªæ–°çš„ HuggingFace æ•°æ®é›†ã€‚è¾“å…¥å¤šä¸ªç›®å½•æ—¶ä½¿ç”¨è‹±æ–‡é€—å·åˆ†éš”ã€‚": {
        "en": "**Function:** Merge datasets from previous stages into a new HuggingFace dataset. Separate paths with commas."
    },
    "ğŸ“ è¾“å…¥æ•°æ®é›†ç›®å½•ï¼ˆé€—å·åˆ†éš”ï¼‰": {
        "en": "ğŸ“ Input dataset directories (comma-separated)"
    },
    "/path/to/ds1,/path/to/ds2,...": {"en": "/path/to/ds1,/path/to/ds2,..."},
    "ğŸ“‚ åˆå¹¶è¾“å‡ºç›®å½•": {"en": "ğŸ“‚ Merge output directory"},
    "/path/to/merged_dataset": {"en": "/path/to/merged_dataset"},
    "â–¶ï¸ å¼€å§‹åˆå¹¶": {"en": "â–¶ï¸ Merge"},
    "ğŸ“ åˆå¹¶æ—¥å¿—": {"en": "ğŸ“ Merge logs"},
    "## ğŸ’¡ ä½¿ç”¨æç¤º": {"en": "## ğŸ’¡ Tips"},
    "- **é˜¶æ®µé¡ºåºä¸å¯é¢ å€’**ï¼šæ¯ä¸ªé˜¶æ®µéƒ½ä¾èµ–å‰ä¸€é˜¶æ®µçš„è¾“å‡º": {
        "en": "- **Do not change the order**: each stage depends on the previous output"
    },
    "- **GPU åŠ é€Ÿ**ï¼šé˜¶æ®µ3æ”¯æŒGPUåŠ é€Ÿï¼Œå¯æ˜¾è‘—æå‡å¤„ç†é€Ÿåº¦": {
        "en": "- **GPU acceleration**: Stage 3 can be significantly faster"
    },
    "- **ç›‘æ§è¿›åº¦**ï¼šæ¯ä¸ªé˜¶æ®µéƒ½æœ‰å®æ—¶è¿›åº¦æ˜¾ç¤ºå’Œè¯¦ç»†æ—¥å¿—": {
        "en": "- **Monitor progress**: each stage shows progress and logs"
    },
    "- **å¯é€‰åˆå¹¶**ï¼šé˜¶æ®µ4å¯å°†å¤šä¸ªé˜¶æ®µäº§å‡ºçš„æ•°æ®é›†è¿›è¡Œåˆå¹¶": {
        "en": "- **Optional merge**: Stage 4 combines datasets from earlier stages"
    },
    "âš ï¸ **æ³¨æ„**ï¼šå¤„ç†å¤§é‡æ–‡ä»¶æ—¶è¯·ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´å’Œè®¡ç®—èµ„æº": {
        "en": "âš ï¸ **Note**: Ensure enough disk space and compute for large batches"
    },
    # training_tab.py
    "BF16ï¼ˆæ¨èï¼‰": {"en": "BF16 (recommended)"},
    "FP16ï¼ˆæ¨èï¼‰": {"en": "FP16 (recommended)"},
    "ğŸ’¡ **LLMæ¨¡å‹**: æ¨èä½¿ç”¨BF16ç²¾åº¦ä»¥è·å¾—æ›´å¥½çš„æ•°å€¼ç¨³å®šæ€§": {
        "en": "ğŸ’¡ **LLM model**: BF16 is recommended for better numerical stability"
    },
    "ğŸ’¡ **Flowæ¨¡å‹**: æ¨èä½¿ç”¨FP16ç²¾åº¦ä»¥èŠ‚çœæ˜¾å­˜å’Œæå‡é€Ÿåº¦": {
        "en": "ğŸ’¡ **Flow model**: FP16 is recommended to save VRAM and improve speed"
    },
    "ğŸš€ æ¨¡å‹è®­ç»ƒ": {"en": "ğŸš€ Model training"},
    "### TTS æ¨¡å‹è®­ç»ƒ": {"en": "### TTS Model Training"},
    "#### 1. æ•°æ®é›†é…ç½®": {"en": "#### 1. Dataset"},
    "è®­ç»ƒæ•°æ®è·¯å¾„": {"en": "Training data path"},
    "è¾“å…¥è®­ç»ƒæ•°æ®è·¯å¾„ï¼Œå¦‚: data/processed/train_ds": {
        "en": "Enter training data path, e.g. data/processed/train_ds"
    },
    "#### 2. æ¨¡å‹é…ç½®": {"en": "#### 2. Model"},
    "æ¨¡å‹ç±»å‹": {"en": "Model type"},
    "æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„": {"en": "Model checkpoint path"},
    "é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„": {"en": "Pretrained model path"},
    "åˆ†è¯å™¨è·¯å¾„": {"en": "Tokenizer path"},
    "åˆ†è¯å™¨æ¨¡å‹è·¯å¾„": {"en": "Tokenizer model path"},
    "è¾“å‡ºç›®å½•": {"en": "Output directory"},
    "è®­ç»ƒè¾“å‡ºä¿å­˜ç›®å½•": {"en": "Training output directory"},
    "#### 3. è®­ç»ƒå‚æ•°": {"en": "#### 3. Training params"},
    "æ‰¹æ¬¡å¤§å°": {"en": "Batch size"},
    "å­¦ä¹ ç‡": {"en": "Learning rate"},
    "è®­ç»ƒè½®æ•°": {"en": "Epochs"},
    "ä¿å­˜é—´éš”(æ­¥æ•°)": {"en": "Save interval (steps)"},
    "æ—¥å¿—è®°å½•é—´éš”(æ­¥æ•°)": {"en": "Log interval (steps)"},
    "è¯„ä¼°é—´éš”(æ­¥æ•°)": {"en": "Eval interval (steps)"},
    "éªŒè¯é›†æ¯”ä¾‹": {"en": "Validation split"},
    "è‡ªåŠ¨åˆ’åˆ†éªŒè¯é›†": {"en": "Auto split validation"},
    "#### 4. é«˜çº§é€‰é¡¹": {"en": "#### 4. Advanced"},
    "å¯ç”¨LoRAå¾®è°ƒ": {"en": "Enable LoRA fine-tuning"},
    "ç²¾åº¦è®¾ç½®": {"en": "Precision"},
    "#### 5. è®¡ç®—èµ„æºè®¾ç½®": {"en": "#### 5. Compute"},
    "ğŸ”„ å¹¶è¡Œè¿›ç¨‹æ•° (GPUæ•°)": {"en": "ğŸ”„ Parallel processes (GPU count)"},
    "ğŸ¯ GPU IDs (å¯é€‰)": {"en": "ğŸ¯ GPU IDs (optional)"},
    "ä¾‹å¦‚: 0,1": {"en": "e.g. 0,1"},
    "#### 6. è®­ç»ƒæ§åˆ¶": {"en": "#### 6. Controls"},
    "ğŸš€ å¼€å§‹è®­ç»ƒ": {"en": "ğŸš€ Start training"},
    "ğŸ›‘ åœæ­¢è®­ç»ƒ": {"en": "ğŸ›‘ Stop training"},
    "ğŸ”„ åˆ·æ–°æ—¥å¿—": {"en": "ğŸ”„ Refresh logs"},
    "#### è®­ç»ƒçŠ¶æ€ä¸æ—¥å¿—": {"en": "#### Training status & logs"},
    "è®­ç»ƒæ—¥å¿—": {"en": "Training logs"},
    "ç­‰å¾…å¼€å§‹è®­ç»ƒ...": {"en": "Waiting to start training..."},
    "æ­£åœ¨å¯åŠ¨è®­ç»ƒ...": {"en": "Starting training..."},
    "#### è®­ç»ƒæ›²çº¿": {"en": "#### Training curves"},
    "è®­ç»ƒæŒ‡æ ‡æ›²çº¿": {"en": "Training metrics plot"},
    "**å›¾è¡¨è®¾ç½®**": {"en": "**Chart settings**"},
    "è‡ªåŠ¨åˆ·æ–°å›¾è¡¨": {"en": "Auto refresh charts"},
    "åˆ·æ–°é—´éš”(ç§’)": {"en": "Refresh interval (s)"},
    "ğŸ”„ ç«‹å³åˆ·æ–°": {"en": "ğŸ”„ Refresh now"},
    "âš¡ å¼ºåˆ¶åˆ·æ–°": {"en": "âš¡ Force refresh"},
    "**ğŸ’¾ å›¾è¡¨å­˜å‚¨ä½ç½®**": {"en": "**ğŸ’¾ Chart storage location**"},
    "è®­ç»ƒå›¾è¡¨ä¼šå®æ—¶æ›´æ–°å¹¶ä¿å­˜åˆ°ï¼š": {
        "en": "Training charts are updated and saved to:"
    },
    "### æ¨¡å‹ç®¡ç†": {"en": "### Model management"},
    "è·¯å¾„": {"en": "Path"},
    "è®­ç»ƒè¾“å‡ºè·¯å¾„": {"en": "Training output paths"},
    "#### æ–‡ä»¶å¤¹æ“ä½œ": {"en": "#### Folder actions"},
    "é€‰æ‹©çš„æ–‡ä»¶å¤¹": {"en": "Selected folder"},
    "ç‚¹å‡»è¡¨æ ¼è¡Œé€‰æ‹©æ–‡ä»¶å¤¹": {"en": "Click a row to select a folder"},
    "ğŸ”„ åˆ·æ–°åˆ—è¡¨": {"en": "ğŸ”„ Refresh list"},
    "ğŸ“‚ åŠ è½½è·¯å¾„": {"en": "ğŸ“‚ Load path"},
    "ğŸ—‘ï¸ åˆ é™¤è·¯å¾„": {"en": "ğŸ—‘ï¸ Delete path"},
    "ğŸ” è½¬æ¢ä¸º model.pt (bf16)": {"en": "ğŸ” Convert to model.pt (bf16)"},
    "æ“ä½œçŠ¶æ€": {"en": "Status"},
    # speaker_manage.py
    "ğŸ—£ï¸ è¯´è¯äººç®¡ç†": {"en": "ğŸ—£ï¸ Speaker management"},
    "# ğŸ—£ï¸ è¯´è¯äººåº“ç®¡ç†": {"en": "# ğŸ—£ï¸ Speaker library"},
    "- é¢„åŠ è½½/ä¿å­˜è·¯å¾„ï¼š`jzx-ai-lab/HydraVox-CV3/spk2info.pt`": {
        "en": "- Preload/save path: `jzx-ai-lab/HydraVox-CV3/spk2info.pt`"
    },
    "- æŸ¥çœ‹å·²æœ‰ speakerï¼ŒåŠ è½½æ•°æ®é›†è®¡ç®— `embedding` å‡å€¼ï¼Œæ–°å¢/è¦†ç›– speaker": {
        "en": "- View speakers, compute embedding means from datasets, add/overwrite speakers"
    },
    "spk2info.pt è·¯å¾„": {"en": "spk2info.pt path"},
    "ğŸ”„ é‡æ–°åŠ è½½": {"en": "ğŸ”„ Reload"},
    "ğŸ’¾ ä¿å­˜å½“å‰": {"en": "ğŸ’¾ Save current"},
    "ç°æœ‰è¯´è¯äºº": {"en": "Existing speakers"},
    "â• ä»æ•°æ®é›†æ–°å¢/è¦†ç›–è¯´è¯äºº": {
        "en": "â• Add/overwrite speakers from dataset"
    },
    "æ•°æ®é›†è·¯å¾„ (HuggingFace load_from_disk)": {
        "en": "Dataset path (HuggingFace load_from_disk)"
    },
    "ğŸ“ è®¡ç®—å‡å€¼": {"en": "ğŸ“ Compute mean"},
    "å‡å€¼ä¿¡æ¯": {"en": "Mean info"},
    "Speaker åç§°": {"en": "Speaker name"},
    "å¦‚ï¼šalice": {"en": "e.g. alice"},
    "âœ… æ–°å¢/è¦†ç›–": {"en": "âœ… Add/overwrite"},
    "è¯·è¾“å…¥æœ‰æ•ˆçš„ speaker åç§°": {
        "en": "Please enter a valid speaker name"
    },
    "è¯·å…ˆè®¡ç®—å‡å€¼": {"en": "Please compute the mean first"},
    # runtime_messages
    "data.select_audio_files": {"zh": "è¯·é€‰æ‹©éŸ³é¢‘æ–‡ä»¶", "en": "Please select audio files"},
    "data.no_files_selected": {"zh": "æœªé€‰æ‹©æ–‡ä»¶", "en": "No files selected"},
    "data.uploaded_files_count": {"zh": "å·²ä¸Šä¼  {count} ä¸ªéŸ³é¢‘æ–‡ä»¶", "en": "Uploaded {count} audio files"},
    "data.upload_audio_first": {"zh": "è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶", "en": "Please upload audio files first"},
    "data.enter_annotation_text": {"zh": "è¯·è¾“å…¥æ ‡æ³¨æ–‡æœ¬", "en": "Please enter annotation text"},
    "data.dataset_empty": {"zh": "æ•°æ®é›†ä¸ºç©º", "en": "Dataset is empty"},
    "data.dataset_valid": {"zh": "âœ… æ•°æ®é›†éªŒè¯é€šè¿‡ï¼Œæ— é—®é¢˜å‘ç°", "en": "âœ… Dataset validated successfully; no issues found"},
    "data.dataset_issues": {
        "zh": "âš ï¸ å‘ç° {count} ä¸ªé—®é¢˜:\n{issues}",
        "en": "âš ï¸ Found {count} issues:\n{issues}",
    },
    "data.row_too_short": {"zh": "ç¬¬{row}è¡Œ: æ–‡æœ¬è¿‡çŸ­", "en": "Row {row}: text too short"},
    "data.row_too_long": {"zh": "ç¬¬{row}è¡Œ: æ–‡æœ¬è¿‡é•¿", "en": "Row {row}: text too long"},
    "data.no_export_data": {"zh": "æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®", "en": "No data to export"},
    "data.unsupported_format": {"zh": "ä¸æ”¯æŒçš„æ ¼å¼", "en": "Unsupported format"},
    "data.enter_valid_input_dir": {"zh": "è¯·è¾“å…¥æœ‰æ•ˆçš„è¾“å…¥ç›®å½•", "en": "Please enter a valid input directory"},
    "data.input_dir_invalid": {"zh": "â— è¾“å…¥ç›®å½•æ— æ•ˆ", "en": "â— Invalid input directory"},
    "data.processing_files_output": {
        "zh": "å°†å¤„ç† {count} ä¸ªæ–‡ä»¶ï¼Œè¾“å‡ºè‡³ {output_dir}",
        "en": "Will process {count} files, output to {output_dir}",
    },
    "data.no_media_files": {"zh": "æ²¡æœ‰å¯å¤„ç†çš„åª’ä½“æ–‡ä»¶", "en": "No media files to process"},
    "data.script_not_found": {"zh": "æ‰¾ä¸åˆ°è„šæœ¬: {path}", "en": "Script not found: {path}"},
    "data.start_failed": {"zh": "å¯åŠ¨å¤±è´¥: {error}", "en": "Failed to start: {error}"},
    "data.in_progress": {
        "zh": "è¿›è¡Œä¸­: {done}/{total} ({pct}%) Â· ç”¨æ—¶ {elapsed}s",
        "en": "In progress: {done}/{total} ({pct}%) Â· elapsed {elapsed}s",
    },
    "data.done": {
        "zh": "âœ… å®Œæˆ: {done}/{total} Â· æ€»ç”¨æ—¶ {elapsed}s",
        "en": "âœ… Done: {done}/{total} Â· total {elapsed}s",
    },
    "data.failed": {
        "zh": "âŒ å¤±è´¥: å·²å®Œæˆ {done}/{total} Â· æ€»ç”¨æ—¶ {elapsed}s",
        "en": "âŒ Failed: completed {done}/{total} Â· total {elapsed}s",
    },
    "data.processing_audio_files_output": {
        "zh": "å°†å¤„ç†çº¦ {count} ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼Œè¾“å‡ºè‡³ {output_dir}",
        "en": "Will process about {count} audio files, output to {output_dir}",
    },
    "data.vad_processing": {"zh": "VAD å¤„ç†ä¸­...", "en": "VAD processing..."},
    "data.in_progress_simple": {
        "zh": "è¿›è¡Œä¸­: {current}/{total} Â· ç”¨æ—¶ {elapsed}s",
        "en": "In progress: {current}/{total} Â· elapsed {elapsed}s",
    },
    "data.run_exception": {"zh": "âŒ è¿è¡Œå¼‚å¸¸: {error}", "en": "âŒ Runtime error: {error}"},
    "data.stage_done": {"zh": "âœ… å®Œæˆ Â· ç”¨æ—¶ {elapsed}s", "en": "âœ… Done Â· elapsed {elapsed}s"},
    "data.stage_failed": {"zh": "âŒ å¤±è´¥ Â· ç”¨æ—¶ {elapsed}s", "en": "âŒ Failed Â· elapsed {elapsed}s"},
    "data.asr_summary": {
        "zh": "å°†è½¬å½• {wav_count} ä¸ª .wav ä¸ {mp3_count} ä¸ª .mp3ï¼Œè¾“å‡ºåˆ° {output_dir}",
        "en": "Will transcribe {wav_count} .wav and {mp3_count} .mp3 files, output to {output_dir}",
    },
    "data.asr_processing": {"zh": "ASR è½¬å½•ä¸­...", "en": "ASR transcribing..."},
    "data.asr_in_progress": {"zh": "è¿›è¡Œä¸­ Â· ç”¨æ—¶ {elapsed}s", "en": "In progress Â· elapsed {elapsed}s"},
    "data.need_input_dirs_comma": {
        "zh": "â— è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªè¾“å…¥ç›®å½•ï¼Œä½¿ç”¨é€—å·åˆ†éš”",
        "en": "â— Please enter at least one input directory, separated by commas",
    },
    "data.need_input_dirs": {"zh": "â— è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªè¾“å…¥ç›®å½•", "en": "â— Please enter at least one input directory"},
    "data.need_output_dir": {"zh": "â— è¯·è¾“å…¥è¾“å‡ºç›®å½•", "en": "â— Please enter an output directory"},
    "data.missing_datasets_dep": {
        "zh": "ç¼ºå°‘datasetsä¾èµ–æˆ–å¯¼å…¥å¤±è´¥: {error}",
        "en": "Missing datasets dependency or import failed: {error}",
    },
    "data.skip_non_dir_dash": {"zh": "- è·³è¿‡ï¼ˆéç›®å½•ï¼‰: {path}", "en": "- Skipped (not a directory): {path}"},
    "data.dataset_ok": {"zh": "- âœ“ {path} Â· {count} æ¡", "en": "- âœ“ {path} Â· {count} items"},
    "data.dataset_load_failed": {"zh": "- âœ— {path} Â· åŠ è½½å¤±è´¥: {error}", "en": "- âœ— {path} Â· Load failed: {error}"},
    "data.output_dir_missing": {"zh": "(æœªæŒ‡å®šï¼Œå»ºè®®å¡«å†™ä¿å­˜ç›®å½•)", "en": "(not set, please provide a save directory)"},
    "data.merge_summary": {
        "zh": "å°†åˆå¹¶ {ok}/{total} ä¸ªå¯ç”¨æ•°æ®é›†ï¼Œæ€»è®¡çº¦ {count} æ¡",
        "en": "Will merge {ok}/{total} available datasets, about {count} items total",
    },
    "data.output_dir_line": {"zh": "è¾“å‡ºç›®å½•: {output_dir}", "en": "Output directory: {output_dir}"},
    "data.reading_progress": {"zh": "è¯»å–ä¸­ ({idx}/{total})", "en": "Reading ({idx}/{total})"},
    "data.no_merge_datasets": {"zh": "âŒ æ²¡æœ‰å¯åˆå¹¶çš„æ•°æ®é›†", "en": "âŒ No datasets to merge"},
    "data.no_common_columns": {"zh": "âŒ å„æ•°æ®åˆ—æ— äº¤é›†ï¼Œæ— æ³•åˆå¹¶", "en": "âŒ No common columns; cannot merge"},
    "data.align_columns": {"zh": "å¯¹é½å­—æ®µ", "en": "Aligning columns"},
    "data.align_failed": {"zh": "âŒ å¯¹é½åˆ—å¤±è´¥: {error}", "en": "âŒ Failed to align columns: {error}"},
    "data.merge_in_progress": {"zh": "åˆå¹¶ä¸­", "en": "Merging"},
    "data.merge_failed": {"zh": "âŒ åˆå¹¶å¤±è´¥: {error}", "en": "âŒ Merge failed: {error}"},
    "data.merge_done": {"zh": "âœ… åˆå¹¶å®Œæˆ Â· å…± {count} æ¡", "en": "âœ… Merge completed Â· {count} items"},
    "data.save_failed": {"zh": "âŒ ä¿å­˜å¤±è´¥: {error}", "en": "âŒ Save failed: {error}"},
    "data.skip_non_dir": {"zh": "è·³è¿‡ï¼ˆéç›®å½•ï¼‰: {path}", "en": "Skipped (not a directory): {path}"},
    "data.no_splits": {"zh": "{path} Â· ä¸å«å¯ç”¨ splitï¼Œå·²è·³è¿‡", "en": "{path} Â· No usable split, skipped"},
    "data.read_count": {"zh": "{path} Â· è¯»å– {count} æ¡", "en": "{path} Â· Read {count} items"},
    "data.load_failed": {"zh": "{path} Â· åŠ è½½å¤±è´¥: {error}", "en": "{path} Â· Load failed: {error}"},
    "data.columns_intersection": {"zh": "åˆ—å¯¹é½ï¼ˆäº¤é›†ï¼‰: {columns}", "en": "Column intersection: {columns}"},
    "data.merge_completed_log": {"zh": "åˆå¹¶å®Œæˆï¼Œåˆè®¡ {count} æ¡", "en": "Merge complete, total {count} items"},
    "data.saved_to": {"zh": "å·²ä¿å­˜è‡³ {output_dir}", "en": "Saved to {output_dir}"},
    "speaker.load_failed": {"zh": "åŠ è½½å¤±è´¥: {error}", "en": "Load failed: {error}"},
    "speaker.saved_to": {"zh": "å·²ä¿å­˜è‡³ {path}", "en": "Saved to {path}"},
    "speaker.save_failed": {"zh": "ä¿å­˜å¤±è´¥: {error}", "en": "Save failed: {error}"},
    "speaker.verify_model_check_failed": {
        "zh": "æ£€æŸ¥è¯´è¯äººæ¨¡å‹å¤±è´¥: {error}",
        "en": "Failed to check speaker model: {error}",
    },
    "speaker.download_failed_fallback": {
        "zh": "ä¸‹è½½ {model} å¤±è´¥ï¼Œå›é€€åˆ° {fallback}",
        "en": "Failed to download {model}, falling back to {fallback}",
    },
    "speaker.download_failed_online": {
        "zh": "ä¸‹è½½è¯´è¯äººæ¨¡å‹å¤±è´¥: {error}ï¼Œå›é€€åˆ°åœ¨çº¿æ¨¡å¼",
        "en": "Failed to download speaker model: {error}, falling back to online mode",
    },
    "speaker.need_dataset_path": {"zh": "è¯·è¾“å…¥æ•°æ®é›†è·¯å¾„", "en": "Please enter a dataset path"},
    "speaker.missing_datasets_dep": {
        "zh": "ç¼ºå°‘datasetsä¾èµ–æˆ–å¯¼å…¥å¤±è´¥: {error}",
        "en": "Missing datasets dependency or import failed: {error}",
    },
    "speaker.load_dataset_failed": {"zh": "åŠ è½½æ•°æ®é›†å¤±è´¥: {error}", "en": "Failed to load dataset: {error}"},
    "speaker.missing_columns": {
        "zh": "æ•°æ®é›†ä¸­æœªæ‰¾åˆ° 'embedding' æˆ– 'audio' åˆ—",
        "en": "Dataset missing 'embedding' or 'audio' column",
    },
    "speaker.embedding_dim_mismatch": {
        "zh": "embedding ç»´åº¦ä¸ä¸€è‡´: {left} vs {right}",
        "en": "Embedding dimension mismatch: {left} vs {right}",
    },
    "speaker.no_embedding_from_audio": {
        "zh": "æœªä»éŸ³é¢‘æå–åˆ°æœ‰æ•ˆçš„ embedding",
        "en": "No valid embedding extracted from audio",
    },
    "speaker.no_embedding": {"zh": "æœªè·å–åˆ°æœ‰æ•ˆçš„ embedding", "en": "No valid embedding found"},
    "speaker.mean_info": {
        "zh": "æ ·æœ¬æ•°: {count}, ç»´åº¦: {dim}, L2èŒƒæ•°: {norm:.6f}",
        "en": "Samples: {count}, dim: {dim}, L2 norm: {norm:.6f}",
    },
    "speaker.mean_info_sampled": {
        "zh": "æ ·æœ¬æ•°: {count}, ç»´åº¦: {dim}, L2èŒƒæ•°: {norm:.6f}ï¼ˆå·²éšæœºæŠ½å– 5000 æ¡éŸ³é¢‘ï¼‰",
        "en": "Samples: {count}, dim: {dim}, L2 norm: {norm:.6f} (sampled 5000 audios)",
    },
    "speaker.compute_mean_failed": {"zh": "è®¡ç®—å‡å€¼å¤±è´¥: {error}", "en": "Failed to compute mean: {error}"},
    "speaker.invalid_name": {"zh": "è¯·è¾“å…¥æœ‰æ•ˆçš„ speaker åç§°", "en": "Please enter a valid speaker name"},
    "speaker.compute_first": {"zh": "è¯·å…ˆè®¡ç®—å‡å€¼", "en": "Please compute the mean first"},
    "training.config_saved": {"zh": "é…ç½®å·²ä¿å­˜åˆ°: {path}", "en": "Config saved to: {path}"},
    "training.task_running": {
        "zh": "âš ï¸ å·²æœ‰è®­ç»ƒä»»åŠ¡åœ¨è¿è¡Œä¸­ï¼Œè¯·å…ˆåœæ­¢å½“å‰è®­ç»ƒ",
        "en": "âš ï¸ A training job is already running. Please stop it first.",
    },
    "training.select_dataset": {"zh": "âŒ è¯·å…ˆé€‰æ‹©æ•°æ®é›†æ–‡ä»¶", "en": "âŒ Please select a dataset file first"},
    "training.script_not_found": {"zh": "âŒ æ‰¾ä¸åˆ°è®­ç»ƒè„šæœ¬: {path}", "en": "âŒ Training script not found: {path}"},
    "training.start_failed": {"zh": "âŒ å¯åŠ¨å¤±è´¥: {error}", "en": "âŒ Failed to start: {error}"},
    "training.started": {
        "zh": "âœ… è®­ç»ƒä»»åŠ¡å·²å¯åŠ¨\nè®­ç»ƒID: {id}\nPID: {pid}\nè„šæœ¬: {script}",
        "en": "âœ… Training started\nID: {id}\nPID: {pid}\nScript: {script}",
    },
    "training.start_failed_detail": {
        "zh": "âŒ è®­ç»ƒå¯åŠ¨å¤±è´¥: {error}",
        "en": "âŒ Training start failed: {error}",
    },
    "training.no_running_task": {"zh": "âš ï¸ å½“å‰æ²¡æœ‰è¿è¡Œä¸­çš„è®­ç»ƒä»»åŠ¡", "en": "âš ï¸ No training task is running"},
    "training.stopped": {"zh": "ğŸ›‘ è®­ç»ƒå·²åœæ­¢ (é€€å‡ºç : {code})", "en": "ğŸ›‘ Training stopped (exit code: {code})"},
    "training.stop_failed": {"zh": "âŒ åœæ­¢è®­ç»ƒå¤±è´¥: {error}", "en": "âŒ Failed to stop training: {error}"},
    "training.model_list_failed": {"zh": "è·å–å¤±è´¥", "en": "Failed to fetch"},
    "training.error_prefix": {"zh": "é”™è¯¯: {error}", "en": "Error: {error}"},
    "training.select_model": {"zh": "è¯·é€‰æ‹©æ¨¡å‹", "en": "Please select a model"},
    "training.model_loaded": {
        "zh": "âœ… æ¨¡å‹ {model} åŠ è½½æˆåŠŸ",
        "en": "âœ… Model {model} loaded successfully",
    },
    "training.select_folder_delete": {
        "zh": "âš ï¸ è¯·é€‰æ‹©è¦åˆ é™¤çš„æ–‡ä»¶å¤¹",
        "en": "âš ï¸ Please select a folder to delete",
    },
    "training.delete_system_folder": {
        "zh": "âš ï¸ ä¸å…è®¸åˆ é™¤ç³»ç»Ÿæ–‡ä»¶å¤¹: {folder}",
        "en": "âš ï¸ Deleting system folder not allowed: {folder}",
    },
    "training.folder_deleted": {
        "zh": "âœ… æ–‡ä»¶å¤¹ {folder} å·²åˆ é™¤",
        "en": "âœ… Folder {folder} deleted",
    },
    "training.folder_not_found": {"zh": "âŒ æœªæ‰¾åˆ°æ–‡ä»¶å¤¹: {folder}", "en": "âŒ Folder not found: {folder}"},
    "training.delete_failed": {"zh": "âŒ åˆ é™¤å¤±è´¥: {error}", "en": "âŒ Delete failed: {error}"},
    "training.select_path_first": {
        "zh": "âš ï¸ è¯·å…ˆåœ¨è¡¨æ ¼ä¸­é€‰æ‹©ä¸€ä¸ªè·¯å¾„",
        "en": "âš ï¸ Please select a path from the table first",
    },
    "training.invalid_path": {"zh": "âŒ è·¯å¾„æ— æ•ˆ: {path}", "en": "âŒ Invalid path: {path}"},
    "training.bin_not_found": {
        "zh": "âŒ æœªæ‰¾åˆ° pytorch_model.bin äº: {path}",
        "en": "âŒ pytorch_model.bin not found at: {path}",
    },
    "training.sharded_not_supported": {
        "zh": "âŒ æš‚ä¸æ”¯æŒåˆ†ç‰‡æƒé‡ï¼ˆ.bin.index.jsonï¼‰ï¼Œè¯·å…ˆåˆå¹¶å†è½¬æ¢",
        "en": "âŒ Sharded weights (.bin.index.json) not supported. Please merge first.",
    },
    "training.state_dict_invalid": {
        "zh": "âŒ æƒé‡æ–‡ä»¶æ ¼å¼ä¸ç¬¦åˆé¢„æœŸï¼ˆéstate_dictï¼‰",
        "en": "âŒ Weight file format invalid (not a state_dict)",
    },
    "training.convert_done": {
        "zh": "âœ… è½¬æ¢å®Œæˆ: {src} â†’ {dst} (bf16)",
        "en": "âœ… Converted: {src} â†’ {dst} (bf16)",
    },
    "training.convert_failed": {"zh": "âŒ è½¬æ¢å¤±è´¥: {error}", "en": "âŒ Conversion failed: {error}"},
    "training.no_outputs": {"zh": "æš‚æ— è®­ç»ƒè¾“å‡º", "en": "No training outputs"},
    "training.train_first": {"zh": "è¯·å…ˆè¿›è¡Œæ¨¡å‹è®­ç»ƒ", "en": "Please run training first"},
    "training.model_files_count": {"zh": "{count}ä¸ªæ¨¡å‹æ–‡ä»¶", "en": "{count} model files"},
    "training.empty_folder": {"zh": "ç©ºæ–‡ä»¶å¤¹", "en": "Empty folder"},
    "training.more_files_suffix": {"zh": " ç­‰{count}ä¸ªæ–‡ä»¶", "en": " and {count} more files"},
    "training.no_task": {"zh": "æš‚æ— è®­ç»ƒä»»åŠ¡", "en": "No training task"},
    "training.status_line": {"zh": "è®­ç»ƒçŠ¶æ€: {status}", "en": "Training status: {status}"},
    "training.id_line": {"zh": "è®­ç»ƒID: {id}", "en": "Training ID: {id}"},
    "training.start_time_line": {"zh": "å¼€å§‹æ—¶é—´: {time}", "en": "Start time: {time}"},
    "training.end_time_line": {"zh": "ç»“æŸæ—¶é—´: {time}", "en": "End time: {time}"},
    "training.log_lines_line": {"zh": "æ—¥å¿—è¡Œæ•°: {count}", "en": "Log lines: {count}"},
    "training.log_omitted": {"zh": "... (çœç•¥äº†å‰{count}è¡Œæ—¥å¿—) ...", "en": "... (omitted {count} earlier lines) ..."},
    "training.log_fetch_failed": {"zh": "è·å–æ—¥å¿—å¤±è´¥: {error}", "en": "Failed to fetch logs: {error}"},
    # train_speech_model.py
    "train.tn_load_failed": {"zh": "æ–‡æœ¬å½’ä¸€åŒ–åº“åŠ è½½å¤±è´¥", "en": "Failed to load text normalization library"},
    "train.ckpt_format_invalid": {
        "zh": "ä¸æ”¯æŒçš„ checkpoint æ ¼å¼ï¼šæœŸæœ›ä¸º state_dict æˆ– {'state_dict': ...}",
        "en": "Unsupported checkpoint format: expected state_dict or {'state_dict': ...}",
    },
    "train.auto_val_disabled": {
        "zh": "è‡ªåŠ¨åˆ’åˆ†éªŒè¯é›†å…³é—­ï¼ˆval_split_ratio <= 0ï¼‰ï¼šä»…è®­ç»ƒä¸éªŒè¯",
        "en": "Auto validation split disabled (val_split_ratio <= 0): train only",
    },
    "train.val_size_zero": {"zh": "éªŒè¯é›†å¤§å°ä¸º 0ï¼šä»…è®­ç»ƒä¸éªŒè¯", "en": "Validation size is 0: train only"},
    "train.val_split_too_large": {
        "zh": "val_split_ratio è¿‡å¤§å¯¼è‡´éªŒè¯é›†å¤§å°({val_size}) >= æ•°æ®é›†æ€»é‡({total})",
        "en": "val_split_ratio too large: val_size ({val_size}) >= total ({total})",
    },
    "train.auto_val_split": {
        "zh": "è‡ªåŠ¨åˆ’åˆ†éªŒè¯é›†: è®­ç»ƒé›† {train_size}ï¼ŒéªŒè¯é›† {val_size}",
        "en": "Auto split: train {train_size}, val {val_size}",
    },
    "train.onnx_no_cuda": {
        "zh": "onnxruntime æœªæ£€æµ‹åˆ° CUDAExecutionProviderï¼ˆavailable={providers}ï¼‰ï¼Œå°†è‡ªåŠ¨ä½¿ç”¨ CPUExecutionProviderã€‚",
        "en": "onnxruntime missing CUDAExecutionProvider (available={providers}); using CPUExecutionProvider.",
    },
    "train.sv_check_failed": {"zh": "æ£€æŸ¥è¯´è¯äººæ¨¡å‹å¤±è´¥: {error}", "en": "Speaker model check failed: {error}"},
    "train.sv_missing_download": {
        "zh": "è¯´è¯äººæ¨¡å‹ä¸å­˜åœ¨ï¼Œå‡†å¤‡ä¸‹è½½: {model_path}",
        "en": "Speaker model not found, downloading: {model_path}",
    },
    "train.sv_download_failed_fallback": {
        "zh": "ä¸‹è½½ {model_path} å¤±è´¥ï¼Œå›é€€åˆ° {fallback_id}",
        "en": "Failed to download {model_path}, fallback to {fallback_id}",
    },
    "train.sv_symlink": {"zh": "åˆ›å»ºè½¯é“¾æ¥: {src} -> {dst}", "en": "Created symlink: {src} -> {dst}"},
    "train.sv_copied": {"zh": "å·²å¤åˆ¶æ¨¡å‹æ–‡ä»¶åˆ°: {path}", "en": "Copied model files to: {path}"},
    "train.sv_download_failed_online": {
        "zh": "ä¸‹è½½è¯´è¯äººæ¨¡å‹å¤±è´¥: {error}ï¼Œå›é€€åˆ°åœ¨çº¿æ¨¡å¼",
        "en": "Failed to download speaker model: {error}, falling back to online mode",
    },
    "train.speech_token_fallback": {
        "zh": "speech_token æå–å¤±è´¥ï¼Œå°†ä½¿ç”¨ batch å†…å…¶å®ƒæ ·æœ¬å›é€€æ›¿ä»£ï¼ˆidx={idx}, audio={audio}, err={err_type}: {error}ï¼‰",
        "en": "speech_token extraction failed; using batch fallback (idx={idx}, audio={audio}, err={err_type}: {error})",
    },
    "train.speech_token_pool_fallback": {
        "zh": "æœ¬ batch æ‰€æœ‰éŸ³é¢‘ speech_token æå–å‡å¤±è´¥ï¼Œå·²ä»å†å²æˆåŠŸæ± éšæœºæŠ½å–å…œåº•ç»§ç»­è®­ç»ƒï¼ˆpool={pool}, pick_len={pick_len}, err={err_type}: {error}ï¼‰",
        "en": "All speech_token extractions failed; fallback to pool (pool={pool}, pick_len={pick_len}, err={err_type}: {error})",
    },
    "train.speech_token_placeholder_fallback": {
        "zh": "æœ¬ batch æ‰€æœ‰éŸ³é¢‘ speech_token æå–å‡å¤±è´¥ï¼Œä¸”å†å²æˆåŠŸæ± ä¸ºç©ºï¼Œå·²ä½¿ç”¨å ä½ token å…œåº•ç»§ç»­è®­ç»ƒï¼ˆfallback_id={fallback_id}, fallback_len={fallback_len}, err={err_type}: {error}ï¼‰",
        "en": "All speech_token extractions failed and pool empty; using placeholder (fallback_id={fallback_id}, fallback_len={fallback_len}, err={err_type}: {error})",
    },
    "train.text_tokenizer_missing": {
        "zh": "æ•°æ®åªæœ‰ text å­—æ®µä½†æœªæä¾› tokenizerï¼Œæ— æ³•ç”Ÿæˆ text_tokenã€‚",
        "en": "Dataset has text only; tokenizer required to build text_token.",
    },
    "train.llm_text_required": {
        "zh": "LLM è®­ç»ƒéœ€è¦ text_token æˆ– text å­—æ®µã€‚",
        "en": "LLM training requires text_token or text.",
    },
    "train.llm_audio_required": {
        "zh": "LLM è®­ç»ƒéœ€è¦ audio å­—æ®µä»¥å®æ—¶æå– speech_tokenã€‚",
        "en": "LLM training requires audio to extract speech_token.",
    },
    "train.flow_audio_required": {
        "zh": "FLOW è®­ç»ƒéœ€è¦ audio å­—æ®µä»¥æå– speech_featã€‚",
        "en": "FLOW training requires audio to extract speech_feat.",
    },
    "train.embedding_missing_no_online": {
        "zh": "æ•°æ®ç¼ºå°‘ embedding ä¸”å·²å…³é—­åœ¨çº¿æå–ï¼ˆ--no_online_embeddingï¼‰ã€‚",
        "en": "Embedding missing and online extraction disabled (--no_online_embedding).",
    },
    "train.cli_model": {"zh": "æ¨¡å‹ç±»å‹", "en": "Model type"},
    "train.cli_config": {"zh": "hyperpyyaml é…ç½®è·¯å¾„", "en": "hyperpyyaml config path"},
    "train.cli_train_data": {"zh": "è®­ç»ƒæ•°æ®è·¯å¾„ï¼Œé€—å·åˆ†éš”", "en": "Training data paths, comma-separated"},
    "train.cli_cv_data": {"zh": "éªŒè¯æ•°æ®è·¯å¾„ï¼Œé€—å·åˆ†éš”", "en": "Validation data paths, comma-separated"},
    "train.cli_auto_val": {"zh": "è‡ªåŠ¨åˆ’åˆ†éªŒè¯é›†", "en": "Auto validation split"},
    "train.cli_val_split": {"zh": "éªŒè¯é›†æ¯”ä¾‹", "en": "Validation split ratio"},
    "train.cli_output_dir": {"zh": "è¾“å‡ºç›®å½•", "en": "Output directory"},
    "train.cli_model_ckpt": {"zh": "åˆå§‹æ¨¡å‹ checkpoint", "en": "Initial model checkpoint"},
    "train.cli_resume": {"zh": "Trainer æ–­ç‚¹ç›®å½•", "en": "Trainer checkpoint directory"},
    "train.cli_tokenizer_path": {"zh": "LLM tokenizer/Qwen è·¯å¾„ï¼›flow å¯é€‰ onnx è·¯å¾„", "en": "LLM tokenizer/Qwen path; flow optional onnx"},
    "train.cli_tokenizer_onnx": {"zh": "speech tokenizer ONNX è·¯å¾„", "en": "Speech tokenizer ONNX path"},
    "train.cli_qwen_pretrain": {"zh": "Qwen2Encoder pretrain_path/tokenizer è·¯å¾„", "en": "Qwen2Encoder pretrain_path/tokenizer path"},
    "train.cli_onnx_use_cuda": {"zh": "ONNX tokenizer æ˜¯å¦ä½¿ç”¨ CUDAExecutionProvider", "en": "Use CUDAExecutionProvider for ONNX tokenizer"},
    "train.cli_onnx_device_id": {"zh": "ONNX CUDA device_idï¼ˆé»˜è®¤å– LOCAL_RANK/RANKï¼Œå¦åˆ™ 0ï¼‰", "en": "ONNX CUDA device_id (default LOCAL_RANK/RANK, else 0)"},
    "train.start": {"zh": "ğŸš€ è®­ç»ƒè„šæœ¬å¯åŠ¨ (model={model})", "en": "ğŸš€ Training script started (model={model})"},
    "train.llm_pretrain_start": {"zh": "ğŸš€ LLM pretrain è„šæœ¬å¯åŠ¨", "en": "ğŸš€ LLM pretrain script started"},
    "train.lora_ignored": {
        "zh": "æ–°æ¨¡å‹é¢„è®­ç»ƒä¸æ”¯æŒ LoRA å‚æ•°ï¼Œå·²å¿½ç•¥ --enable_lora ç­‰é…ç½®ã€‚",
        "en": "LoRA not supported for pretrain; --enable_lora ignored.",
    },
    "train.resume_not_found": {
        "zh": "--resume_from_checkpoint è·¯å¾„ä¸å­˜åœ¨ï¼š{path}",
        "en": "--resume_from_checkpoint path not found: {path}",
    },
    "train.resume_not_dir": {
        "zh": "--resume_from_checkpoint éœ€è¦ä¼  checkpoint ç›®å½•ï¼Œä½†å¾—åˆ°ï¼š{path}",
        "en": "--resume_from_checkpoint must be a checkpoint dir, got: {path}",
    },
    "train.resume_from": {"zh": "å°†ä» Trainer checkpoint æ–­ç‚¹ç»­è®­ï¼š{path}", "en": "Resuming from Trainer checkpoint: {path}"},
    "train.model_ckpt_required": {
        "zh": "æœªæŒ‡å®š --resume_from_checkpoint æ—¶ï¼Œå¿…é¡»æä¾› --model_ckpt ä½œä¸ºåˆå§‹æƒé‡ã€‚",
        "en": "When --resume_from_checkpoint is empty, --model_ckpt is required.",
    },
    "train.missing_keys": {
        "zh": "load_state_dict missing keys: {count}ï¼ˆç¤ºä¾‹ï¼š{sample}ï¼‰",
        "en": "load_state_dict missing keys: {count} (e.g. {sample})",
    },
    "train.unexpected_keys": {
        "zh": "load_state_dict unexpected keys: {count}ï¼ˆç¤ºä¾‹ï¼š{sample}ï¼‰",
        "en": "load_state_dict unexpected keys: {count} (e.g. {sample})",
    },
    # convert_to_wav.py
    "convert.cli_src": {"zh": "åŸå§‹ç›®å½•", "en": "Source directory"},
    "convert.cli_dst": {"zh": "è¾“å‡ºç›®å½•", "en": "Output directory"},
    "convert.cli_sr": {"zh": "ç›®æ ‡é‡‡æ ·ç‡", "en": "Target sample rate"},
    "convert.cli_overwrite": {"zh": "è¦†ç›–å·²å­˜åœ¨æ–‡ä»¶", "en": "Overwrite existing files"},
    "convert.cli_jobs": {"zh": "å¹¶è¡Œçº¿ç¨‹æ•°", "en": "Parallel threads"},
    "convert.no_files": {"zh": "æœªæ‰¾åˆ°æ”¯æŒçš„åª’ä½“æ–‡ä»¶ã€‚", "en": "No supported media files found."},
    "convert.step_done": {
        "zh": "step 1/5: âœ… å…¨éƒ¨å®Œæˆï¼å·²è½¬æ¢ {done}/{total} ä¸ªæ–‡ä»¶ -> {output}",
        "en": "step 1/5: âœ… All Finished! Converted {done}/{total} files -> {output}",
    },
    # vad_processor.py
    "vad.loading_model": {"zh": "æ­£åœ¨åŠ è½½Silero VADæ¨¡å‹...", "en": "Loading Silero VAD model..."},
    "vad.model_loaded": {"zh": "âœ“ VADæ¨¡å‹åŠ è½½æˆåŠŸ", "en": "âœ“ VAD model loaded"},
    "vad.model_load_failed": {"zh": "âœ— VADæ¨¡å‹åŠ è½½å¤±è´¥: {error}", "en": "âœ— VAD model load failed: {error}"},
    "vad.load_audio_failed": {"zh": "åŠ è½½éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {error}", "en": "Failed to load audio file: {error}"},
    "vad.save_audio_failed": {"zh": "ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {error}", "en": "Failed to save audio file: {error}"},
    "vad.audio_too_short_warn": {
        "zh": "  è­¦å‘Š: éŸ³é¢‘æ—¶é•¿({duration:.2f}s)å°äºåˆå¹¶é˜ˆå€¼({threshold}s)",
        "en": "  Warning: audio duration ({duration:.2f}s) is below merge threshold ({threshold}s)",
    },
    "vad.no_speech_segments": {"zh": "  æœªæ£€æµ‹åˆ°è¯­éŸ³ç‰‡æ®µ", "en": "  No speech segments detected"},
    "vad.no_valid_segments": {"zh": "  æ²¡æœ‰æœ‰æ•ˆçš„è¯­éŸ³ç‰‡æ®µ", "en": "  No valid speech segments"},
    "vad.segments_generated": {"zh": "  ç”Ÿæˆ {count} ä¸ªç‰‡æ®µ", "en": "  Generated {count} segments"},
    "vad.process_failed": {"zh": "  å¤„ç†å¤±è´¥: {error}", "en": "  Processing failed: {error}"},
    "vad.scan_dir": {"zh": "æ‰«æç›®å½•: {input_dir}", "en": "Scanning directory: {input_dir}"},
    "vad.no_audio_files": {"zh": "æœªæ‰¾åˆ°ä»»ä½•éŸ³é¢‘æ–‡ä»¶", "en": "No audio files found"},
    "vad.found_audio_files": {"zh": "æ‰¾åˆ° {count} ä¸ªéŸ³é¢‘æ–‡ä»¶", "en": "Found {count} audio files"},
    "vad.processing_audio_desc": {"zh": "å¤„ç†éŸ³é¢‘æ–‡ä»¶", "en": "Processing audio files"},
    "vad.process_complete_count": {
        "zh": "å¤„ç†å®Œæˆï¼Œæ€»å…±ç”Ÿæˆ {count} ä¸ªæ–‡ä»¶",
        "en": "Processing complete, generated {count} files",
    },
    "vad.cli_description": {"zh": "ğŸ”Š åŸºäºSilero VADçš„éŸ³é¢‘æ™ºèƒ½åˆ‡åˆ†å·¥å…·", "en": "ğŸ”Š Silero VAD audio segmentation tool"},
    "vad.cli_input": {"zh": "è¾“å…¥æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„", "en": "Input file or directory path"},
    "vad.cli_output": {"zh": "è¾“å‡ºç›®å½•è·¯å¾„", "en": "Output directory path"},
    "vad.cli_recursive": {"zh": "é€’å½’å¤„ç†å­ç›®å½•", "en": "Process subdirectories recursively"},
    "vad.cli_sample_rate": {"zh": "è¾“å‡ºé‡‡æ ·ç‡ (é»˜è®¤: 16000)", "en": "Output sample rate (default: 16000)"},
    "vad.cli_vad_threshold": {"zh": "VADé˜ˆå€¼ (é»˜è®¤: 0.5)", "en": "VAD threshold (default: 0.5)"},
    "vad.cli_min_speech": {"zh": "æœ€çŸ­è¯­éŸ³æ—¶é•¿ (é»˜è®¤: 250ms)", "en": "Min speech duration (default: 250ms)"},
    "vad.cli_min_silence": {"zh": "æœ€çŸ­é™éŸ³æ—¶é•¿ (é»˜è®¤: 200ms)", "en": "Min silence duration (default: 200ms)"},
    "vad.cli_speech_pad": {"zh": "å‰åå¡«å……æ—¶é•¿ (é»˜è®¤: 30ms)", "en": "Speech padding (default: 30ms)"},
    "vad.cli_merge_threshold": {"zh": "æœ€å°éŸ³é¢‘é•¿åº¦é˜ˆå€¼(ç§’)ï¼Œå°äºæ­¤å€¼ä¼šè¢«åˆå¹¶ (é»˜è®¤: 0.5)", "en": "Min audio length threshold (s), shorter segments will be merged (default: 0.5)"},
    "vad.cli_split_threshold": {"zh": "æœ€å¤§éŸ³é¢‘é•¿åº¦é˜ˆå€¼(ç§’)ï¼Œè¶…è¿‡æ­¤å€¼ä¼šè¢«åˆ‡åˆ† (é»˜è®¤: 10.0)", "en": "Max audio length threshold (s), longer segments will be split (default: 10.0)"},
    "vad.title": {"zh": "ğŸ”Š Silero VAD éŸ³é¢‘åˆ‡åˆ†å·¥å…·", "en": "ğŸ”Š Silero VAD Audio Segmentation Tool"},
    "vad.path_not_found": {"zh": "é”™è¯¯: è·¯å¾„ä¸å­˜åœ¨: {path}", "en": "Error: path does not exist: {path}"},
    "vad.input": {"zh": "è¾“å…¥: {input}", "en": "Input: {input}"},
    "vad.output": {"zh": "è¾“å‡º: {output}", "en": "Output: {output}"},
    "vad.sample_rate": {"zh": "é‡‡æ ·ç‡: {sample_rate}Hz", "en": "Sample rate: {sample_rate}Hz"},
    "vad.split_threshold": {"zh": "åˆ‡åˆ†é˜ˆå€¼: {threshold}s", "en": "Split threshold: {threshold}s"},
    "vad.merge_threshold": {"zh": "åˆå¹¶é˜ˆå€¼: {threshold}s", "en": "Merge threshold: {threshold}s"},
    "vad.init_failed": {"zh": "åˆå§‹åŒ–å¤±è´¥: {error}", "en": "Initialization failed: {error}"},
    "vad.invalid_path_type": {"zh": "æ— æ•ˆçš„è·¯å¾„ç±»å‹: {path}", "en": "Invalid path type: {path}"},
    "vad.user_interrupt": {"zh": "ç”¨æˆ·ä¸­æ–­å¤„ç†", "en": "Processing interrupted by user"},
    "vad.process_error": {"zh": "å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {error}", "en": "Error during processing: {error}"},
    "vad.total_files": {"zh": "æ€»ç”Ÿæˆæ–‡ä»¶æ•°: {count}", "en": "Total files generated: {count}"},
    "vad.total_time": {"zh": "æ€»è€—æ—¶: {seconds:.2f}ç§’", "en": "Total time: {seconds:.2f}s"},
    "vad.done": {"zh": "âœ… å¤„ç†å®Œæˆï¼", "en": "âœ… Processing complete!"},
    "vad.step_done": {
        "zh": "step 2/5: âœ… å…¨éƒ¨å®Œæˆï¼å·²åˆ›å»º {count} ä¸ªæ–‡ä»¶ -> {output}",
        "en": "step 2/5: âœ… All Finished! created {count} files -> {output}",
    },
    # transcribe_to_dataset.py
    "asr.resample": {
        "zh": "é‡é‡‡æ · {name}: {src_sr}Hz -> {dst_sr}Hz",
        "en": "Resample {name}: {src_sr}Hz -> {dst_sr}Hz",
    },
    "asr.txt_read_failed": {
        "zh": " ! è¯»å–txtæ–‡ä»¶å¤±è´¥ {path}: {error}, ä½¿ç”¨ASRè½¬å½•",
        "en": " ! Failed to read txt {path}: {error}, using ASR transcription",
    },
    "asr.merge_stereo": {"zh": "åˆå¹¶ç«‹ä½“å£° {name}", "en": "Merge stereo {name}"},
    "asr.worker_use_gpu": {
        "zh": "[Worker {worker_id}] ä½¿ç”¨GPU {gpu_id}ï¼Œæ˜ å°„ä¸º {target_device}",
        "en": "[Worker {worker_id}] Using GPU {gpu_id}, mapped to {target_device}",
    },
    "asr.worker_gpu_unavailable": {
        "zh": "[Worker {worker_id}] GPU {gpu_id} ä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°CPU",
        "en": "[Worker {worker_id}] GPU {gpu_id} unavailable, switching to CPU",
    },
    "asr.worker_start": {
        "zh": "[Worker {worker_id}] å¼€å§‹å¤„ç† {count} ä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨è®¾å¤‡: {device}",
        "en": "[Worker {worker_id}] Start processing {count} files on {device}",
    },
    "asr.worker_model_loaded": {"zh": "[Worker {worker_id}] ASRæ¨¡å‹åŠ è½½æˆåŠŸ", "en": "[Worker {worker_id}] ASR model loaded"},
    "asr.worker_model_failed": {
        "zh": "[Worker {worker_id}] ASRæ¨¡å‹åŠ è½½å¤±è´¥: {error}",
        "en": "[Worker {worker_id}] ASR model load failed: {error}",
    },
    "asr.worker_try_cpu": {"zh": "[Worker {worker_id}] å°è¯•ä½¿ç”¨CPUåŠ è½½æ¨¡å‹", "en": "[Worker {worker_id}] Trying CPU model"},
    "asr.worker_skip_file": {
        "zh": "[Worker {worker_id}] è·³è¿‡æ–‡ä»¶ {name}: {error}",
        "en": "[Worker {worker_id}] Skipping file {name}: {error}",
    },
    "asr.worker_done": {
        "zh": "[Worker {worker_id}] å®Œæˆå¤„ç†ï¼Œç”Ÿæˆ {count} æ¡è®°å½•",
        "en": "[Worker {worker_id}] Done, generated {count} records",
    },
    "asr.worker_error": {"zh": "[Worker {worker_id}] å‘ç”Ÿé”™è¯¯: {error}", "en": "[Worker {worker_id}] Error: {error}"},
    "asr.worker_desc": {"zh": "Worker {worker_id}", "en": "Worker {worker_id}"},
    "asr.mp_start": {
        "zh": "ğŸš€ å¯åŠ¨å¤šè¿›ç¨‹å¤„ç†: {workers} ä¸ªå·¥ä½œè¿›ç¨‹å¤„ç† {count} ä¸ªæ–‡ä»¶",
        "en": "ğŸš€ Starting multiprocess: {workers} workers for {count} files",
    },
    "asr.main_start_worker": {
        "zh": "[ä¸»è¿›ç¨‹] å¯åŠ¨å·¥ä½œè¿›ç¨‹ {worker_id}ï¼Œåˆ†é… {count} ä¸ªæ–‡ä»¶ï¼ŒGPU: {gpu_id}",
        "en": "[Main] Started worker {worker_id}, assigned {count} files, GPU: {gpu_id}",
    },
    "asr.main_worker_done": {"zh": "[ä¸»è¿›ç¨‹] å·¥ä½œè¿›ç¨‹ {worker_id} å·²å®Œæˆ", "en": "[Main] Worker {worker_id} completed"},
    "asr.main_merge_worker": {
        "zh": "[ä¸»è¿›ç¨‹] åˆå¹¶å·¥ä½œè¿›ç¨‹ {worker_id} çš„ {count} æ¡è®°å½•",
        "en": "[Main] Merging {count} records from worker {worker_id}",
    },
    "asr.mp_done": {"zh": "âœ… å¤šè¿›ç¨‹å¤„ç†å®Œæˆï¼Œæ€»å…±ç”Ÿæˆ {count} æ¡è®°å½•", "en": "âœ… Multiprocess done, {count} records total"},
    "asr.total_records": {"zh": "æ€»è®°å½•æ•°: {count}", "en": "Total records: {count}"},
    "asr.no_records": {"zh": "âš ï¸ æ²¡æœ‰è®°å½•å¯å¤„ç†", "en": "âš ï¸ No records to process"},
    "asr.small_records": {"zh": "è®°å½•æ•°è¾ƒå°‘ï¼Œç›´æ¥å¤„ç†...", "en": "Few records, processing directly..."},
    "asr.normalizing": {"zh": "æ­£åœ¨è¿›è¡Œå“åº¦æ§åˆ¶...", "en": "Normalizing loudness..."},
    "asr.normalizing_desc": {"zh": "å“åº¦å½’ä¸€åŒ–", "en": "Normalizing"},
    "asr.normalizing_batch_desc": {"zh": "æ‰¹æ¬¡å½’ä¸€åŒ– {batch_idx}", "en": "Normalizing batch {batch_idx}"},
    "asr.build_dataset": {"zh": "å¼€å§‹ç”ŸæˆDataset...", "en": "Building dataset..."},
    "asr.dataset_saved": {
        "zh": "âœ“ æ•°æ®é›†å·²ä¿å­˜ï¼ŒåŒ…å« {count} æ¡è®°å½• -> {dst}",
        "en": "âœ“ Saved dataset with {count} records -> {dst}",
    },
    "asr.batch_processing_start": {"zh": "å¼€å§‹åˆ†æ‰¹å¤„ç†ï¼Œæ‰¹å¤§å°: {batch_size}", "en": "Batch processing, size: {batch_size}"},
    "asr.batch_processing": {
        "zh": "å¤„ç†æ‰¹æ¬¡ {batch_idx}/{total_batches} (è®°å½• {start}-{end})",
        "en": "Processing batch {batch_idx}/{total_batches} (records {start}-{end})",
    },
    "asr.batch_build_dataset": {"zh": "åˆ›å»ºæ‰¹æ¬¡ {batch_idx} çš„Dataset...", "en": "Building dataset for batch {batch_idx}..."},
    "asr.batch_saved": {"zh": "âœ“ æ‰¹æ¬¡ {batch_idx} å·²ä¿å­˜åˆ° {path}", "en": "âœ“ Batch {batch_idx} saved to {path}"},
    "asr.merge_batches": {"zh": "åˆå¹¶ {count} ä¸ªæ‰¹æ¬¡...", "en": "Merging {count} batches..."},
    "asr.final_saved": {"zh": "âœ“ æœ€ç»ˆæ•°æ®é›†å·²ä¿å­˜åˆ° {path}", "en": "âœ“ Final dataset saved to {path}"},
    "asr.cleanup_batches": {"zh": "âœ“ å·²æ¸…ç†ä¸´æ—¶æ‰¹æ¬¡æ–‡ä»¶", "en": "âœ“ Cleaned up temporary batch files"},
    "asr.merge_failed": {"zh": "âš ï¸ åˆå¹¶å¤±è´¥: {error}", "en": "âš ï¸ Merge failed: {error}"},
    "asr.batch_files_saved": {"zh": "æ‰¹æ¬¡æ–‡ä»¶ä¿å­˜åœ¨: {path}", "en": "Batch files saved at: {path}"},
    "asr.batch_files_hint": {"zh": "ä½ å¯ä»¥æ‰‹åŠ¨åŠ è½½å„ä¸ªæ‰¹æ¬¡æ–‡ä»¶", "en": "You can load each batch file manually"},
    "asr.cli_src": {"zh": "éŸ³é¢‘æ–‡ä»¶æ ¹ç›®å½•", "en": "Audio root directory"},
    "asr.cli_dst": {"zh": "è¾“å‡º datasets ç›®å½•", "en": "Output datasets directory"},
    "asr.cli_gpu_devices": {"zh": "æŒ‡å®šGPUè®¾å¤‡ï¼Œç”¨é€—å·åˆ†éš”ï¼Œå¦‚: 0,1,2,3", "en": "GPU devices, comma-separated, e.g. 0,1,2,3"},
    "asr.cli_num_workers": {"zh": "å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°", "en": "Number of worker processes"},
    "asr.cli_min_sec": {"zh": "åˆ†æ®µæœ€å°é—´éš” (s)", "en": "Minimum segment interval (s)"},
    "asr.cli_batch_size": {"zh": "æ‰¹å¤„ç†å¤§å°ï¼Œé¿å…å†…å­˜æº¢å‡º (é»˜è®¤: 1000)", "en": "Batch size to avoid OOM (default: 1000)"},
    "asr.no_valid_gpu": {"zh": "âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„GPUè®¾å¤‡ï¼Œä½¿ç”¨CPU", "en": "âš ï¸ No valid GPU found, using CPU"},
    "asr.use_gpu_devices": {"zh": "ğŸš€ å°†ä½¿ç”¨GPUè®¾å¤‡: {devices}", "en": "ğŸš€ Using GPU devices: {devices}"},
    "asr.use_cpu": {"zh": "ğŸ–¥ï¸ ä½¿ç”¨CPUè®¾å¤‡", "en": "ğŸ–¥ï¸ Using CPU"},
    "asr.multi_gpu": {"zh": "ğŸ“Š å¤šGPUå¹¶è¡Œå¤„ç†ï¼Œä½¿ç”¨ {workers} ä¸ªå·¥ä½œè¿›ç¨‹", "en": "ğŸ“Š Multi-GPU processing with {workers} workers"},
    "asr.cpu_parallel": {"zh": "ğŸ”§ CPUå¹¶è¡Œå¤„ç†ï¼Œä½¿ç”¨ {workers} ä¸ªå·¥ä½œè¿›ç¨‹", "en": "ğŸ”§ CPU processing with {workers} workers"},
    "asr.no_audio_files": {
        "zh": "é”™è¯¯ï¼šåœ¨ç›®å½• '{src}' ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½• .wav æˆ– .mp3 æ–‡ä»¶ã€‚",
        "en": "Error: no .wav or .mp3 files found in '{src}'.",
    },
    "asr.found_files": {
        "zh": "æ‰¾åˆ° {wav_count} ä¸ª .wav æ–‡ä»¶å’Œ {mp3_count} ä¸ª .mp3 æ–‡ä»¶",
        "en": "Found {wav_count} .wav and {mp3_count} .mp3 files",
    },
    "asr.loading_model": {"zh": "æ­£åœ¨åŠ è½½ ASR æ¨¡å‹...", "en": "Loading ASR model..."},
    "asr.using_model": {"zh": "[ASR] ä½¿ç”¨ {model_type} äº {device}", "en": "[ASR] using {model_type} on {device}"},
    "asr.asr_desc": {"zh": "ASR", "en": "ASR"},
    "asr.no_records_extracted": {"zh": "é”™è¯¯ï¼šæœªèƒ½ä»éŸ³é¢‘æ–‡ä»¶ä¸­æå–ä»»ä½•æœ‰æ•ˆçš„è¯­éŸ³æ–‡æœ¬å¯¹ã€‚", "en": "Error: no valid speech-text pairs extracted."},
    "asr.step_done": {
        "zh": "step 4/5: âœ… å…¨éƒ¨å®Œæˆï¼å·²è½¬å½• {count} ä¸ªæ–‡ä»¶ -> {dst}",
        "en": "step 4/5: âœ… All Finished! Transcribed {count} files -> {dst}",
    },
    # main_ui.py
    "ui.speaker_fetch_failed": {"zh": "è·å–è¯´è¯äººåˆ—è¡¨å¤±è´¥: {error}", "en": "Failed to fetch speaker list: {error}"},
    "ui.simple_start": {"zh": "ğŸµ å¯åŠ¨ HydraVox ç®€å•ç‰ˆç•Œé¢...", "en": "ğŸµ Launching HydraVox simple UI..."},
    "ui.full_start": {"zh": "ğŸš€ å¯åŠ¨ HydraVox å®Œæ•´ç‰ˆç•Œé¢...", "en": "ğŸš€ Launching HydraVox full UI..."},
    "ui.system_start": {"zh": "ğŸš€ å¯åŠ¨ HydraVox TTS ç³»ç»Ÿ...", "en": "ğŸš€ Starting HydraVox TTS system..."},
    "ui.service_addr": {"zh": "ğŸ“¡ æœåŠ¡åœ°å€: http://{server_name}:{server_port}", "en": "ğŸ“¡ Service: http://{server_name}:{server_port}"},
    "ui.backend_addr": {"zh": "ğŸ”— åç«¯åœ°å€: {backend}", "en": "ğŸ”— Backend: {backend}"},
}


def t(text: str, **kwargs) -> str:
    entry = _TRANSLATIONS.get(text)
    if entry:
        result = entry.get(_LANG, entry.get("zh", text))
    else:
        result = text
    if kwargs:
        try:
            return result.format(**kwargs)
        except Exception:
            return result
    return result


@dataclass(frozen=True)
class I18nMessage:
    key: str
    kwargs: Dict[str, Any]


def msg(key: str, **kwargs: Any) -> I18nMessage:
    return I18nMessage(key=key, kwargs=kwargs)


def render(value: Any) -> Any:
    if isinstance(value, I18nMessage):
        return t(value.key, **value.kwargs)
    if isinstance(value, tuple):
        return tuple(render(v) for v in value)
    if isinstance(value, list):
        return [render(v) for v in value]
    if isinstance(value, dict):
        return {k: render(v) for k, v in value.items()}
    return value


def with_i18n(fn):
    @wraps(fn)
    def wrapper(*args, **kwargs):
        result = fn(*args, **kwargs)
        if isinstance(result, types.GeneratorType):
            for item in result:
                yield render(item)
            return
        return render(result)

    return wrapper


def get_lang() -> str:
    return _LANG


def set_lang(lang: str) -> str:
    global _LANG
    lang = (lang or "").lower()
    if lang not in ("zh", "en"):
        lang = "en"
    _LANG = lang
    os.environ["HYDRAVOX_UI_LANG"] = lang
    return _LANG
