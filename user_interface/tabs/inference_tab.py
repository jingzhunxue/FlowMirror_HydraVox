import os, io, base64, requests, numpy as np, gradio as gr
from typing import Tuple, List, Dict, Optional
import logging
import soundfile as sf
from pathlib import Path

logger = logging.getLogger("inference_tab")

BACKEND = os.getenv("BACKEND_URL", "http://127.0.0.1:8000")

# è·å–é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent.parent
SAMPLES_DIR = PROJECT_ROOT / "assets/samples"

# é»˜è®¤å‚è€ƒéŸ³é¢‘é…ç½®ï¼ˆä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼‰
DEFAULT_REFERENCE_AUDIO = PROJECT_ROOT / "assets/samples/æµªæµªå±±çš„å°å¦–æ€ª/å°çŒªå¦–/å°çŒªå¦–1.wav"
DEFAULT_REFERENCE_TEXT_FILE = PROJECT_ROOT / "assets/samples/æµªæµªå±±çš„å°å¦–æ€ª/å°çŒªå¦–/å°çŒªå¦–1.txt"

def scan_reference_samples() -> Dict[str, Dict[str, Path]]:
    """æ‰«æassets/samplesç›®å½•ï¼Œè·å–æ‰€æœ‰å¯ç”¨çš„å‚è€ƒéŸ³é¢‘å’Œæ–‡æœ¬æ–‡ä»¶"""
    samples = {}
    
    if not SAMPLES_DIR.exists():
        logger.warning(f"Samples directory not found: {SAMPLES_DIR}")
        return samples
    
    try:
        # éå†æ‰€æœ‰ä½œå“æ–‡ä»¶å¤¹ï¼ˆå¦‚ï¼šæµªæµªå±±çš„å°å¦–æ€ªã€å°çŒªä½©å¥‡ç­‰ï¼‰
        for work_dir in SAMPLES_DIR.iterdir():
            if not work_dir.is_dir():
                continue
            
            # é¦–å…ˆæ£€æŸ¥ä½œå“æ–‡ä»¶å¤¹ä¸‹æ˜¯å¦ç›´æ¥æœ‰éŸ³é¢‘æ–‡ä»¶ï¼ˆå•å±‚ç»“æ„ï¼‰
            for wav_file in work_dir.glob("*.wav"):
                txt_file = wav_file.with_suffix(".txt")
                if txt_file.exists():
                    # ç”Ÿæˆæ˜¾ç¤ºåç§°ï¼šä½œå“å/æ–‡ä»¶å
                    display_name = f"{work_dir.name}/{wav_file.stem}"
                    samples[display_name] = {
                        "audio": wav_file,
                        "text": txt_file
                    }
                    logger.debug(f"Found sample: {display_name}")
            
            # ç„¶åéå†æ¯ä¸ªä½œå“ä¸‹çš„è§’è‰²æ–‡ä»¶å¤¹ï¼ˆä¸¤å±‚ç»“æ„ï¼‰
            for character_dir in work_dir.iterdir():
                if not character_dir.is_dir():
                    continue
                
                # æŸ¥æ‰¾éŸ³é¢‘å’Œæ–‡æœ¬æ–‡ä»¶å¯¹
                for wav_file in character_dir.glob("*.wav"):
                    txt_file = wav_file.with_suffix(".txt")
                    if txt_file.exists():
                        # ç”Ÿæˆæ˜¾ç¤ºåç§°ï¼šä½œå“å/è§’è‰²å/æ–‡ä»¶å
                        display_name = f"{work_dir.name}/{character_dir.name}/{wav_file.stem}"
                        samples[display_name] = {
                            "audio": wav_file,
                            "text": txt_file
                        }
                        logger.debug(f"Found sample: {display_name}")
        
        logger.info(f"Found {len(samples)} reference samples in {SAMPLES_DIR}")
        
    except Exception as e:
        logger.error(f"Error scanning samples directory: {e}")
    
    return samples

# åœ¨å¯åŠ¨æ—¶æ‰«æä¸€æ¬¡æ ·æœ¬ç›®å½•
REFERENCE_SAMPLES = scan_reference_samples()

def get_speakers() -> List[str]:
    """ä»åç«¯è·å–è¯´è¯äººåˆ—è¡¨"""
    try:
        resp = requests.get(f"{BACKEND}/api/v1/speakers")
        resp.raise_for_status()
        speakers = resp.json()
        if isinstance(speakers, list) and len(speakers) > 0:
            return speakers
        else:
            logger.error("åç«¯è¿”å›çš„è¯´è¯äººåˆ—è¡¨ä¸ºç©º")
            return ["default"]
    except Exception as e:
        logger.error(f"è·å–è¯´è¯äººåˆ—è¡¨å¤±è´¥: {str(e)}")
        return ["default"]

# æ–°å¢ï¼šåˆ—å‡ºç¯å¢ƒå˜é‡ç›®å½•ä¸­çš„ .pt æ–‡ä»¶
def list_pt_files_from_env(env_var: str, key_word: str = "") -> List[str]:
    directory = os.getenv(env_var, "")
    if not directory or not os.path.isdir(directory):
        return []
    try:
        return [
            os.path.join(directory, name)
            for name in sorted(os.listdir(directory))
            if name.endswith(".pt") and os.path.isfile(os.path.join(directory, name)) and key_word in name
        ]
    except Exception as e:
        logger.error(f"è¯»å– {env_var} ç›®å½•å¤±è´¥: {str(e)}")
        return []

def refresh_speakers():
    """åˆ·æ–°è¯´è¯äººåˆ—è¡¨ï¼Œå¹¶è¿”å›ä¸‹æ‹‰æ¡†æ›´æ–°ä¸ä¿¡æ¯æ–‡æœ¬"""
    speakers = get_speakers()
    info = f"å¯ç”¨è¯´è¯äººï¼š{len(speakers)} ä¸ª"
    return gr.update(choices=speakers, value=speakers[0] if speakers else "default"), info

def load_pt(llm_pt: str, flow_pt: str):
    """åŠ è½½æ¨¡å‹æƒé‡ï¼Œè¿”å›é¢å‘ç”¨æˆ·çš„çŠ¶æ€æ–‡æœ¬ï¼Œå¹¶å¼¹å‡ºæç¤ºã€‚"""
    try:
        if not llm_pt or not flow_pt:
            gr.Warning("è¯·é€‰æ‹© LLM ä¸ Flow æƒé‡æ–‡ä»¶åå†åŠ è½½ã€‚")
            return "â— è¯·å…ˆé€‰æ‹© LLM ä¸ Flow æƒé‡æ–‡ä»¶ã€‚"

        payload = {
            "llm_pt": llm_pt,
            "flow_pt": flow_pt
        }
        resp = requests.post(f"{BACKEND}/api/v1/load_pt", json=payload)
        resp.raise_for_status()
        data = resp.json()
        # å…¼å®¹åç«¯ä¸åŒè¿”å›æ ¼å¼
        msg = data.get("message") if isinstance(data, dict) else str(data)
        gr.Info("æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ")
        return f"âœ… åŠ è½½æˆåŠŸ\nLLM: {llm_pt}\nFlow: {flow_pt}\næ¶ˆæ¯: {msg}"
    except Exception as e:
        logger.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        gr.Warning(f"åŠ è½½å¤±è´¥: {e}")
        return f"âŒ åŠ è½½å¤±è´¥: {e}"

def tts_once(
    text: str,
    speaker_id: str,
    top_p: float,
    top_k: int,
    win_size: int,
    tau_r: float,
    inference_head_num: int,
) -> Tuple[int, np.ndarray]:
    """æ‰§è¡Œä¸€æ¬¡TTSåˆæˆï¼Œæºå¸¦é«˜çº§æ§åˆ¶å‚æ•°"""
    try:
        payload = {
            "text": text,
            "speaker_id": speaker_id,
            "extra_params": {
                "top_p": float(top_p),
                "top_k": int(top_k),
                "win_size": int(win_size),
                "tau_r": float(tau_r),
                "inference_head_num": int(inference_head_num),
            },
        }
        resp = requests.post(f"{BACKEND}/api/v1/tts", json=payload)
        resp.raise_for_status()
        data = resp.json()['data']
        audio_b64 = data["audio_base64"]
        sr = int(data["sample_rate"])
        wav_bytes = base64.b64decode(audio_b64)
        
        import soundfile as sf
        audio_np, file_sr = sf.read(io.BytesIO(wav_bytes), dtype="float32")
        if file_sr != sr:
            sr = file_sr
        return (sr, audio_np)
    except Exception as e:
        import traceback
        traceback.print_exc()
        logger.error(f"TTSåˆæˆå¤±è´¥: {str(e)}")
        return None

def zero_shot_tts(
    text: str,
    prompt_text: str,
    prompt_audio,
    top_p: float,
    top_k: int,
    win_size: int,
    tau_r: float,
    inference_head_num: int,
) -> Tuple[int, np.ndarray]:
    """æ‰§è¡ŒZero-shot TTSåˆæˆ"""
    try:
        if prompt_audio is None:
            logger.error("æç¤ºéŸ³é¢‘ä¸èƒ½ä¸ºç©º")
            return None
            
        # å°†éŸ³é¢‘è½¬æ¢ä¸ºbase64
        import soundfile as sf
        audio_data = prompt_audio[1]  # (sr, audio_data)
        sample_rate = prompt_audio[0]
        
        # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶å†è¯»å–
        import tempfile
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
            sf.write(tmp_file.name, audio_data, sample_rate)
            with open(tmp_file.name, "rb") as f:
                audio_bytes = f.read()
            os.unlink(tmp_file.name)
        
        prompt_audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
        
        payload = {
            "tts_text": text,
            "prompt_text": prompt_text,
            "prompt_audio_base64": prompt_audio_base64,
            "extra_params": {
                "top_p": float(top_p),
                "top_k": int(top_k),
                "win_size": int(win_size),
                "tau_r": float(tau_r),
                "inference_head_num": int(inference_head_num),
            },
        }
        resp = requests.post(f"{BACKEND}/api/v1/zero-shot", json=payload)
        resp.raise_for_status()
        data = resp.json()['data']
        audio_b64 = data["audio_base64"]
        sr = int(data["sample_rate"])
        wav_bytes = base64.b64decode(audio_b64)
        
        audio_np, file_sr = sf.read(io.BytesIO(wav_bytes), dtype="float32")
        if file_sr != sr:
            sr = file_sr
        return (sr, audio_np)
    except Exception as e:
        import traceback
        traceback.print_exc()
        logger.error(f"Zero-shotåˆæˆå¤±è´¥: {str(e)}")
        return None

def synthesis_wrapper(
    text: str,
    synthesis_mode: str,
    speaker_id: str,
    prompt_text: str,
    prompt_audio,
    top_p: float,
    top_k: int,
    win_size: int,
    tau_r: float,
    inference_head_num: int,
) -> Tuple[int, np.ndarray]:
    """åˆæˆåŒ…è£…å‡½æ•°ï¼Œæ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„åˆæˆæ–¹å¼"""
    if synthesis_mode == "é¢„è®¾è¯´è¯äºº":
        return tts_once(text, speaker_id, top_p, top_k, win_size, tau_r, inference_head_num)
    elif synthesis_mode == "Zero-shot":
        if not prompt_text.strip():
            logger.error("Zero-shotæ¨¡å¼ä¸‹æç¤ºæ–‡æœ¬ä¸èƒ½ä¸ºç©º")
            return None
        if prompt_audio is None:
            logger.error("Zero-shotæ¨¡å¼ä¸‹æç¤ºéŸ³é¢‘ä¸èƒ½ä¸ºç©º")
            return None
        return zero_shot_tts(text, prompt_text, prompt_audio, top_p, top_k, win_size, tau_r, inference_head_num)
    else:
        logger.error(f"æœªçŸ¥çš„åˆæˆæ¨¡å¼: {synthesis_mode}")
        return None

def load_default_reference_audio():
    """åŠ è½½é»˜è®¤å‚è€ƒéŸ³é¢‘å’Œæ–‡æœ¬"""
    text_value = ""  # åˆå§‹åŒ–é»˜è®¤æ–‡æœ¬å€¼
    audio_value = None  # åˆå§‹åŒ–é»˜è®¤éŸ³é¢‘å€¼
    
    try:
        # è¯»å–é»˜è®¤å‚è€ƒæ–‡æœ¬
        if DEFAULT_REFERENCE_TEXT_FILE.exists():
            try:
                with open(DEFAULT_REFERENCE_TEXT_FILE, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if content:
                        text_value = content
                        logger.info(f"æˆåŠŸåŠ è½½é»˜è®¤å‚è€ƒæ–‡æœ¬: {len(content)} å­—ç¬¦")
            except Exception as te:
                logger.warning(f"è¯»å–é»˜è®¤å‚è€ƒæ–‡æœ¬å¤±è´¥: {te}")
        else:
            logger.warning(f"é»˜è®¤å‚è€ƒæ–‡æœ¬æ–‡ä»¶ä¸å­˜åœ¨: {DEFAULT_REFERENCE_TEXT_FILE}")

        # è¯»å–é»˜è®¤å‚è€ƒéŸ³é¢‘
        if DEFAULT_REFERENCE_AUDIO.exists():
            try:
                audio_data, sample_rate = sf.read(str(DEFAULT_REFERENCE_AUDIO), dtype="float32")
                audio_value = (sample_rate, audio_data)
                logger.info(f"æˆåŠŸåŠ è½½é»˜è®¤å‚è€ƒéŸ³é¢‘: {sample_rate}Hz, {len(audio_data)/sample_rate:.2f}ç§’")
            except Exception as ae:
                logger.error(f"è¯»å–é»˜è®¤å‚è€ƒéŸ³é¢‘å¤±è´¥: {ae}")
        else:
            logger.warning(f"é»˜è®¤å‚è€ƒéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {DEFAULT_REFERENCE_AUDIO}")
            
        return audio_value, text_value
        
    except Exception as e:
        logger.error(f"åŠ è½½é»˜è®¤å‚è€ƒéŸ³é¢‘å¤±è´¥: {e}")
        return None, text_value

def load_reference_sample(sample_name: str) -> Tuple[Optional[Tuple[int, np.ndarray]], str]:
    """åŠ è½½æŒ‡å®šçš„å‚è€ƒæ ·æœ¬éŸ³é¢‘å’Œæ–‡æœ¬"""
    if not sample_name or sample_name not in REFERENCE_SAMPLES:
        return load_default_reference_audio()
    
    sample_info = REFERENCE_SAMPLES[sample_name]
    text_value = ""
    audio_value = None
    
    try:
        # è¯»å–æ–‡æœ¬
        if sample_info["text"].exists():
            with open(sample_info["text"], "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    text_value = content
                    logger.info(f"åŠ è½½å‚è€ƒæ–‡æœ¬ [{sample_name}]: {len(content)} å­—ç¬¦")
        
        # è¯»å–éŸ³é¢‘
        if sample_info["audio"].exists():
            audio_data, sample_rate = sf.read(str(sample_info["audio"]), dtype="float32")
            audio_value = (sample_rate, audio_data)
            logger.info(f"åŠ è½½å‚è€ƒéŸ³é¢‘ [{sample_name}]: {sample_rate}Hz, {len(audio_data)/sample_rate:.2f}ç§’")
    
    except Exception as e:
        logger.error(f"åŠ è½½å‚è€ƒæ ·æœ¬å¤±è´¥ [{sample_name}]: {e}")
        return load_default_reference_audio()
    
    return audio_value, text_value

def toggle_synthesis_mode(mode: str):
    """åˆ‡æ¢åˆæˆæ¨¡å¼æ—¶çš„ç•Œé¢æ›´æ–°"""
    if mode == "é¢„è®¾è¯´è¯äºº":
        return (
            gr.update(visible=True),   # speaker_row
            gr.update(visible=False),  # zero_shot_row
            gr.update(value=""),       # prompt_text
            gr.update(value=None),     # prompt_audio
            gr.update(visible=False),  # reference_preset
        )
    elif mode == "Zero-shot":
        # è·å–æ ·æœ¬åˆ—è¡¨
        sample_names = list(REFERENCE_SAMPLES.keys())
        
        # å¦‚æœæœ‰æ ·æœ¬å¯ç”¨ï¼ŒåŠ è½½ç¬¬ä¸€ä¸ªæ ·æœ¬
        if sample_names:
            default_sample = sample_names[0]
            default_audio, default_text = load_reference_sample(default_sample)
        else:
            # å¦‚æœæ²¡æœ‰æ ·æœ¬ï¼ŒåŠ è½½é»˜è®¤éŸ³é¢‘
            default_sample = None
            default_audio, default_text = load_default_reference_audio()
        
        return (
            gr.update(visible=False),  # speaker_row
            gr.update(visible=True),   # zero_shot_row
            gr.update(value=default_text),  # prompt_text
            gr.update(value=default_audio), # prompt_audio
            gr.update(
                visible=True,
                choices=sample_names,
                value=default_sample
            ),  # reference_preset
        )
    else:
        return (
            gr.update(visible=True),   # speaker_row
            gr.update(visible=False),  # zero_shot_row
            gr.update(value=""),       # prompt_text
            gr.update(value=None),     # prompt_audio
            gr.update(visible=False),  # reference_preset
        )

def clear_inputs():
    """æ¸…ç©ºè¾“å…¥ä¸è¾“å‡º"""
    return "", None, "", None

def create_inference_tab():
    """åˆ›å»ºæ¨ç†tabç•Œé¢ï¼ˆç²¾ç®€ä¸ç¾åŒ–ï¼‰"""
    with gr.Tab("ğŸ¤ è¯­éŸ³åˆæˆ"):
        gr.Markdown(
            """
            <div style=\"display:flex;align-items:center;gap:10px;margin:8px 0 2px 0;\">
                <h3 style=\"margin:0;color:#2c3e50;\">TTS è¯­éŸ³åˆæˆ</h3>
                <span style=\"font-size:12px;color:#95a5a6;\">å³æ—¶æ–‡æœ¬è½¬è¯­éŸ³ Â· æ”¯æŒå¤šè¯´è¯äºº</span>
            </div>
            """
        )
        
        # æ–°å¢ï¼šæ¨¡å‹æƒé‡é€‰æ‹©ï¼ˆæ¥è‡ªç¯å¢ƒå˜é‡ç›®å½•ï¼‰
        with gr.Row(equal_height=True):
            with gr.Column(scale=2):
                llm_choices = list_pt_files_from_env("LLM_DIR", "llm")
                llm_weight = gr.Dropdown(
                    choices=llm_choices,
                    value=(llm_choices[0] if llm_choices else None),
                    label="LLM æƒé‡ (llm.pt)",
                    allow_custom_value=True,
                    interactive=True,
                )
            with gr.Column(scale=2):
                flow_choices = list_pt_files_from_env("FLOW_DIR", "flow")
                flow_weight = gr.Dropdown(
                    choices=flow_choices,
                    value=(flow_choices[0] if flow_choices else None),
                    label="Flow æƒé‡ (flow.pt)",
                    allow_custom_value=True,
                    interactive=True,
                )
            with gr.Column(scale=1):
                # é€šè¿‡elem_idåº”ç”¨å‚ç›´å±…ä¸­æ ·å¼
                load_pt_btn = gr.Button("ğŸ”„ åŠ è½½æ¨¡å‹", variant="secondary", elem_id="load-pt-btn")
        # æ¨¡å‹åŠ è½½çŠ¶æ€æ˜¾ç¤º
        model_load_info = gr.Markdown(value="", elem_classes=["tiny-muted"])
        # å±€éƒ¨æ ·å¼ï¼šè®©æŒ‰é’®å®¹å™¨å……æ»¡åˆ—é«˜å¹¶å‚ç›´å±…ä¸­
        gr.HTML(
            """
            <style>
            #load-pt-btn { height: 100%; display: flex; align-items: center; }
            #load-pt-btn button { width: 100%; }
            </style>
            """
        )
        with gr.Row():
            with gr.Column(scale=2):
                single_text = gr.Textbox(
                    label="è¾“å…¥æ–‡æœ¬",
                    value="ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäº HTTP çš„ TTS æ¼”ç¤ºã€‚",
                    placeholder="è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬...",
                    lines=4,
                )
                
                gr.Examples(
                    examples=[
                        "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå‡ºå»èµ°èµ°ã€‚",
                        "æ¬¢è¿ä½¿ç”¨ HydraVox,å¤šå¤´é¢„æµ‹è®©è¯­éŸ³æ›´è‡ªç„¶ã€‚",
                        "è¯·åœ¨æç¤ºæ¡†ä¸­è¾“å…¥ä½ æƒ³è¦åˆæˆçš„æ–‡æœ¬å†…å®¹ã€‚",
                    ],
                    inputs=[single_text],
                    label="ç¤ºä¾‹"
                )
            
            with gr.Column(scale=1):
                # åˆæˆæ¨¡å¼é€‰æ‹©
                synthesis_mode = gr.Radio(
                    choices=["é¢„è®¾è¯´è¯äºº", "Zero-shot"],
                    value="é¢„è®¾è¯´è¯äºº",
                    label="åˆæˆæ¨¡å¼"
                )
                gr.Markdown("*é€‰æ‹©ä½¿ç”¨é¢„è®¾è¯´è¯äººæˆ–Zero-shotè¯­éŸ³å…‹éš†*", elem_classes=["tiny-muted"])
                
                # é¢„è®¾è¯´è¯äººæ¨¡å¼ç•Œé¢
                with gr.Group(visible=True) as speaker_row:
                    gr.HTML(
                        """
                        <div style=\"display:flex;align-items:center;gap:8px;margin:8px 0 4px 0;\">
                            <span style=\"font-weight:600;color:#34495e;\">é¢„è®¾è¯´è¯äºº</span>
                            <span style=\"font-size:12px;color:#95a5a6;\">é€‰æ‹©é¢„è®­ç»ƒçš„å‘éŸ³äºº</span>
                        </div>
                        """
                    )
                    speakers_init = get_speakers()
                    with gr.Row():
                        with gr.Column(scale=3):
                            speaker = gr.Dropdown(
                                choices=speakers_init,
                                value=(speakers_init[0] if speakers_init else "default"),
                                label=None,
                                allow_custom_value=False,
                            )
                        with gr.Column(scale=1):
                            refresh_btn = gr.Button("â†» åˆ·æ–°", variant="secondary", min_width=80)
                    speaker_info = gr.Markdown(
                        value=f"å¯ç”¨è¯´è¯äººï¼š{len(speakers_init)} ä¸ª",
                        elem_classes=["tiny-muted"]
                    )
                
                # Zero-shotæ¨¡å¼ç•Œé¢
                with gr.Group(visible=False) as zero_shot_row:
                    gr.HTML(
                        """
                        <div style=\"display:flex;align-items:center;gap:8px;margin:8px 0 4px 0;\">
                            <span style=\"font-weight:600;color:#34495e;\">Zero-shot è¯­éŸ³å…‹éš†</span>
                            <span style=\"font-size:12px;color:#95a5a6;\">é€‰æ‹©æˆ–ä¸Šä¼ å‚è€ƒéŸ³é¢‘è¿›è¡Œè¯­éŸ³å…‹éš†</span>
                        </div>
                        """
                    )
                    
                    # é¢„è®¾å‚è€ƒéŸ³é¢‘é€‰æ‹©
                    sample_names = list(REFERENCE_SAMPLES.keys())
                    reference_preset = gr.Dropdown(
                        choices=sample_names,
                        value=sample_names[0] if sample_names else None,
                        label="é¢„è®¾å‚è€ƒéŸ³é¢‘",
                        visible=False,
                        interactive=True,
                    )
                    gr.Markdown("*é€‰æ‹©ä¸€ä¸ªé¢„è®¾çš„å‚è€ƒéŸ³é¢‘ï¼Œæˆ–è€…ä¸Šä¼ è‡ªå·±çš„éŸ³é¢‘æ–‡ä»¶*", elem_classes=["tiny-muted"])
                    
                    # è·å–é»˜è®¤éŸ³é¢‘å’Œæ–‡æœ¬
                    default_audio, default_text = load_default_reference_audio()
                    
                    prompt_text = gr.Textbox(
                        label="å‚è€ƒéŸ³é¢‘å¯¹åº”æ–‡æœ¬ (ASRå†…å®¹)",
                        placeholder="è¯·è¾“å…¥å‚è€ƒéŸ³é¢‘ä¸­è¯´è¯äººè¯´çš„å†…å®¹...",
                        lines=2,
                        value=default_text
                    )
                    gr.Markdown("*è¯·å‡†ç¡®è¾“å…¥å‚è€ƒéŸ³é¢‘ä¸­çš„æ–‡å­—å†…å®¹ï¼Œè¿™å°†ç”¨äºè¯­éŸ³å…‹éš†*", elem_classes=["tiny-muted"])
                    
                    prompt_audio = gr.Audio(
                        label="å‚è€ƒéŸ³é¢‘",
                        type="numpy",
                        value=default_audio
                    )
                    gr.Markdown("*ä½ å¯ä»¥ä»ä¸Šæ–¹é€‰æ‹©é¢„è®¾éŸ³é¢‘ï¼Œæˆ–è€…ç›´æ¥ä¸Šä¼ è‡ªå·±çš„éŸ³é¢‘æ–‡ä»¶*", elem_classes=["tiny-muted"])
        
        with gr.Row():
            with gr.Accordion("é«˜çº§è®¾ç½®", open=False):
                with gr.Row():
                    top_p = gr.Slider(0.0, 1.0, value=0.9, step=0.01, label="top_p")
                    top_k = gr.Slider(1, 100, value=10, step=1, label="top_k")
                with gr.Row():
                    win_size = gr.Slider(0, 256, value=32, step=8, label="win_size")
                    tau_r = gr.Slider(0.0, 1.0, value=0.2, step=0.01, label="tau_r")
                inference_head_num = gr.Slider(1, 5, value=2, step=1, label="inference_head_num")
        
        with gr.Row():
            synth_btn = gr.Button("ğŸµ åˆæˆ", variant="primary", min_width=120)
            clear_btn = gr.Button("ğŸ§¹ æ¸…ç©º", variant="secondary", min_width=100)
        
        audio_out = gr.Audio(
            label="åˆæˆéŸ³é¢‘",
            type="numpy",
            streaming=False,
            autoplay=True,
            show_download_button=True,
        )
        
        # äº‹ä»¶ç»‘å®š
        # æ¨¡å¼åˆ‡æ¢
        synthesis_mode.change(
            fn=toggle_synthesis_mode,
            inputs=[synthesis_mode],
            outputs=[speaker_row, zero_shot_row, prompt_text, prompt_audio, reference_preset],
        )
        
        # é¢„è®¾å‚è€ƒéŸ³é¢‘é€‰æ‹©
        reference_preset.change(
            fn=load_reference_sample,
            inputs=[reference_preset],
            outputs=[prompt_audio, prompt_text],
        )
        
        # åˆæˆæŒ‰é’®
        synth_btn.click(
            fn=synthesis_wrapper,
            inputs=[
                single_text, 
                synthesis_mode, 
                speaker, 
                prompt_text, 
                prompt_audio, 
                top_p, 
                top_k, 
                win_size, 
                tau_r, 
                inference_head_num
            ],
            outputs=audio_out,
        )
        
        clear_btn.click(
            fn=clear_inputs,
            outputs=[single_text, audio_out, prompt_text, prompt_audio],
        )
        
        refresh_btn.click(
            fn=refresh_speakers,
            outputs=[speaker, speaker_info],
        )

        load_pt_btn.click(
            fn=load_pt,
            inputs=[llm_weight, flow_weight],
            outputs=[model_load_info],
        )
        
        gr.Markdown(f"**åç«¯åœ°å€**: `{BACKEND}`") 