import os, io, base64, requests, numpy as np, gradio as gr
from typing import Tuple, List
import logging
import soundfile as sf

logger = logging.getLogger("inference_tab")

BACKEND = os.getenv("BACKEND_URL", "http://127.0.0.1:8000")

# é»˜è®¤å‚è€ƒéŸ³é¢‘é…ç½®
DEFAULT_REFERENCE_AUDIO = "/home/ecs-user/code/zeying/Audio/HydraVox/yahan.wav"
DEFAULT_REFERENCE_TEXT = "ä»–å°±ç»™å®‹ç¥å®—ä¸Šä¹¦ï¼Œä»–è¯´å¯ä»¥å…å»æˆ‘çš„å®˜èŒï¼Œä½†æ˜¯æˆ‘è¦èµå›æˆ‘å“¥å“¥çš„æ€§å‘½ã€‚"

def get_speakers() -> List[str]:
    """ä»åç«¯è·å–è¯´è¯äººåˆ—è¡¨"""
    try:
        resp = requests.get(f"{BACKEND}/api/v1/speakers")
        resp.raise_for_status()
        speakers = resp.json()
        if isinstance(speakers, list) and len(speakers) > 0:
            return speakers
        else:
            logger.error("åç«¯è¿”å›çš„è¯´è¯äººåˆ—è¡¨ä¸ºç©º")
            return ["default"]
    except Exception as e:
        logger.error(f"è·å–è¯´è¯äººåˆ—è¡¨å¤±è´¥: {str(e)}")
        return ["default"]

# æ–°å¢ï¼šåˆ—å‡ºç¯å¢ƒå˜é‡ç›®å½•ä¸­çš„ .pt æ–‡ä»¶
def list_pt_files_from_env(env_var: str, key_word: str = "") -> List[str]:
    directory = os.getenv(env_var, "")
    if not directory or not os.path.isdir(directory):
        return []
    try:
        return [
            os.path.join(directory, name)
            for name in sorted(os.listdir(directory))
            if name.endswith(".pt") and os.path.isfile(os.path.join(directory, name)) and key_word in name
        ]
    except Exception as e:
        logger.error(f"è¯»å– {env_var} ç›®å½•å¤±è´¥: {str(e)}")
        return []

def refresh_speakers():
    """åˆ·æ–°è¯´è¯äººåˆ—è¡¨ï¼Œå¹¶è¿”å›ä¸‹æ‹‰æ¡†æ›´æ–°ä¸ä¿¡æ¯æ–‡æœ¬"""
    speakers = get_speakers()
    info = f"å¯ç”¨è¯´è¯äººï¼š{len(speakers)} ä¸ª"
    return gr.update(choices=speakers, value=speakers[0] if speakers else "default"), info

def load_pt(llm_pt: str, flow_pt: str):
    """åŠ è½½æ¨¡å‹æƒé‡"""
    payload = {
        "llm_pt": llm_pt,
        "flow_pt": flow_pt
    }
    resp = requests.post(f"{BACKEND}/api/v1/load_pt", json=payload)
    resp.raise_for_status()
    return resp.json()

def tts_once(
    text: str,
    speaker_id: str,
    top_p: float,
    top_k: int,
    win_size: int,
    tau_r: float,
    inference_head_num: int,
) -> Tuple[int, np.ndarray]:
    """æ‰§è¡Œä¸€æ¬¡TTSåˆæˆï¼Œæºå¸¦é«˜çº§æ§åˆ¶å‚æ•°"""
    try:
        payload = {
            "text": text,
            "speaker_id": speaker_id,
            "extra_params": {
                "top_p": float(top_p),
                "top_k": int(top_k),
                "win_size": int(win_size),
                "tau_r": float(tau_r),
                "inference_head_num": int(inference_head_num),
            },
        }
        resp = requests.post(f"{BACKEND}/api/v1/tts", json=payload)
        resp.raise_for_status()
        data = resp.json()['data']
        audio_b64 = data["audio_base64"]
        sr = int(data["sample_rate"])
        wav_bytes = base64.b64decode(audio_b64)
        
        import soundfile as sf
        audio_np, file_sr = sf.read(io.BytesIO(wav_bytes), dtype="float32")
        if file_sr != sr:
            sr = file_sr
        return (sr, audio_np)
    except Exception as e:
        import traceback
        traceback.print_exc()
        logger.error(f"TTSåˆæˆå¤±è´¥: {str(e)}")
        return None

def zero_shot_tts(
    text: str,
    prompt_text: str,
    prompt_audio,
    top_p: float,
    top_k: int,
    win_size: int,
    tau_r: float,
    inference_head_num: int,
) -> Tuple[int, np.ndarray]:
    """æ‰§è¡ŒZero-shot TTSåˆæˆ"""
    try:
        if prompt_audio is None:
            logger.error("æç¤ºéŸ³é¢‘ä¸èƒ½ä¸ºç©º")
            return None
            
        # å°†éŸ³é¢‘è½¬æ¢ä¸ºbase64
        import soundfile as sf
        audio_data = prompt_audio[1]  # (sr, audio_data)
        sample_rate = prompt_audio[0]
        
        # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶å†è¯»å–
        import tempfile
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
            sf.write(tmp_file.name, audio_data, sample_rate)
            with open(tmp_file.name, "rb") as f:
                audio_bytes = f.read()
            os.unlink(tmp_file.name)
        
        prompt_audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
        
        payload = {
            "tts_text": text,
            "prompt_text": prompt_text,
            "prompt_audio_base64": prompt_audio_base64,
            "extra_params": {
                "top_p": float(top_p),
                "top_k": int(top_k),
                "win_size": int(win_size),
                "tau_r": float(tau_r),
                "inference_head_num": int(inference_head_num),
            },
        }
        resp = requests.post(f"{BACKEND}/api/v1/zero-shot", json=payload)
        resp.raise_for_status()
        data = resp.json()['data']
        audio_b64 = data["audio_base64"]
        sr = int(data["sample_rate"])
        wav_bytes = base64.b64decode(audio_b64)
        
        audio_np, file_sr = sf.read(io.BytesIO(wav_bytes), dtype="float32")
        if file_sr != sr:
            sr = file_sr
        return (sr, audio_np)
    except Exception as e:
        import traceback
        traceback.print_exc()
        logger.error(f"Zero-shotåˆæˆå¤±è´¥: {str(e)}")
        return None

def synthesis_wrapper(
    text: str,
    synthesis_mode: str,
    speaker_id: str,
    prompt_text: str,
    prompt_audio,
    top_p: float,
    top_k: int,
    win_size: int,
    tau_r: float,
    inference_head_num: int,
) -> Tuple[int, np.ndarray]:
    """åˆæˆåŒ…è£…å‡½æ•°ï¼Œæ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„åˆæˆæ–¹å¼"""
    if synthesis_mode == "é¢„è®¾è¯´è¯äºº":
        return tts_once(text, speaker_id, top_p, top_k, win_size, tau_r, inference_head_num)
    elif synthesis_mode == "Zero-shot":
        if not prompt_text.strip():
            logger.error("Zero-shotæ¨¡å¼ä¸‹æç¤ºæ–‡æœ¬ä¸èƒ½ä¸ºç©º")
            return None
        if prompt_audio is None:
            logger.error("Zero-shotæ¨¡å¼ä¸‹æç¤ºéŸ³é¢‘ä¸èƒ½ä¸ºç©º")
            return None
        return zero_shot_tts(text, prompt_text, prompt_audio, top_p, top_k, win_size, tau_r, inference_head_num)
    else:
        logger.error(f"æœªçŸ¥çš„åˆæˆæ¨¡å¼: {synthesis_mode}")
        return None

def load_default_reference_audio():
    """åŠ è½½é»˜è®¤å‚è€ƒéŸ³é¢‘"""
    try:
        if os.path.exists(DEFAULT_REFERENCE_AUDIO):
            audio_data, sample_rate = sf.read(DEFAULT_REFERENCE_AUDIO, dtype="float32")
            return (sample_rate, audio_data), DEFAULT_REFERENCE_TEXT
        else:
            logger.warning(f"é»˜è®¤å‚è€ƒéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {DEFAULT_REFERENCE_AUDIO}")
            return None, DEFAULT_REFERENCE_TEXT
    except Exception as e:
        logger.error(f"åŠ è½½é»˜è®¤å‚è€ƒéŸ³é¢‘å¤±è´¥: {e}")
        return None, DEFAULT_REFERENCE_TEXT

def toggle_synthesis_mode(mode: str):
    """åˆ‡æ¢åˆæˆæ¨¡å¼æ—¶çš„ç•Œé¢æ›´æ–°"""
    if mode == "é¢„è®¾è¯´è¯äºº":
        return (
            gr.update(visible=True),   # speaker_row æ˜¾ç¤º
            gr.update(visible=False),  # zero_shot_row éšè—
            gr.update(value=""),       # æ¸…ç©ºprompt_text
            gr.update(value=None),     # æ¸…ç©ºprompt_audio
        )
    elif mode == "Zero-shot":
        # åŠ è½½é»˜è®¤å‚è€ƒéŸ³é¢‘
        default_audio, default_text = load_default_reference_audio()
        return (
            gr.update(visible=False),  # speaker_row éšè—
            gr.update(visible=True),   # zero_shot_row æ˜¾ç¤º
            gr.update(value=default_text),  # è®¾ç½®é»˜è®¤æ–‡æœ¬
            gr.update(value=default_audio), # è®¾ç½®é»˜è®¤éŸ³é¢‘
        )
    else:
        return (
            gr.update(visible=True),   # é»˜è®¤æ˜¾ç¤ºé¢„è®¾è¯´è¯äºº
            gr.update(visible=False),
            gr.update(value=""),       # æ¸…ç©ºprompt_text
            gr.update(value=None),     # æ¸…ç©ºprompt_audio
        )

def clear_inputs():
    """æ¸…ç©ºè¾“å…¥ä¸è¾“å‡º"""
    return "", None, "", None

def create_inference_tab():
    """åˆ›å»ºæ¨ç†tabç•Œé¢ï¼ˆç²¾ç®€ä¸ç¾åŒ–ï¼‰"""
    with gr.Tab("ğŸ¤ è¯­éŸ³åˆæˆ"):
        gr.Markdown(
            """
            <div style=\"display:flex;align-items:center;gap:10px;margin:8px 0 2px 0;\">
                <h3 style=\"margin:0;color:#2c3e50;\">TTS è¯­éŸ³åˆæˆ</h3>
                <span style=\"font-size:12px;color:#95a5a6;\">å³æ—¶æ–‡æœ¬è½¬è¯­éŸ³ Â· æ”¯æŒå¤šè¯´è¯äºº</span>
            </div>
            """
        )
        
        # æ–°å¢ï¼šæ¨¡å‹æƒé‡é€‰æ‹©ï¼ˆæ¥è‡ªç¯å¢ƒå˜é‡ç›®å½•ï¼‰
        with gr.Row(equal_height=True):
            with gr.Column(scale=2):
                llm_choices = list_pt_files_from_env("LLM_DIR", "llm")
                llm_weight = gr.Dropdown(
                    choices=llm_choices,
                    value=(llm_choices[0] if llm_choices else None),
                    label="LLM æƒé‡ (llm.pt)",
                    allow_custom_value=True,
                    interactive=True,
                )
            with gr.Column(scale=2):
                flow_choices = list_pt_files_from_env("FLOW_DIR", "flow")
                flow_weight = gr.Dropdown(
                    choices=flow_choices,
                    value=(flow_choices[0] if flow_choices else None),
                    label="Flow æƒé‡ (flow.pt)",
                    allow_custom_value=True,
                    interactive=True,
                )
            with gr.Column(scale=1):
                # é€šè¿‡elem_idåº”ç”¨å‚ç›´å±…ä¸­æ ·å¼
                load_pt_btn = gr.Button("ğŸ”„ åŠ è½½æ¨¡å‹", variant="secondary", elem_id="load-pt-btn")
        # å±€éƒ¨æ ·å¼ï¼šè®©æŒ‰é’®å®¹å™¨å……æ»¡åˆ—é«˜å¹¶å‚ç›´å±…ä¸­
        gr.HTML(
            """
            <style>
            #load-pt-btn { height: 100%; display: flex; align-items: center; }
            #load-pt-btn button { width: 100%; }
            </style>
            """
        )
        with gr.Row():
            with gr.Column(scale=2):
                single_text = gr.Textbox(
                    label="è¾“å…¥æ–‡æœ¬",
                    value="ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäº HTTP çš„ TTS æ¼”ç¤ºã€‚",
                    placeholder="è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬...",
                    lines=4,
                )
                
                gr.Examples(
                    examples=[
                        "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå‡ºå»èµ°èµ°ã€‚",
                        "æ¬¢è¿ä½¿ç”¨ HydraVox,å¤šå¤´é¢„æµ‹è®©è¯­éŸ³æ›´è‡ªç„¶ã€‚",
                        "è¯·åœ¨æç¤ºæ¡†ä¸­è¾“å…¥ä½ æƒ³è¦åˆæˆçš„æ–‡æœ¬å†…å®¹ã€‚",
                    ],
                    inputs=[single_text],
                    label="ç¤ºä¾‹"
                )
            
            with gr.Column(scale=1):
                # åˆæˆæ¨¡å¼é€‰æ‹©
                synthesis_mode = gr.Radio(
                    choices=["é¢„è®¾è¯´è¯äºº", "Zero-shot"],
                    value="é¢„è®¾è¯´è¯äºº",
                    label="åˆæˆæ¨¡å¼"
                )
                gr.Markdown("*é€‰æ‹©ä½¿ç”¨é¢„è®¾è¯´è¯äººæˆ–Zero-shotè¯­éŸ³å…‹éš†*", elem_classes=["tiny-muted"])
                
                # é¢„è®¾è¯´è¯äººæ¨¡å¼ç•Œé¢
                with gr.Group(visible=True) as speaker_row:
                    gr.HTML(
                        """
                        <div style=\"display:flex;align-items:center;gap:8px;margin:8px 0 4px 0;\">
                            <span style=\"font-weight:600;color:#34495e;\">é¢„è®¾è¯´è¯äºº</span>
                            <span style=\"font-size:12px;color:#95a5a6;\">é€‰æ‹©é¢„è®­ç»ƒçš„å‘éŸ³äºº</span>
                        </div>
                        """
                    )
                    speakers_init = get_speakers()
                    with gr.Row():
                        with gr.Column(scale=3):
                            speaker = gr.Dropdown(
                                choices=speakers_init,
                                value=(speakers_init[0] if speakers_init else "default"),
                                label=None,
                                allow_custom_value=False,
                            )
                        with gr.Column(scale=1):
                            refresh_btn = gr.Button("â†» åˆ·æ–°", variant="secondary", min_width=80)
                    speaker_info = gr.Markdown(
                        value=f"å¯ç”¨è¯´è¯äººï¼š{len(speakers_init)} ä¸ª",
                        elem_classes=["tiny-muted"]
                    )
                
                # Zero-shotæ¨¡å¼ç•Œé¢
                with gr.Group(visible=False) as zero_shot_row:
                    gr.HTML(
                        """
                        <div style=\"display:flex;align-items:center;gap:8px;margin:8px 0 4px 0;\">
                            <span style=\"font-weight:600;color:#34495e;\">Zero-shot è¯­éŸ³å…‹éš†</span>
                            <span style=\"font-size:12px;color:#95a5a6;\">ä¸Šä¼ å‚è€ƒéŸ³é¢‘è¿›è¡Œè¯­éŸ³å…‹éš†</span>
                        </div>
                        """
                    )
                    # è·å–é»˜è®¤éŸ³é¢‘å’Œæ–‡æœ¬
                    default_audio, default_text = load_default_reference_audio()
                    
                    prompt_text = gr.Textbox(
                        label="å‚è€ƒéŸ³é¢‘å¯¹åº”æ–‡æœ¬ (ASRå†…å®¹)",
                        placeholder="è¯·è¾“å…¥å‚è€ƒéŸ³é¢‘ä¸­è¯´è¯äººè¯´çš„å†…å®¹...",
                        lines=2,
                        value=default_text
                    )
                    gr.Markdown("*è¯·å‡†ç¡®è¾“å…¥å‚è€ƒéŸ³é¢‘ä¸­çš„æ–‡å­—å†…å®¹ï¼Œè¿™å°†ç”¨äºè¯­éŸ³å…‹éš†*", elem_classes=["tiny-muted"])
                    
                    prompt_audio = gr.Audio(
                        label="å‚è€ƒéŸ³é¢‘",
                        type="numpy",
                        value=default_audio
                    )
                    gr.Markdown("*å·²é¢„åŠ è½½é»˜è®¤å‚è€ƒéŸ³é¢‘ (yahan.wav)ï¼Œä½ ä¹Ÿå¯ä»¥ä¸Šä¼ è‡ªå·±çš„éŸ³é¢‘æ–‡ä»¶*", elem_classes=["tiny-muted"])
        
        with gr.Row():
            with gr.Accordion("é«˜çº§è®¾ç½®", open=False):
                with gr.Row():
                    top_p = gr.Slider(0.0, 1.0, value=0.9, step=0.01, label="top_p")
                    top_k = gr.Slider(1, 100, value=10, step=1, label="top_k")
                with gr.Row():
                    win_size = gr.Slider(1, 256, value=32, step=8, label="win_size")
                    tau_r = gr.Slider(0.0, 1.0, value=0.2, step=0.01, label="tau_r")
                inference_head_num = gr.Slider(1, 5, value=2, step=1, label="inference_head_num")
        
        with gr.Row():
            synth_btn = gr.Button("ğŸµ åˆæˆ", variant="primary", min_width=120)
            clear_btn = gr.Button("ğŸ§¹ æ¸…ç©º", variant="secondary", min_width=100)
        
        audio_out = gr.Audio(
            label="åˆæˆéŸ³é¢‘",
            type="numpy",
            streaming=False,
            autoplay=True,
            show_download_button=True,
        )
        
        # äº‹ä»¶ç»‘å®š
        # æ¨¡å¼åˆ‡æ¢
        synthesis_mode.change(
            fn=toggle_synthesis_mode,
            inputs=[synthesis_mode],
            outputs=[speaker_row, zero_shot_row, prompt_text, prompt_audio],
        )
        
        # åˆæˆæŒ‰é’®
        synth_btn.click(
            fn=synthesis_wrapper,
            inputs=[
                single_text, 
                synthesis_mode, 
                speaker, 
                prompt_text, 
                prompt_audio, 
                top_p, 
                top_k, 
                win_size, 
                tau_r, 
                inference_head_num
            ],
            outputs=audio_out,
        )
        
        clear_btn.click(
            fn=clear_inputs,
            outputs=[single_text, audio_out, prompt_text, prompt_audio],
        )
        
        refresh_btn.click(
            fn=refresh_speakers,
            outputs=[speaker, speaker_info],
        )

        load_pt_btn.click(
            fn=load_pt,
            inputs=[llm_weight, flow_weight],
            outputs=[],
        )
        
        gr.Markdown(f"**åç«¯åœ°å€**: `{BACKEND}`") 