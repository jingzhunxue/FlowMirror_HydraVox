import os, gradio as gr
import pandas as pd
from typing import List, Tuple
import json

def upload_audio_files(files):
    """å¤„ç†ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶"""
    if not files:
        gr.Warning("è¯·é€‰æ‹©éŸ³é¢‘æ–‡ä»¶")
        return "æœªé€‰æ‹©æ–‡ä»¶", []
    
    file_info = []
    for file in files:
        if file:
            file_info.append({
                "æ–‡ä»¶å": os.path.basename(file.name),
                "å¤§å°": f"{os.path.getsize(file.name) / 1024:.1f} KB",
                "è·¯å¾„": file.name
            })
    
    df = pd.DataFrame(file_info)
    return f"å·²ä¸Šä¼  {len(files)} ä¸ªéŸ³é¢‘æ–‡ä»¶", df

def process_text_annotation(audio_files, text_content: str):
    """å¤„ç†æ–‡æœ¬æ ‡æ³¨"""
    if not audio_files:
        gr.Warning("è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶")
        return "è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"
    
    if not text_content.strip():
        gr.Warning("è¯·è¾“å…¥æ ‡æ³¨æ–‡æœ¬")
        return "è¯·è¾“å…¥æ ‡æ³¨æ–‡æœ¬"
    
    lines = text_content.strip().split('\n')
    annotations = []
    
    for i, line in enumerate(lines):
        if line.strip():
            annotations.append({
                "éŸ³é¢‘ID": f"audio_{i+1}",
                "æ–‡æœ¬": line.strip(),
                "çŠ¶æ€": "å·²æ ‡æ³¨"
            })
    
    df = pd.DataFrame(annotations)
    return df

def validate_dataset(dataset_df):
    """éªŒè¯æ•°æ®é›†è´¨é‡"""
    if dataset_df is None or len(dataset_df) == 0:
        return "æ•°æ®é›†ä¸ºç©º"
    
    issues = []
    
    # æ£€æŸ¥æ–‡æœ¬é•¿åº¦
    for idx, row in dataset_df.iterrows():
        text = str(row.get('æ–‡æœ¬', ''))
        if len(text) < 5:
            issues.append(f"ç¬¬{idx+1}è¡Œ: æ–‡æœ¬è¿‡çŸ­")
        elif len(text) > 200:
            issues.append(f"ç¬¬{idx+1}è¡Œ: æ–‡æœ¬è¿‡é•¿")
    
    if not issues:
        return "âœ… æ•°æ®é›†éªŒè¯é€šè¿‡ï¼Œæ— é—®é¢˜å‘ç°"
    else:
        return f"âš ï¸ å‘ç° {len(issues)} ä¸ªé—®é¢˜:\n" + "\n".join(issues[:10])

def export_dataset(dataset_df, format_type: str):
    """å¯¼å‡ºæ•°æ®é›†"""
    if dataset_df is None or len(dataset_df) == 0:
        gr.Warning("æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®")
        return None
    
    if format_type == "CSV":
        output_path = "/tmp/dataset.csv"
        dataset_df.to_csv(output_path, index=False)
    elif format_type == "JSON":
        output_path = "/tmp/dataset.json"
        dataset_df.to_json(output_path, orient='records', ensure_ascii=False, indent=2)
    else:
        gr.Warning("ä¸æ”¯æŒçš„æ ¼å¼")
        return None
    
    return output_path

def create_data_tab():
    """åˆ›å»ºæ•°æ®å¤„ç†tabç•Œé¢"""
    with gr.Tab("ğŸ“Š æ•°æ®å¤„ç†"):
        gr.Markdown("### æ•°æ®é›†åˆ¶ä½œä¸å¤„ç†")
        
        with gr.Row():
            with gr.Column(scale=1):
                # éŸ³é¢‘ä¸Šä¼ åŒºåŸŸ
                gr.Markdown("#### 1. éŸ³é¢‘æ–‡ä»¶ä¸Šä¼ ")
                audio_files = gr.File(
                    label="é€‰æ‹©éŸ³é¢‘æ–‡ä»¶",
                    file_count="multiple",
                    file_types=[".wav", ".mp3", ".flac", ".m4a"]
                )
                upload_btn = gr.Button("ğŸ“ ä¸Šä¼ éŸ³é¢‘", variant="primary")
                upload_status = gr.Textbox(label="ä¸Šä¼ çŠ¶æ€", interactive=False)
                
                # æ–‡æœ¬æ ‡æ³¨åŒºåŸŸ
                gr.Markdown("#### 2. æ–‡æœ¬æ ‡æ³¨")
                text_annotation = gr.Textbox(
                    label="æ–‡æœ¬æ ‡æ³¨ï¼ˆæ¯è¡Œå¯¹åº”ä¸€ä¸ªéŸ³é¢‘ï¼‰",
                    placeholder="ç¬¬ä¸€ä¸ªéŸ³é¢‘çš„æ–‡æœ¬\nç¬¬äºŒä¸ªéŸ³é¢‘çš„æ–‡æœ¬\n...",
                    lines=8
                )
                annotate_btn = gr.Button("âœï¸ ç”Ÿæˆæ ‡æ³¨", variant="secondary")
                
            with gr.Column(scale=2):
                # æ–‡ä»¶åˆ—è¡¨
                gr.Markdown("#### éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨")
                file_list = gr.Dataframe(
                    headers=["æ–‡ä»¶å", "å¤§å°", "è·¯å¾„"],
                    label="å·²ä¸Šä¼ æ–‡ä»¶",
                    interactive=False
                )
                
                # æ ‡æ³¨ç»“æœ
                gr.Markdown("#### æ ‡æ³¨ç»“æœ")
                annotation_result = gr.Dataframe(
                    headers=["éŸ³é¢‘ID", "æ–‡æœ¬", "çŠ¶æ€"],
                    label="æ ‡æ³¨æ•°æ®",
                    interactive=True
                )
        
        # æ•°æ®å¤„ç†å·¥å…·
        gr.Markdown("### æ•°æ®é›†å¤„ç†å·¥å…·")
        with gr.Row():
            with gr.Column():
                gr.Markdown("#### æ•°æ®éªŒè¯")
                validate_btn = gr.Button("ğŸ” éªŒè¯æ•°æ®é›†", variant="secondary")
                validation_result = gr.Textbox(
                    label="éªŒè¯ç»“æœ",
                    lines=5,
                    interactive=False
                )
                
            with gr.Column():
                gr.Markdown("#### æ•°æ®å¯¼å‡º")
                export_format = gr.Dropdown(
                    choices=["CSV", "JSON"],
                    value="JSON",
                    label="å¯¼å‡ºæ ¼å¼"
                )
                export_btn = gr.Button("ğŸ’¾ å¯¼å‡ºæ•°æ®é›†", variant="primary")
                export_file = gr.File(label="ä¸‹è½½æ•°æ®é›†")
        
        # æ•°æ®ç»Ÿè®¡
        gr.Markdown("### æ•°æ®é›†ç»Ÿè®¡")
        with gr.Row():
            total_count = gr.Number(label="æ€»æ ·æœ¬æ•°", interactive=False)
            avg_length = gr.Number(label="å¹³å‡æ–‡æœ¬é•¿åº¦", interactive=False)
            unique_chars = gr.Number(label="å”¯ä¸€å­—ç¬¦æ•°", interactive=False)
        
        # äº‹ä»¶ç»‘å®š
        upload_btn.click(
            fn=upload_audio_files,
            inputs=[audio_files],
            outputs=[upload_status, file_list]
        )
        
        annotate_btn.click(
            fn=process_text_annotation,
            inputs=[audio_files, text_annotation],
            outputs=annotation_result
        )
        
        validate_btn.click(
            fn=validate_dataset,
            inputs=[annotation_result],
            outputs=validation_result
        )
        
        export_btn.click(
            fn=export_dataset,
            inputs=[annotation_result, export_format],
            outputs=export_file
        ) 