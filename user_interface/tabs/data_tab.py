import os, gradio as gr
import pandas as pd
from typing import List, Tuple
import json
import subprocess, time, sys
from pathlib import Path
import re

AUDIO_EXTS = {".wav", ".flac", ".mp3", ".ogg", ".m4a"}
VIDEO_EXTS = {".mp4", ".mov", ".webm", ".mkv"}


def upload_audio_files(files):
    """å¤„ç†ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶"""
    if not files:
        gr.Warning("è¯·é€‰æ‹©éŸ³é¢‘æ–‡ä»¶")
        return "æœªé€‰æ‹©æ–‡ä»¶", []
    
    file_info = []
    for file in files:
        if file:
            file_info.append({
                "æ–‡ä»¶å": os.path.basename(file.name),
                "å¤§å°": f"{os.path.getsize(file.name) / 1024:.1f} KB",
                "è·¯å¾„": file.name
            })
    
    df = pd.DataFrame(file_info)
    return f"å·²ä¸Šä¼  {len(files)} ä¸ªéŸ³é¢‘æ–‡ä»¶", df

def process_text_annotation(audio_files, text_content: str):
    """å¤„ç†æ–‡æœ¬æ ‡æ³¨"""
    if not audio_files:
        gr.Warning("è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶")
        return "è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"
    
    if not text_content.strip():
        gr.Warning("è¯·è¾“å…¥æ ‡æ³¨æ–‡æœ¬")
        return "è¯·è¾“å…¥æ ‡æ³¨æ–‡æœ¬"
    
    lines = text_content.strip().split('\n')
    annotations = []
    
    for i, line in enumerate(lines):
        if line.strip():
            annotations.append({
                "éŸ³é¢‘ID": f"audio_{i+1}",
                "æ–‡æœ¬": line.strip(),
                "çŠ¶æ€": "å·²æ ‡æ³¨"
            })
    
    df = pd.DataFrame(annotations)
    return df

def validate_dataset(dataset_df):
    """éªŒè¯æ•°æ®é›†è´¨é‡"""
    if dataset_df is None or len(dataset_df) == 0:
        return "æ•°æ®é›†ä¸ºç©º"
    
    issues = []
    
    # æ£€æŸ¥æ–‡æœ¬é•¿åº¦
    for idx, row in dataset_df.iterrows():
        text = str(row.get('æ–‡æœ¬', ''))
        if len(text) < 5:
            issues.append(f"ç¬¬{idx+1}è¡Œ: æ–‡æœ¬è¿‡çŸ­")
        elif len(text) > 200:
            issues.append(f"ç¬¬{idx+1}è¡Œ: æ–‡æœ¬è¿‡é•¿")
    
    if not issues:
        return "âœ… æ•°æ®é›†éªŒè¯é€šè¿‡ï¼Œæ— é—®é¢˜å‘ç°"
    else:
        return f"âš ï¸ å‘ç° {len(issues)} ä¸ªé—®é¢˜:\n" + "\n".join(issues[:10])

def export_dataset(dataset_df, format_type: str):
    """å¯¼å‡ºæ•°æ®é›†"""
    if dataset_df is None or len(dataset_df) == 0:
        gr.Warning("æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®")
        return None
    
    if format_type == "CSV":
        output_path = "/tmp/dataset.csv"
        dataset_df.to_csv(output_path, index=False)
    elif format_type == "JSON":
        output_path = "/tmp/dataset.json"
        dataset_df.to_json(output_path, orient='records', ensure_ascii=False, indent=2)
    else:
        gr.Warning("ä¸æ”¯æŒçš„æ ¼å¼")
        return None
    
    return output_path

def _project_root() -> Path:
    return Path(__file__).resolve().parents[2]


def _convert_script_path() -> Path:
    return _project_root() / "scripts/preprocess/convert_to_wav.py"


def _vad_script_path() -> Path:
    return _project_root() / "scripts/preprocess/vad_processor.py"

def _asr_script_path() -> Path:
    return _project_root() / "scripts/preprocess/transcribe_to_dataset.py"


def _generate_default_output_dir(input_dir: str, suffix: str) -> str:
    if not input_dir:
        return ""
    try:
        base = Path(input_dir)
        parent = base.parent
        if parent == base:
            return str(base.with_name(base.name + suffix))
        return str(parent / f"{base.name}{suffix}")
    except Exception:
        return ""


def _list_media_files(base_dir: str) -> List[Path]:
    if not base_dir or not os.path.isdir(base_dir):
        return []
    base = Path(base_dir)
    exts = AUDIO_EXTS.union(VIDEO_EXTS)
    return [p for p in base.rglob("*") if p.is_file() and p.suffix.lower() in exts]


def _build_expected_outputs(src_dir: str, dst_dir: str) -> List[Path]:
    files = _list_media_files(src_dir)
    src_path = Path(src_dir)
    dst_path = Path(dst_dir)
    expected: List[Path] = []
    for f in files:
        try:
            rel = f.relative_to(src_path).with_suffix(".wav")
        except ValueError:
            # If f is not under src_path, skip
            continue
        expected.append(dst_path / rel)
    return expected


def _count_existing(paths: List[Path]) -> int:
    cnt = 0
    for p in paths:
        if p.exists():
            cnt += 1
    return cnt


def _auto_detect_device_and_processes() -> Tuple[str, int, str]:
    """è¿”å› (device, num_processes, detail_msg). device ä¸º 'GPU' æˆ– 'CPU'ã€‚"""
    device = "CPU"
    num_proc = 1
    detail = "CUDA ä¸å¯ç”¨ï¼Œé»˜è®¤ CPU x1"
    try:
        import torch  # type: ignore
        if torch.cuda.is_available():
            n = torch.cuda.device_count() or 1
            device = "GPU"
            num_proc = n
            detail = f"CUDA å¯ç”¨ï¼ŒGPU æ•°: {n}"
    except Exception:
        pass
    return device, num_proc, detail


def preview_stage1(input_dir: str, output_dir: str):
    if not input_dir or not os.path.isdir(input_dir):
        gr.Warning("è¯·è¾“å…¥æœ‰æ•ˆçš„è¾“å…¥ç›®å½•")
        return pd.DataFrame([]), 0, "â— è¾“å…¥ç›®å½•æ— æ•ˆ"
    if not output_dir:
        output_dir = _generate_default_output_dir(input_dir, "_resample")
    files = _list_media_files(input_dir)
    expected = _build_expected_outputs(input_dir, output_dir)
    preview_rows = []
    for i, (src, dst) in enumerate(zip(files, expected)):
        if i >= 50:
            break
        preview_rows.append({"æºæ–‡ä»¶": str(src), "ç›®æ ‡æ–‡ä»¶": str(dst)})
    df = pd.DataFrame(preview_rows)
    status = f"å°†å¤„ç† {len(files)} ä¸ªæ–‡ä»¶ï¼Œè¾“å‡ºè‡³ {output_dir}"
    return df, len(files), status


def run_stage1(input_dir: str, output_dir: str, sample_rate: int, overwrite: bool):
    """ä»¥å­è¿›ç¨‹æ–¹å¼å¯åŠ¨è½¬æ¢ï¼Œå¹¶å‘¨æœŸæ€§ç»Ÿè®¡è¿›åº¦ï¼ˆé€šè¿‡ç›®æ ‡æ–‡ä»¶å­˜åœ¨æ•°ï¼‰ã€‚"""
    if not input_dir or not os.path.isdir(input_dir):
        yield 0, "â— è¾“å…¥ç›®å½•æ— æ•ˆ", ""
        return
    if not output_dir:
        output_dir = _generate_default_output_dir(input_dir, "_resample")
    expected = _build_expected_outputs(input_dir, output_dir)
    total = len(expected)
    if total == 0:
        yield 0, "æ²¡æœ‰å¯å¤„ç†çš„åª’ä½“æ–‡ä»¶", ""
        return

    script_path = _convert_script_path()
    if not script_path.exists():
        yield 0, f"æ‰¾ä¸åˆ°è„šæœ¬: {script_path}", ""
        return

    cmd = [
        sys.executable,
        str(script_path),
        "--src", input_dir,
        "--dst", output_dir,
        "--sr", str(int(sample_rate)),
    ]
    if overwrite:
        cmd.append("--overwrite")

    start_time = time.time()
    try:
        proc = subprocess.Popen(cmd)
    except Exception as e:
        yield 0, f"å¯åŠ¨å¤±è´¥: {e}", ""
        return

    # è½®è¯¢è¿›åº¦
    last = -1
    while True:
        ret = proc.poll()
        done = _count_existing(expected)
        pct = int(done * 100 / total) if total else 0
        elapsed = int(time.time() - start_time)
        if pct != last:
            status = f"è¿›è¡Œä¸­: {done}/{total} ({pct}%) Â· ç”¨æ—¶ {elapsed}s"
            yield pct, status, ""
            last = pct
        if ret is not None:
            break
        time.sleep(1.0)

    # å®Œæˆ/å¤±è´¥çŠ¶æ€
    done = _count_existing(expected)
    pct = int(done * 100 / total) if total else 0
    elapsed = int(time.time() - start_time)
    if proc.returncode == 0:
        yield 100, f"âœ… å®Œæˆ: {done}/{total} Â· æ€»ç”¨æ—¶ {elapsed}s", ""
    else:
        yield pct, f"âŒ å¤±è´¥: å·²å®Œæˆ {done}/{total} Â· æ€»ç”¨æ—¶ {elapsed}s", ""


def _sync_output_dir(input_dir: str, auto_sync: bool, suffix: str):
    if auto_sync and input_dir:
        return _generate_default_output_dir(input_dir, suffix)
    return gr.update()


def _chain_next_input(prev_output_dir: str, link_enabled: bool):
    if link_enabled and prev_output_dir:
        return prev_output_dir
    return gr.update()


def _refresh_device_once():
    d, p, detail = _auto_detect_device_and_processes()
    return detail, p

def _refresh_device_triplet():
    d, p, detail = _auto_detect_device_and_processes()
    return detail, p, ("GPU" if d == "GPU" else "CPU")


def preview_stage2(input_dir: str, output_dir: str):
    if not input_dir or not os.path.isdir(input_dir):
        return "â— è¾“å…¥ç›®å½•æ— æ•ˆ"
    if not output_dir:
        output_dir = _generate_default_output_dir(input_dir, "_vad")
    # ç²—ç•¥ç»Ÿè®¡ï¼šè¾“å…¥éŸ³é¢‘æ–‡ä»¶æ•°é‡
    audio_files = [p for p in Path(input_dir).rglob('*') if p.suffix.lower() in {'.wav', '.mp3', '.flac', '.m4a', '.ogg', '.wma'}]
    return f"å°†å¤„ç†çº¦ {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼Œè¾“å‡ºè‡³ {output_dir}"


def run_stage2(input_dir: str,
               output_dir: str,
               threshold: float,
               min_speech_ms: float,
               min_silence_ms: float,
               pad_ms: float,
               min_seg_s: float,
               max_seg_s: float,
               link_enabled: bool):
    """è¿è¡Œ VAD å¤„ç†è„šæœ¬ï¼Œå¹¶è§£æ stdout å®æ—¶æ›´æ–°è¿›åº¦ã€‚
    è¾“å‡ºï¼š(progress_percent, status_text, log_text, next_stage_input)
    """
    if not input_dir or not os.path.isdir(input_dir):
        yield 0, "â— è¾“å…¥ç›®å½•æ— æ•ˆ", "", gr.update()
        return
    if not output_dir:
        output_dir = _generate_default_output_dir(input_dir, "_vad")

    script_path = _vad_script_path()
    if not script_path.exists():
        yield 0, f"æ‰¾ä¸åˆ°è„šæœ¬: {script_path}", "", gr.update()
        return

    cmd = [
        sys.executable,
        str(script_path),
        str(input_dir),
        "-o", str(output_dir),
        "--sample-rate", "16000",
        "--vad-threshold", str(float(threshold)),
        "--min-speech-duration-ms", str(int(min_speech_ms)),
        "--min-silence-duration-ms", str(int(min_silence_ms)),
        "--speech-pad-ms", str(int(pad_ms)),
        "--merge-threshold", str(float(min_seg_s)),
        "--split-threshold", str(float(max_seg_s)),
    ]

    try:
        proc = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
            universal_newlines=True,
        )
    except Exception as e:
        yield 0, f"å¯åŠ¨å¤±è´¥: {e}", "", gr.update()
        return

    start_time = time.time()
    log_lines: List[str] = []
    total = None
    current = 0
    last_pct = -1

    # åˆå§‹æç¤º
    yield 0, "VAD å¤„ç†ä¸­...", "", gr.update()

    try:
        assert proc.stdout is not None
        for raw_line in proc.stdout:
            line = raw_line.rstrip()
            if not line:
                continue
            # ç´¯ç§¯æ—¥å¿—ï¼ˆä»…ä¿ç•™æœ€è¿‘ 50 è¡Œï¼‰
            log_lines.append(line)
            if len(log_lines) > 50:
                log_lines = log_lines[-50:]

            # è§£ææ€»æ•°
            m_total = re.search(r"æ‰¾åˆ°\s+(\d+)\s+ä¸ªéŸ³é¢‘æ–‡ä»¶", line)
            if m_total:
                try:
                    total = int(m_total.group(1))
                except Exception:
                    total = total

            # è§£æ tqdm è¿›åº¦ "å¤„ç†éŸ³é¢‘æ–‡ä»¶: ... 12/34 ..."
            if "å¤„ç†éŸ³é¢‘æ–‡ä»¶" in line:
                m_prog = re.search(r"(\d+)\s*/\s*(\d+)", line)
                if m_prog:
                    try:
                        current = int(m_prog.group(1))
                        total = int(m_prog.group(2))
                    except Exception:
                        pass

            pct = None
            if total and total > 0:
                pct = int(max(0, min(100, current * 100 // total)))

            elapsed = int(time.time() - start_time)
            status = f"è¿›è¡Œä¸­: {current}/{total if total else '?'} Â· ç”¨æ—¶ {elapsed}s"

            if pct is not None and pct != last_pct:
                yield pct, status, "\n".join(log_lines), gr.update()
                last_pct = pct
            else:
                # ä»…æ›´æ–°æ—¥å¿—ä¸çŠ¶æ€
                yield (last_pct if last_pct >= 0 else 0), status, "\n".join(log_lines), gr.update()

        ret = proc.wait()
    except Exception as e:
        yield (last_pct if last_pct >= 0 else 0), f"âŒ è¿è¡Œå¼‚å¸¸: {e}", "\n".join(log_lines), gr.update()
        return

    elapsed = int(time.time() - start_time)
    if proc.returncode == 0:
        final_status = f"âœ… å®Œæˆ Â· ç”¨æ—¶ {elapsed}s"
        # è‹¥å¯ç”¨ä¸²è”ï¼Œå°†ä¸‹é˜¶æ®µè¾“å…¥è®¾ç½®ä¸ºæœ¬é˜¶æ®µè¾“å‡ºç›®å½•
        next_input = output_dir if link_enabled else gr.update()
        yield 100, final_status, "\n".join(log_lines), next_input
    else:
        yield (last_pct if last_pct >= 0 else 0), f"âŒ å¤±è´¥ Â· ç”¨æ—¶ {elapsed}s", "\n".join(log_lines), gr.update()


def preview_stage3(input_dir: str, output_dir: str):
    if not input_dir or not os.path.isdir(input_dir):
        return "â— è¾“å…¥ç›®å½•æ— æ•ˆ"
    if not output_dir:
        output_dir = _generate_default_output_dir(input_dir, "_asr")
    wav_files = list(Path(input_dir).rglob("*.wav"))
    mp3_files = list(Path(input_dir).rglob("*.mp3"))
    return f"å°†è½¬å½• {len(wav_files)} ä¸ª .wav ä¸ {len(mp3_files)} ä¸ª .mp3ï¼Œè¾“å‡ºåˆ° {output_dir}"


def run_stage3(input_dir: str,
               output_dir: str,
               device_choice: str,
               num_processes: float):
    """è¿è¡Œ ASR è½¬å½•è„šæœ¬ã€‚
    è¾“å‡ºï¼š(progress_percent, status_text, log_text)
    """
    if not input_dir or not os.path.isdir(input_dir):
        yield 0, "â— è¾“å…¥ç›®å½•æ— æ•ˆ", ""
        return
    if not output_dir:
        output_dir = _generate_default_output_dir(input_dir, "_asr")

    script_path = _asr_script_path()
    if not script_path.exists():
        yield 0, f"æ‰¾ä¸åˆ°è„šæœ¬: {script_path}", ""
        return

    # è®¾å¤‡ä¸è¿›ç¨‹é€‰æ‹©
    chosen = device_choice
    dev_detect, gpu_count, _detail = _auto_detect_device_and_processes()
    if chosen == "è‡ªåŠ¨":
        chosen = "GPU" if dev_detect == "GPU" else "CPU"
    use_cuda = (chosen == "GPU" and dev_detect == "GPU")
    device_flag = "cuda" if use_cuda else "cpu"
    try:
        nproc = max(1, int(num_processes))
    except Exception:
        nproc = 1

    gpu_devices = []
    if use_cuda:
        try:
            import torch  # type: ignore
            if torch.cuda.is_available():
                cnt = torch.cuda.device_count()
                take = min(nproc, cnt)
                gpu_devices = list(range(take))
        except Exception:
            gpu_devices = []
            device_flag = "cpu"

    cmd = [
        sys.executable,
        str(script_path),
        "--src", str(input_dir),
        "--dst", str(output_dir),
        "--device", device_flag,
        "--num_workers", str(nproc),
    ]
    if device_flag == "cuda" and gpu_devices:
        cmd.extend(["--gpu_devices", ",".join(str(x) for x in gpu_devices)])

    try:
        proc = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
            universal_newlines=True,
        )
    except Exception as e:
        yield 0, f"å¯åŠ¨å¤±è´¥: {e}", ""
        return

    start_time = time.time()
    log_lines: List[str] = []
    last_pct = -1
    total_files = None
    # å¤šè¿›ç¨‹è§£ææ•°æ®ï¼ˆå¯é€‰ï¼Œè‹¥è§£æå¤±è´¥åˆ™å›é€€åˆ°æ—¥å¿—ï¼‰
    worker_chunks = {}
    worker_pct = {}
    num_workers_detected = None

    yield 0, "ASR è½¬å½•ä¸­...", ""

    try:
        assert proc.stdout is not None
        for raw_line in proc.stdout:
            line = raw_line.rstrip()
            if not line:
                continue
            log_lines.append(line)
            if len(log_lines) > 200:
                log_lines = log_lines[-200:]

            # è§£ææ€»æ•°
            m_total = re.search(r"æ‰¾åˆ°\s+(\d+)\s+ä¸ª\s+\.wav\s+æ–‡ä»¶å’Œ\s+(\d+)\s+ä¸ª\s+\.mp3\s+æ–‡ä»¶", line)
            if m_total:
                try:
                    total_files = int(m_total.group(1)) + int(m_total.group(2))
                except Exception:
                    pass

            # è§£æå¤šè¿›ç¨‹æ€»ä½“ä¿¡æ¯
            m_multi = re.search(r"å¯åŠ¨å¤šè¿›ç¨‹å¤„ç†:\s*(\d+)\s*ä¸ªå·¥ä½œè¿›ç¨‹å¤„ç†\s*(\d+)\s*ä¸ªæ–‡ä»¶", line)
            if m_multi:
                try:
                    num_workers_detected = int(m_multi.group(1))
                    total_files = int(m_multi.group(2))
                except Exception:
                    pass
            m_chunk = re.search(r"å¯åŠ¨å·¥ä½œè¿›ç¨‹\s*(\d+)ï¼Œåˆ†é…\s*(\d+)\s*ä¸ªæ–‡ä»¶", line)
            if m_chunk:
                try:
                    wid = int(m_chunk.group(1)); size = int(m_chunk.group(2))
                    worker_chunks[wid] = size
                except Exception:
                    pass

            # è§£æå•è¿›åº¦ï¼ˆtqdm ç™¾åˆ†æ¯”ï¼‰
            m_asr_pct = re.search(r"ASR.*?(\d+)%\|", line)
            if m_asr_pct:
                try:
                    pct = int(m_asr_pct.group(1))
                    last_pct = pct
                except Exception:
                    pass

            m_worker_pct = re.search(r"Worker\s*(\d+).*?(\d+)%\|", line)
            if m_worker_pct:
                try:
                    wid = int(m_worker_pct.group(1)); pct = int(m_worker_pct.group(2))
                    worker_pct[wid] = pct
                    if worker_chunks:
                        total_chunk = sum(worker_chunks.values()) or len(worker_pct)
                        weighted = 0
                        for w, p in worker_pct.items():
                            weight = worker_chunks.get(w, 1)
                            weighted += p * weight
                        last_pct = int(weighted / total_chunk)
                    else:
                        # å¹³å‡
                        last_pct = int(sum(worker_pct.values()) / max(1, len(worker_pct)))
                except Exception:
                    pass

            elapsed = int(time.time() - start_time)
            status = f"è¿›è¡Œä¸­ Â· ç”¨æ—¶ {elapsed}s"
            yield (last_pct if last_pct >= 0 else 0), status, "\n".join(log_lines)

        ret = proc.wait()
    except Exception as e:
        yield (last_pct if last_pct >= 0 else 0), f"âŒ è¿è¡Œå¼‚å¸¸: {e}", "\n".join(log_lines)
        return

    elapsed = int(time.time() - start_time)
    if proc.returncode == 0:
        msg = f"âœ… å®Œæˆ Â· ç”¨æ—¶ {elapsed}s"
        yield 100, msg, "\n".join(log_lines)
    else:
        yield (last_pct if last_pct >= 0 else 0), f"âŒ å¤±è´¥ Â· ç”¨æ—¶ {elapsed}s", "\n".join(log_lines)



def _parse_comma_dirs(input_dirs_text: str) -> List[str]:
    if not input_dirs_text:
        return []
    parts = [p.strip() for p in input_dirs_text.split(',')]
    return [p for p in parts if p]


def _dataset_total_len(ds) -> int:
    try:
        from datasets import Dataset, DatasetDict  # type: ignore
        if isinstance(ds, Dataset):
            return len(ds)
        if isinstance(ds, DatasetDict):
            return sum(len(v) for v in ds.values())
    except Exception:
        pass
    try:
        return len(ds)
    except Exception:
        return 0


def _flatten_to_datasets(ds_obj) -> List["Dataset"]:
    from datasets import Dataset, DatasetDict  # type: ignore
    if isinstance(ds_obj, Dataset):
        return [ds_obj]
    if isinstance(ds_obj, DatasetDict):
        return [v for v in ds_obj.values()]
    return []


def preview_stage4(input_dirs_text: str, output_dir: str):
    paths = _parse_comma_dirs(input_dirs_text)
    if not paths:
        return "â— è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªè¾“å…¥ç›®å½•ï¼Œä½¿ç”¨é€—å·åˆ†éš”"
    try:
        from datasets import load_from_disk  # type: ignore
    except Exception as e:
        return f"ç¼ºå°‘datasetsä¾èµ–æˆ–å¯¼å…¥å¤±è´¥: {e}"

    lines: List[str] = []
    total = 0
    ok = 0
    for p in paths:
        if not os.path.isdir(p):
            lines.append(f"- è·³è¿‡ï¼ˆéç›®å½•ï¼‰: {p}")
            continue
        try:
            ds = load_from_disk(p)
            n = _dataset_total_len(ds)
            lines.append(f"- âœ“ {p} Â· {n} æ¡")
            total += n
            ok += 1
        except Exception as e:
            lines.append(f"- âœ— {p} Â· åŠ è½½å¤±è´¥: {e}")

    out = output_dir or "(æœªæŒ‡å®šï¼Œå»ºè®®å¡«å†™ä¿å­˜ç›®å½•)"
    head = [f"å°†åˆå¹¶ {ok}/{len(paths)} ä¸ªå¯ç”¨æ•°æ®é›†ï¼Œæ€»è®¡çº¦ {total} æ¡", f"è¾“å‡ºç›®å½•: {out}"]
    return "\n".join(head + ["", *lines])


def run_stage4_merge(input_dirs_text: str, output_dir: str):
    """åˆå¹¶å¤šä¸ª HuggingFace æ•°æ®é›†ï¼ˆæ”¯æŒ Dataset / DatasetDictï¼‰ï¼Œå¹¶ä¿å­˜åˆ° output_dirã€‚
    è¿›åº¦æŒ‰é˜¶æ®µç²—ç•¥ä¼°è®¡å¹¶æä¾›æ—¥å¿—ã€‚
    """
    paths = _parse_comma_dirs(input_dirs_text)
    if not paths:
        yield 0, "â— è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªè¾“å…¥ç›®å½•", ""
        return
    if not output_dir:
        yield 0, "â— è¯·è¾“å…¥è¾“å‡ºç›®å½•", ""
        return
    try:
        from datasets import load_from_disk, concatenate_datasets  # type: ignore
    except Exception as e:
        yield 0, f"ç¼ºå°‘datasetsä¾èµ–æˆ–å¯¼å…¥å¤±è´¥: {e}", ""
        return

    log_lines: List[str] = []
    ds_list_all = []
    ok = 0
    total_dirs = len(paths)

    # è¯»å–é˜¶æ®µ
    for idx, p in enumerate(paths, start=1):
        if not os.path.isdir(p):
            log_lines.append(f"è·³è¿‡ï¼ˆéç›®å½•ï¼‰: {p}")
            yield int(idx * 10 / max(1, total_dirs)), f"è¯»å–ä¸­ ({idx}/{total_dirs})", "\n".join(log_lines)
            continue
        try:
            ds_obj = load_from_disk(p)
            subs = _flatten_to_datasets(ds_obj)
            if not subs:
                log_lines.append(f"{p} Â· ä¸å«å¯ç”¨ splitï¼Œå·²è·³è¿‡")
            else:
                for ds in subs:
                    ds_list_all.append(ds)
                ln = sum(len(s) for s in subs)
                log_lines.append(f"{p} Â· è¯»å– {ln} æ¡")
                ok += 1
        except Exception as e:
            log_lines.append(f"{p} Â· åŠ è½½å¤±è´¥: {e}")
        yield int(idx * 10 / max(1, total_dirs)), f"è¯»å–ä¸­ ({idx}/{total_dirs})", "\n".join(log_lines)

    if not ds_list_all:
        yield 0, "âŒ æ²¡æœ‰å¯åˆå¹¶çš„æ•°æ®é›†", "\n".join(log_lines)
        return

    # å¯¹é½åˆ—ï¼ˆå–äº¤é›†ï¼‰
    try:
        all_cols = [set(ds.column_names) for ds in ds_list_all]
        common_cols = list(set.intersection(*all_cols)) if all_cols else []
        if not common_cols:
            yield 0, "âŒ å„æ•°æ®åˆ—æ— äº¤é›†ï¼Œæ— æ³•åˆå¹¶", "\n".join(log_lines)
            return
        log_lines.append(f"åˆ—å¯¹é½ï¼ˆäº¤é›†ï¼‰: {sorted(common_cols)}")
        yield 20, "å¯¹é½å­—æ®µ", "\n".join(log_lines)
        ds_aligned = [ds.select_columns(common_cols) for ds in ds_list_all]
    except Exception as e:
        yield 0, f"âŒ å¯¹é½åˆ—å¤±è´¥: {e}", "\n".join(log_lines)
        return

    # åˆå¹¶é˜¶æ®µ
    try:
        merged = concatenate_datasets(ds_aligned)
        log_lines.append(f"åˆå¹¶å®Œæˆï¼Œåˆè®¡ {len(merged)} æ¡")
        yield 60, "åˆå¹¶ä¸­", "\n".join(log_lines)
    except Exception as e:
        yield 0, f"âŒ åˆå¹¶å¤±è´¥: {e}", "\n".join(log_lines)
        return

    # ä¿å­˜é˜¶æ®µ
    try:
        from pathlib import Path as _Path
        _Path(output_dir).parent.mkdir(parents=True, exist_ok=True)
        merged.save_to_disk(output_dir)
        log_lines.append(f"å·²ä¿å­˜è‡³ {output_dir}")
        yield 100, f"âœ… åˆå¹¶å®Œæˆ Â· å…± {len(merged)} æ¡", "\n".join(log_lines)
    except Exception as e:
        yield 90, f"âŒ ä¿å­˜å¤±è´¥: {e}", "\n".join(log_lines)
        return


def create_data_tab():
    """åˆ›å»ºæ•°æ®å¤„ç†tabç•Œé¢"""
    with gr.Tab("ğŸ“Š æ•°æ®å¤„ç†"):
        gr.Markdown("""
        # ğŸ› ï¸ éŸ³é¢‘æ•°æ®é¢„å¤„ç†å·¥ä½œæµ
        
        **ä¸‰ä¸ªé˜¶æ®µçš„å¤„ç†æµç¨‹ï¼š** æ ¼å¼è½¬æ¢ â†’ VADåˆ†æ®µ â†’ ASRè½¬å½•
        **å¯é€‰é˜¶æ®µï¼š** æ•°æ®é›†åˆå¹¶
        """)
        
        device_default, proc_default, device_detail = _auto_detect_device_and_processes()

        # é˜¶æ®µ1ï¼šæ ¼å¼è½¬æ¢ä¸é‡é‡‡æ ·
        with gr.Accordion("ğŸµ é˜¶æ®µ 1 - æ ¼å¼è½¬æ¢ä¸é‡é‡‡æ ·", open=False):
            gr.Markdown("**åŠŸèƒ½ï¼š** å°†å„ç§éŸ³é¢‘/è§†é¢‘æ ¼å¼ç»Ÿä¸€è½¬æ¢ä¸º 16kHz WAV æ ¼å¼")
            
            with gr.Group():
                with gr.Column():
                    with gr.Row():
                        s1_input_dir = gr.Textbox(label="ğŸ“ è¾“å…¥ç›®å½•", placeholder="/path/to/input_dir", scale=3)
                        s1_auto_sync = gr.Checkbox(value=True, label="ğŸ”„ è‡ªåŠ¨åŒæ­¥è¾“å‡ºè·¯å¾„", info="æ·»åŠ _resampleåç¼€", scale=1)
                        s1_output_dir = gr.Textbox(label="ğŸ“‚ è¾“å‡ºç›®å½•", placeholder="è‡ªåŠ¨åŒæ­¥æˆ–æ‰‹åŠ¨å¡«å†™", scale=3)
                        
                    with gr.Row():
                        s1_sr = gr.Dropdown(
                            choices=[8000,16000,22050,44100,48000], 
                            value=16000, 
                            label="ğŸ¤ é‡‡æ ·ç‡ (Hz)",
                            scale=1
                        )
                        s1_overwrite = gr.Checkbox(value=False, label="âš ï¸ è¦†ç›–å·²å­˜åœ¨æ–‡ä»¶", scale=1)
                        
                    with gr.Row():
                        s1_preview_btn = gr.Button("ğŸ‘€ é¢„è§ˆå˜æ›´", variant="secondary", scale=1)
                        s1_start_btn = gr.Button("â–¶ï¸ å¼€å§‹å¤„ç†", variant="primary", scale=1)
                        
                    s1_preview_df = gr.Dataframe(
                        headers=["æºæ–‡ä»¶", "ç›®æ ‡æ–‡ä»¶"], 
                        label="ğŸ“‹ æ˜ å°„é¢„è§ˆï¼ˆå‰50æ¡ï¼‰", 
                        interactive=False
                    )
                    
                    with gr.Row():
                        s1_total_num = gr.Number(label="ğŸ“Š å¾…å¤„ç†æ–‡ä»¶æ•°", interactive=False, scale=1)
                        s1_progress = gr.Slider(0, 100, value=0, step=1, label="ğŸ“ˆ è¿›åº¦ (%)", interactive=False, scale=2)
                        
                    s1_status = gr.Textbox(label="ğŸ“‹ çŠ¶æ€", interactive=False)
                    s1_log = gr.Textbox(label="ğŸ“ è¿è¡Œæ—¥å¿—", lines=4, interactive=False, show_copy_button=True)

        # é˜¶æ®µ2ï¼šVAD å¤„ç†ï¼ˆSileroï¼‰
        with gr.Accordion("ğŸ”Š é˜¶æ®µ 2 - VAD è¯­éŸ³æ´»åŠ¨æ£€æµ‹", open=False):
            gr.Markdown("**åŠŸèƒ½ï¼š** ä½¿ç”¨ Silero VAD æ£€æµ‹å¹¶åˆ†å‰²è¯­éŸ³ç‰‡æ®µï¼Œå»é™¤é™éŸ³éƒ¨åˆ†")
            
            with gr.Group():
                with gr.Column():
                    with gr.Row():
                        s2_input_dir = gr.Textbox(label="ğŸ“ è¾“å…¥ç›®å½•", placeholder="é»˜è®¤è¡”æ¥é˜¶æ®µ1è¾“å‡º", scale=3)
                        s2_auto_sync = gr.Checkbox(value=True, label="ğŸ”„ è‡ªåŠ¨åŒæ­¥è¾“å‡ºè·¯å¾„", info="æ·»åŠ _vadåç¼€", scale=1)
                        s2_output_dir = gr.Textbox(label="ğŸ“‚ è¾“å‡ºç›®å½•", placeholder="è‡ªåŠ¨åŒæ­¥æˆ–æ‰‹åŠ¨å¡«å†™", scale=3)
                        
                    with gr.Accordion("âš™ï¸ VAD å‚æ•°è®¾ç½®", open=False):
                        with gr.Row():
                            s2_threshold = gr.Slider(0.0, 1.0, value=0.5, step=0.01, label="ğŸ¯ ç½®ä¿¡åº¦é˜ˆå€¼", info="è¶Šé«˜è¶Šä¸¥æ ¼")
                            s2_min_speech_ms = gr.Number(value=250, label="ğŸ—£ï¸ æœ€çŸ­è¯­éŸ³ (ms)")
                            s2_min_silence_ms = gr.Number(value=200, label="ğŸ”‡ æœ€çŸ­é™éŸ³ (ms)")
                            s2_pad_ms = gr.Number(value=30, label="ğŸ”§ å‰åå¡«å…… (ms)")
                        with gr.Row():
                            s2_min_seg = gr.Number(value=0.5, label="â±ï¸ æœ€çŸ­ç‰‡æ®µ (s)")
                            s2_max_seg = gr.Number(value=30, label="â° æœ€é•¿ç‰‡æ®µ (s)")
                            
                    with gr.Row():
                        s2_preview_btn = gr.Button("ğŸ‘€ é¢„è§ˆ", variant="secondary", scale=1)
                        s2_start_btn = gr.Button("â–¶ï¸ å¼€å§‹å¤„ç†", variant="primary", scale=1)
                        
                    with gr.Row():
                        s2_progress = gr.Slider(0, 100, value=0, step=1, label="ğŸ“ˆ è¿›åº¦ (%)", interactive=False)
                        
                    s2_status = gr.Textbox(label="ğŸ“‹ çŠ¶æ€", interactive=False)
                    s2_log = gr.Textbox(label="ğŸ“ è¿è¡Œæ—¥å¿—", lines=4, interactive=False, show_copy_button=True)

        # é˜¶æ®µ3ï¼šASR å¤„ç†
        with gr.Accordion("ğŸ™ï¸ é˜¶æ®µ 3 - ASR è¯­éŸ³è¯†åˆ«è½¬å½•", open=False):
            gr.Markdown("**åŠŸèƒ½ï¼š** ä½¿ç”¨è¯­éŸ³è¯†åˆ«æŠ€æœ¯å°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡æœ¬ï¼Œç”Ÿæˆè®­ç»ƒæ•°æ®é›†")
            
            with gr.Group():
                with gr.Column():
                    with gr.Row():
                        s3_input_dir = gr.Textbox(label="ğŸ“ è¾“å…¥ç›®å½•", placeholder="é»˜è®¤è¡”æ¥é˜¶æ®µ2è¾“å‡º", scale=3)
                        s3_auto_sync = gr.Checkbox(value=True, label="ğŸ”„ è‡ªåŠ¨åŒæ­¥è¾“å‡ºè·¯å¾„", info="æ·»åŠ _asråç¼€", scale=1)
                        s3_output_dir = gr.Textbox(label="ğŸ“‚ è¾“å‡ºç›®å½•", placeholder="è‡ªåŠ¨åŒæ­¥æˆ–æ‰‹åŠ¨å¡«å†™", scale=3)
                        
                    with gr.Accordion("âš™ï¸ è®¡ç®—èµ„æºè®¾ç½®", open=False):
                        with gr.Row():
                            s3_device = gr.Dropdown(
                                choices=["è‡ªåŠ¨", "CPU", "GPU"], 
                                value=("GPU" if device_default=="GPU" else "CPU"), 
                                label="ğŸ’» è®¡ç®—è®¾å¤‡"
                            )
                            s3_processes = gr.Number(value=proc_default, label="ğŸ”„ å¹¶è¡Œè¿›ç¨‹æ•°")
                            s3_detect_btn = gr.Button("ğŸ”„ åˆ·æ–°è®¾å¤‡æ£€æµ‹", variant="secondary", size="sm")
                        s3_device_info = gr.Textbox(value=device_detail, label="â„¹ï¸ è®¾å¤‡æ£€æµ‹ä¿¡æ¯", interactive=False)
                        
                    with gr.Row():
                        s3_preview_btn = gr.Button("ğŸ‘€ é¢„è§ˆ", variant="secondary", scale=1)
                        s3_start_btn = gr.Button("â–¶ï¸ å¼€å§‹å¤„ç†", variant="primary", scale=1)
                        
                    with gr.Row():
                        s3_progress = gr.Slider(0, 100, value=0, step=1, label="ğŸ“ˆ è¿›åº¦ (%)", interactive=False)
                        
                    s3_status = gr.Textbox(label="ğŸ“‹ çŠ¶æ€", interactive=False)
                    s3_log = gr.Textbox(label="ğŸ“ è¿è¡Œæ—¥å¿—", lines=4, interactive=False, show_copy_button=True)

        # é˜¶æ®µ4ï¼šæ•°æ®é›†åˆå¹¶ï¼ˆå¯é€‰ï¼‰
        with gr.Accordion("ğŸ§© é˜¶æ®µ 4 - æ•°æ®é›†åˆå¹¶ (å¯é€‰)", open=False):
            gr.Markdown("**åŠŸèƒ½ï¼š** å°†å¤šä¸ªå‰é¢é˜¶æ®µç”Ÿæˆçš„æ•°æ®é›†ç›®å½•åˆå¹¶ä¸ºä¸€ä¸ªæ–°çš„ HuggingFace æ•°æ®é›†ã€‚è¾“å…¥å¤šä¸ªç›®å½•æ—¶ä½¿ç”¨è‹±æ–‡é€—å·åˆ†éš”ã€‚")
            with gr.Group():
                with gr.Column():
                    with gr.Row():
                        s4_input_dirs = gr.Textbox(label="ğŸ“ è¾“å…¥æ•°æ®é›†ç›®å½•ï¼ˆé€—å·åˆ†éš”ï¼‰", placeholder="/path/to/ds1,/path/to/ds2,...", scale=3)
                        s4_output_dir = gr.Textbox(label="ğŸ“‚ åˆå¹¶è¾“å‡ºç›®å½•", placeholder="/path/to/merged_dataset", scale=3)
                    with gr.Row():
                        s4_preview_btn = gr.Button("ğŸ‘€ é¢„è§ˆ", variant="secondary", scale=1)
                        s4_start_btn = gr.Button("â–¶ï¸ å¼€å§‹åˆå¹¶", variant="primary", scale=1)
                    with gr.Row():
                        s4_progress = gr.Slider(0, 100, value=0, step=1, label="ğŸ“ˆ è¿›åº¦ (%)", interactive=False)
                    s4_status = gr.Textbox(label="ğŸ“‹ çŠ¶æ€", interactive=False)
                    s4_log = gr.Textbox(label="ğŸ“ åˆå¹¶æ—¥å¿—", lines=6, interactive=False, show_copy_button=True)

        gr.Markdown("""
        ---
        
        ## ğŸ’¡ ä½¿ç”¨æç¤º
        
        - **é˜¶æ®µé¡ºåºä¸å¯é¢ å€’**ï¼šæ¯ä¸ªé˜¶æ®µéƒ½ä¾èµ–å‰ä¸€é˜¶æ®µçš„è¾“å‡º
        - **GPU åŠ é€Ÿ**ï¼šé˜¶æ®µ3æ”¯æŒGPUåŠ é€Ÿï¼Œå¯æ˜¾è‘—æå‡å¤„ç†é€Ÿåº¦
        - **ç›‘æ§è¿›åº¦**ï¼šæ¯ä¸ªé˜¶æ®µéƒ½æœ‰å®æ—¶è¿›åº¦æ˜¾ç¤ºå’Œè¯¦ç»†æ—¥å¿—
        - **å¯é€‰åˆå¹¶**ï¼šé˜¶æ®µ4å¯å°†å¤šä¸ªé˜¶æ®µäº§å‡ºçš„æ•°æ®é›†è¿›è¡Œåˆå¹¶
        
        âš ï¸ **æ³¨æ„**ï¼šå¤„ç†å¤§é‡æ–‡ä»¶æ—¶è¯·ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´å’Œè®¡ç®—èµ„æº
        """)

        # éšè—çš„çŠ¶æ€å˜é‡ï¼Œç”¨äºå•ç‹¬è¿è¡Œé˜¶æ®µæ—¶ä¼ é€’link_enabled=False
        link_disabled_state = gr.State(value=False)

        # äº‹ä»¶ç»‘å®šï¼ˆé¢„å¤„ç†ï¼‰
        # é˜¶æ®µ1ï¼šè‡ªåŠ¨åŒæ­¥è¾“å‡ºã€é“¾åˆ°é˜¶æ®µ2è¾“å…¥
        s1_input_dir.change(
            fn=lambda d, a: _sync_output_dir(d, a, "_resample"),
            inputs=[s1_input_dir, s1_auto_sync],
            outputs=s1_output_dir,
        )
        s1_auto_sync.change(
            fn=lambda a, d: _sync_output_dir(d, a, "_resample"),
            inputs=[s1_auto_sync, s1_input_dir],
            outputs=s1_output_dir,
        )

        # é˜¶æ®µ2ï¼šè‡ªåŠ¨åŒæ­¥è¾“å‡ºã€é“¾åˆ°é˜¶æ®µ3è¾“å…¥
        s2_input_dir.change(
            fn=lambda d, a: _sync_output_dir(d, a, "_vad"),
            inputs=[s2_input_dir, s2_auto_sync],
            outputs=s2_output_dir,
        )
        s2_auto_sync.change(
            fn=lambda a, d: _sync_output_dir(d, a, "_vad"),
            inputs=[s2_auto_sync, s2_input_dir],
            outputs=s2_output_dir,
        )

        # é˜¶æ®µ3ï¼šè‡ªåŠ¨åŒæ­¥è¾“å‡º
        s3_input_dir.change(
            fn=lambda d, a: _sync_output_dir(d, a, "_asr"),
            inputs=[s3_input_dir, s3_auto_sync],
            outputs=s3_output_dir,
        )
        s3_auto_sync.change(
            fn=lambda a, d: _sync_output_dir(d, a, "_asr"),
            inputs=[s3_auto_sync, s3_input_dir],
            outputs=s3_output_dir,
        )

        # é˜¶æ®µ1ï¼šé¢„è§ˆä¸å¼€å§‹å¤„ç†
        s1_preview_btn.click(
            fn=preview_stage1,
            inputs=[s1_input_dir, s1_output_dir],
            outputs=[s1_preview_df, s1_total_num, s1_status],
        )
        s1_start_btn.click(
            fn=run_stage1,
            inputs=[s1_input_dir, s1_output_dir, s1_sr, s1_overwrite],
            outputs=[s1_progress, s1_status, s1_log],
        )

        # é˜¶æ®µ2ï¼šé¢„è§ˆä¸å¼€å§‹å¤„ç†
        s2_preview_btn.click(
            fn=preview_stage2,
            inputs=[s2_input_dir, s2_output_dir],
            outputs=s2_status,
        )
        s2_start_btn.click(
            fn=run_stage2,
            inputs=[s2_input_dir, s2_output_dir, s2_threshold, s2_min_speech_ms, s2_min_silence_ms, s2_pad_ms, s2_min_seg, s2_max_seg, link_disabled_state],
            outputs=[s2_progress, s2_status, s2_log, s3_input_dir],
        )

        # é˜¶æ®µ3ï¼šé¢„è§ˆä¸å¼€å§‹å¤„ç†
        s3_preview_btn.click(
            fn=preview_stage3,
            inputs=[s3_input_dir, s3_output_dir],
            outputs=s3_status,
        )
        s3_start_btn.click(
            fn=run_stage3,
            inputs=[s3_input_dir, s3_output_dir, s3_device, s3_processes],
            outputs=[s3_progress, s3_status, s3_log],
        )

        # é˜¶æ®µ3ï¼šåˆ·æ–°è®¾å¤‡
        s3_detect_btn.click(
            fn=_refresh_device_triplet,
            inputs=[],
            outputs=[s3_device_info, s3_processes, s3_device],
        )

        # é˜¶æ®µ4ï¼šé¢„è§ˆä¸å¼€å§‹åˆå¹¶
        s4_preview_btn.click(
            fn=preview_stage4,
            inputs=[s4_input_dirs, s4_output_dir],
            outputs=s4_status,
        )
        s4_start_btn.click(
            fn=run_stage4_merge,
            inputs=[s4_input_dirs, s4_output_dir],
            outputs=[s4_progress, s4_status, s4_log],
        )
