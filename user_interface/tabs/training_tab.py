import os, gradio as gr
import json
import time
import re
from typing import Dict, Any, Optional, List, Tuple
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from pathlib import Path
import threading
import logging

# å¯¼å…¥APIå®¢æˆ·ç«¯
from user_interface.utils.api_client import api_client

logger = logging.getLogger(__name__)

# å…¨å±€çŠ¶æ€ç®¡ç†
class TrainingState:
    def __init__(self):
        self.current_training_id: Optional[str] = None
        self.is_training: bool = False
        self.log_update_timer = None
        # å›¾è¡¨ç¼“å­˜ç›¸å…³
        self.last_plot_update: float = 0
        self.plot_cache_duration: float = 10.0  # ç¼“å­˜10ç§’
        self.cached_plot_path: Optional[str] = None
        self.last_log_size: int = 0  # è®°å½•ä¸Šæ¬¡æ—¥å¿—æ–‡ä»¶å¤§å°
        self.plot_update_interval: float = 5.0  # å›¾è¡¨æ›´æ–°é—´éš”ï¼ˆç§’ï¼‰
        # æ—¥å¿—æ˜¾ç¤ºç¼“å­˜
        self.cached_log_text: str = "ç­‰å¾…å¼€å§‹è®­ç»ƒ..."
        self.last_log_update: float = 0
        self.log_cache_duration: float = 2.0  # æ—¥å¿—ç¼“å­˜2ç§’
        self.last_displayed_log_count: int = 0  # ä¸Šæ¬¡æ˜¾ç¤ºçš„æ—¥å¿—è¡Œæ•°
        
training_state = TrainingState()

def load_training_config():
    """åŠ è½½è®­ç»ƒé…ç½®"""
    default_config = {
        "batch_size": 32,
        "learning_rate": 0.001,
        "epochs": 100,
        "save_interval": 10,
        "validation_split": 0.1,
        "optimizer": "Adam",
        "scheduler": "CosineAnnealingLR"
    }
    return default_config

def save_training_config(config_dict: Dict[str, Any]):
    """ä¿å­˜è®­ç»ƒé…ç½®"""
    config_path = "/tmp/training_config.json"
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config_dict, f, indent=2, ensure_ascii=False)
    return f"é…ç½®å·²ä¿å­˜åˆ°: {config_path}"

def start_training(
    dataset_path: str, 
    model_type: str,
    model_checkpoint: str,
    tokenizer_path: str,
    output_dir: str,
    batch_size: int,
    learning_rate: float,
    epochs: int,
    save_interval: int,
    validation_split: float,
    optimizer: str,
    scheduler: str,
    use_auto_split: bool,
    enable_lora: bool,
    precision_choice: str
):
    """å¯åŠ¨è®­ç»ƒä»»åŠ¡"""
    global training_state
    
    if training_state.is_training:
        return "âš ï¸ å·²æœ‰è®­ç»ƒä»»åŠ¡åœ¨è¿è¡Œä¸­ï¼Œè¯·å…ˆåœæ­¢å½“å‰è®­ç»ƒ"
    
    if not dataset_path:
        return "âŒ è¯·å…ˆé€‰æ‹©æ•°æ®é›†æ–‡ä»¶"
    
    try:
        # æ ¹æ®ç²¾åº¦é€‰æ‹©è®¾ç½®å‚æ•°ï¼Œç¡®ä¿åªæœ‰ä¸€ä¸ªä¸ºtrue
        use_fp16 = (precision_choice == "fp16")
        use_bf16 = (precision_choice == "bf16")
        
        # æ„å»ºè®­ç»ƒé…ç½®
        config = {
            "model_type": model_type,
            "model_checkpoint": model_checkpoint,
            "tokenizer_path": tokenizer_path,
            "train_data": dataset_path,
            "output_dir": output_dir,
            "batch_size": batch_size,
            "learning_rate": learning_rate,
            "epochs": epochs,
            "save_steps": save_interval * 100,  # è½¬æ¢ä¸ºæ­¥æ•°
            "auto_val_split": use_auto_split,
            "val_split_ratio": validation_split,
            "use_fp16": use_fp16,
            "use_bf16": use_bf16,
            "enable_lora": enable_lora
        }
        
        # è®°å½•è¯¦ç»†çš„å‚æ•°ä¿¡æ¯ç”¨äºè°ƒè¯•
        logger.info("=" * 50)
        logger.info("ğŸš€ å‡†å¤‡å¯åŠ¨è®­ç»ƒä»»åŠ¡")
        logger.info(f"ç²¾åº¦é€‰æ‹©: {precision_choice}")
        logger.info(f"use_fp16: {use_fp16}")
        logger.info(f"use_bf16: {use_bf16}")
        logger.info("è®­ç»ƒé…ç½®å‚æ•°:")
        for key, value in config.items():
            logger.info(f"  {key}: {value}")
        logger.info("=" * 50)
        
        # å¦‚æœä¸ä½¿ç”¨è‡ªåŠ¨åˆ†å‰²ï¼Œéœ€è¦æ‰‹åŠ¨æŒ‡å®šéªŒè¯é›†è·¯å¾„
        if not use_auto_split:
            # å‡è®¾éªŒè¯é›†åœ¨è®­ç»ƒé›†åŒä¸€ç›®å½•ä¸‹çš„valå­ç›®å½•
            train_path = Path(dataset_path)
            val_path = train_path.parent / "val" / train_path.name
            if val_path.exists():
                config["cv_data"] = str(val_path)
            else:
                config["auto_val_split"] = True  # å¦‚æœæ²¡æœ‰éªŒè¯é›†ï¼Œè‡ªåŠ¨å¯ç”¨åˆ†å‰²
        
        # è°ƒç”¨APIå¯åŠ¨è®­ç»ƒ
        result = api_client.start_training(config)
        
        if result.get("success"):
            training_state.current_training_id = result["data"]["training_id"]
            training_state.is_training = True
            
            # é‡ç½®æ—¥å¿—å’Œå›¾è¡¨ç¼“å­˜
            training_state.cached_log_text = "æ­£åœ¨å¯åŠ¨è®­ç»ƒ..."
            training_state.last_log_update = 0
            training_state.last_displayed_log_count = 0
            training_state.last_log_size = 0
            training_state.last_plot_update = 0
            if training_state.cached_plot_path and os.path.exists(training_state.cached_plot_path):
                try:
                    os.remove(training_state.cached_plot_path)
                except:
                    pass
            training_state.cached_plot_path = None
            
            return f"âœ… è®­ç»ƒä»»åŠ¡å·²å¯åŠ¨\nè®­ç»ƒID: {training_state.current_training_id}\nPID: {result['data']['pid']}\nçŠ¶æ€: {result['data']['status']}"
        else:
            return f"âŒ è®­ç»ƒå¯åŠ¨å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}"
            
    except Exception as e:
        logger.error(f"å¯åŠ¨è®­ç»ƒå¤±è´¥: {e}")
        return f"âŒ è®­ç»ƒå¯åŠ¨å¤±è´¥: {str(e)}"

def stop_training():
    """åœæ­¢è®­ç»ƒ"""
    global training_state
    
    if not training_state.is_training or not training_state.current_training_id:
        return "âš ï¸ å½“å‰æ²¡æœ‰è¿è¡Œä¸­çš„è®­ç»ƒä»»åŠ¡"
    
    try:
        result = api_client.stop_training(training_state.current_training_id)
        
        if result.get("success"):
            training_state.is_training = False
            training_state.current_training_id = None
            return f"ğŸ›‘ è®­ç»ƒå·²åœæ­¢: {result['message']}"
        else:
            return f"âŒ åœæ­¢è®­ç»ƒå¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}"
            
    except Exception as e:
        logger.error(f"åœæ­¢è®­ç»ƒå¤±è´¥: {e}")
        return f"âŒ åœæ­¢è®­ç»ƒå¤±è´¥: {str(e)}"

def get_training_logs():
    """è·å–è®­ç»ƒæ—¥å¿—ï¼Œå¸¦ç¨³å®šçš„ç¼“å­˜æœºåˆ¶"""
    global training_state
    
    current_time = time.time()
    
    if not training_state.current_training_id:
        training_state.cached_log_text = "æš‚æ— è®­ç»ƒä»»åŠ¡"
        return training_state.cached_log_text
    
    # æ£€æŸ¥ç¼“å­˜æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
    time_since_last_update = current_time - training_state.last_log_update
    if time_since_last_update < training_state.log_cache_duration:
        return training_state.cached_log_text
    
    try:
        result = api_client.get_training_status(training_state.current_training_id)
        
        if result.get("success"):
            data = result["data"]
            status = data["status"]
            logs = data.get("logs", [])
            
            # æ›´æ–°è®­ç»ƒçŠ¶æ€
            if status in ["completed", "failed", "stopped"]:
                training_state.is_training = False
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„æ—¥å¿—å†…å®¹
            current_log_count = len(logs)
            if current_log_count == training_state.last_displayed_log_count and time_since_last_update < 5.0:
                # å¦‚æœæ—¥å¿—è¡Œæ•°æ²¡å˜ä¸”è·ç¦»ä¸Šæ¬¡æ›´æ–°ä¸åˆ°5ç§’ï¼Œè¿”å›ç¼“å­˜
                return training_state.cached_log_text
            
            # æ›´æ–°æ—¥å¿—è®¡æ•°
            training_state.last_displayed_log_count = current_log_count
            
            # æ„å»ºç¨³å®šçš„æ—¥å¿—å¤´éƒ¨ä¿¡æ¯
            header_info = []
            header_info.append(f"è®­ç»ƒçŠ¶æ€: {status}")
            header_info.append(f"è®­ç»ƒID: {training_state.current_training_id}")
            
            if data.get("start_time"):
                start_time = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(data["start_time"]))
                header_info.append(f"å¼€å§‹æ—¶é—´: {start_time}")
            
            if data.get("end_time"):
                end_time = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(data["end_time"]))
                header_info.append(f"ç»“æŸæ—¶é—´: {end_time}")
            
            # æ·»åŠ è¿›åº¦ä¿¡æ¯
            if logs:
                header_info.append(f"æ—¥å¿—è¡Œæ•°: {len(logs)}")
            
            header_info.append("=" * 50)
            header_text = "\n".join(header_info) + "\n"
            
            # æ™ºèƒ½é€‰æ‹©æ˜¾ç¤ºçš„æ—¥å¿—è¡Œæ•°
            if len(logs) <= 100:
                # å°‘äº100è¡Œï¼Œå…¨éƒ¨æ˜¾ç¤º
                displayed_logs = logs
            else:
                # è¶…è¿‡100è¡Œï¼Œæ˜¾ç¤ºæœ€å80è¡Œï¼Œä½†ä¿ç•™å®Œæ•´çš„è®­ç»ƒè¿›åº¦ä¿¡æ¯
                displayed_logs = logs[-80:]
            
            # ç¡®ä¿æ˜¾ç¤ºçš„æ—¥å¿—ä»¥å®Œæ•´è¡Œç»“æŸ
            log_content = "".join(displayed_logs)
            
            # å¦‚æœæœ‰æˆªæ–­ï¼Œæ·»åŠ æç¤º
            if len(logs) > len(displayed_logs):
                truncate_info = f"\n... (çœç•¥äº†å‰{len(logs) - len(displayed_logs)}è¡Œæ—¥å¿—) ...\n\n"
                log_content = truncate_info + log_content
            
            # æ„å»ºæœ€ç»ˆçš„æ—¥å¿—æ–‡æœ¬
            training_state.cached_log_text = header_text + log_content
            training_state.last_log_update = current_time
            
            return training_state.cached_log_text
        else:
            error_msg = f"è·å–æ—¥å¿—å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}"
            training_state.cached_log_text = error_msg
            return error_msg
            
    except Exception as e:
        logger.error(f"è·å–è®­ç»ƒæ—¥å¿—å¤±è´¥: {e}")
        error_msg = f"è·å–æ—¥å¿—å¤±è´¥: {str(e)}"
        training_state.cached_log_text = error_msg
        return error_msg

def parse_training_logs(log_file_path: str) -> Dict[str, List[float]]:
    """è§£æè®­ç»ƒæ—¥å¿—ï¼Œæå–è®­ç»ƒæŒ‡æ ‡"""
    metrics = {
        'steps': [],
        'loss': [],
        'grad_norm': [],
        'learning_rate': [],
        'epoch': []
    }
    
    try:
        if not os.path.exists(log_file_path):
            logger.warning(f"æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file_path}")
            return metrics
        
        with open(log_file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        step = 0
        for line in lines:
            # åŒ¹é…è®­ç»ƒæ—¥å¿—ä¸­çš„æŒ‡æ ‡ä¿¡æ¯
            # ç¤ºä¾‹æ ¼å¼: {'loss': 5.2719, 'grad_norm': 2.815345287322998, 'learning_rate': 9.891681109185442e-05, 'epoch': 0.02}
            if line.strip().startswith('{') and 'loss' in line:
                try:
                    # å°è¯•ç›´æ¥ä½¿ç”¨evalè§£æå­—å…¸ï¼ˆæ›´å®‰å…¨çš„æ–¹æ³•ï¼‰
                    line_clean = line.strip()
                    if line_clean.endswith('\n'):
                        line_clean = line_clean[:-1]
                    
                    # å°è¯•è§£æä¸ºå­—å…¸
                    try:
                        import ast
                        metrics_dict = ast.literal_eval(line_clean)
                        if isinstance(metrics_dict, dict) and 'loss' in metrics_dict:
                            step += 1
                            metrics['steps'].append(step)
                            metrics['loss'].append(float(metrics_dict['loss']))
                            metrics['grad_norm'].append(float(metrics_dict.get('grad_norm', 0)))
                            metrics['learning_rate'].append(float(metrics_dict.get('learning_rate', 0)))
                            metrics['epoch'].append(float(metrics_dict.get('epoch', 0)))
                    except (ValueError, SyntaxError):
                        # å¦‚æœast.literal_evalå¤±è´¥ï¼Œå›åˆ°æ­£åˆ™è¡¨è¾¾å¼æ–¹æ³•
                        loss_match = re.search(r"'loss':\s*([\d\.-eE]+)", line)
                        grad_norm_match = re.search(r"'grad_norm':\s*([\d\.-eE]+)", line)
                        lr_match = re.search(r"'learning_rate':\s*([\d\.-eE]+)", line)
                        epoch_match = re.search(r"'epoch':\s*([\d\.-eE]+)", line)
                        
                        if loss_match:
                            step += 1
                            metrics['steps'].append(step)
                            metrics['loss'].append(float(loss_match.group(1)))
                            
                            metrics['grad_norm'].append(
                                float(grad_norm_match.group(1)) if grad_norm_match 
                                else (metrics['grad_norm'][-1] if metrics['grad_norm'] else 0)
                            )
                            metrics['learning_rate'].append(
                                float(lr_match.group(1)) if lr_match 
                                else (metrics['learning_rate'][-1] if metrics['learning_rate'] else 0)
                            )
                            metrics['epoch'].append(
                                float(epoch_match.group(1)) if epoch_match 
                                else (metrics['epoch'][-1] if metrics['epoch'] else 0)
                            )
                
                except (ValueError, AttributeError) as e:
                    logger.debug(f"è§£ææ—¥å¿—è¡Œå¤±è´¥: {line.strip()}, é”™è¯¯: {e}")
                    continue
        
        logger.info(f"ä»æ—¥å¿—æ–‡ä»¶è§£æå‡º {len(metrics['loss'])} ä¸ªè®­ç»ƒæ­¥éª¤çš„æ•°æ®")
        
    except Exception as e:
        logger.error(f"è§£æè®­ç»ƒæ—¥å¿—å¤±è´¥: {e}")
    
    return metrics

def generate_training_plot(force_update: bool = False):
    """ç”Ÿæˆè®­ç»ƒæ›²çº¿å›¾ï¼Œå¸¦ç¼“å­˜å’Œæ™ºèƒ½åˆ·æ–°"""
    global training_state
    
    current_time = time.time()
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆç¼“å­˜æœºåˆ¶ï¼‰
    if not force_update and training_state.cached_plot_path and os.path.exists(training_state.cached_plot_path):
        time_since_last_update = current_time - training_state.last_plot_update
        if time_since_last_update < training_state.plot_cache_duration:
            logger.debug(f"ä½¿ç”¨ç¼“å­˜çš„è®­ç»ƒå›¾è¡¨ï¼Œè·ç¦»ä¸Šæ¬¡æ›´æ–° {time_since_last_update:.1f} ç§’")
            return training_state.cached_plot_path
    
    if not training_state.current_training_id:
        # å¦‚æœæ²¡æœ‰å½“å‰è®­ç»ƒï¼Œç”Ÿæˆç¤ºä¾‹å›¾è¡¨
        return _generate_sample_plot()
    
    try:
        # è·å–å½“å‰è®­ç»ƒçš„æ—¥å¿—æ–‡ä»¶è·¯å¾„
        result = api_client.get_training_status(training_state.current_training_id)
        
        if not result.get("success"):
            logger.warning("æ— æ³•è·å–è®­ç»ƒçŠ¶æ€ï¼Œä½¿ç”¨ç¤ºä¾‹å›¾è¡¨")
            return _generate_sample_plot()
        
        training_data = result["data"]
        log_file = training_data.get("log_file")
        
        if not log_file:
            logger.debug("è®­ç»ƒä»»åŠ¡æš‚æ— æ—¥å¿—æ–‡ä»¶è·¯å¾„")
            return None  # è¿”å›Noneè¡¨ç¤ºæš‚æ— æ•°æ®
        
        if not os.path.exists(log_file):
            logger.debug(f"æ—¥å¿—æ–‡ä»¶å°šä¸å­˜åœ¨: {log_file}ï¼Œå¯èƒ½è®­ç»ƒåˆšå¼€å§‹")
            return None  # è¿”å›Noneè¡¨ç¤ºæš‚æ— æ•°æ®
        
        # æ£€æŸ¥æ—¥å¿—æ–‡ä»¶æ˜¯å¦æœ‰æ›´æ–°ï¼ˆé€šè¿‡æ–‡ä»¶å¤§å°åˆ¤æ–­ï¼‰
        current_log_size = os.path.getsize(log_file)
        if not force_update and current_log_size == training_state.last_log_size:
            # æ—¥å¿—æ–‡ä»¶æ²¡æœ‰æ›´æ–°ï¼Œä¸”ç¼“å­˜æœªè¿‡æœŸ
            if training_state.cached_plot_path and os.path.exists(training_state.cached_plot_path):
                time_since_last_update = current_time - training_state.last_plot_update
                if time_since_last_update < training_state.plot_update_interval:
                    logger.debug("æ—¥å¿—æ–‡ä»¶æ— æ›´æ–°ï¼Œä½¿ç”¨ç¼“å­˜å›¾è¡¨")
                    return training_state.cached_plot_path
        
        # æ›´æ–°æ—¥å¿—æ–‡ä»¶å¤§å°è®°å½•
        training_state.last_log_size = current_log_size
        
        # è§£ææ—¥å¿—è·å–è®­ç»ƒæ•°æ®
        metrics = parse_training_logs(log_file)
        
        if not metrics['loss']:
            logger.warning("æ—¥å¿—ä¸­æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒæ•°æ®ï¼Œä½¿ç”¨ç¤ºä¾‹å›¾è¡¨")
            return _generate_sample_plot()
        
        logger.info(f"ç”Ÿæˆè®­ç»ƒå›¾è¡¨ï¼ŒåŒ…å« {len(metrics['loss'])} ä¸ªæ•°æ®ç‚¹")
        
        # åˆ›å»ºå¤šå­å›¾
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'è®­ç»ƒè¿›åº¦ - {training_state.current_training_id}', fontsize=16)
        
        steps = metrics['steps']
        
        # å­å›¾1: Lossæ›²çº¿
        ax1.plot(steps, metrics['loss'], color='blue', linewidth=2, marker='o', markersize=3, alpha=0.7)
        ax1.set_title('è®­ç»ƒæŸå¤± (Loss)', fontsize=12)
        ax1.set_xlabel('æ­¥æ•° (Steps)')
        ax1.set_ylabel('Loss')
        ax1.grid(True, alpha=0.3)
        # æ·»åŠ æœ€æ–°å€¼æ ‡æ³¨
        if metrics['loss']:
            latest_loss = metrics['loss'][-1]
            ax1.annotate(f'æœ€æ–°: {latest_loss:.4f}', 
                        xy=(steps[-1], latest_loss), xytext=(0.7, 0.9),
                        textcoords='axes fraction', fontsize=10,
                        bbox=dict(boxstyle='round,pad=0.3', facecolor='lightblue', alpha=0.7))
        
        # å­å›¾2: æ¢¯åº¦èŒƒæ•°
        if metrics['grad_norm']:
            ax2.plot(steps, metrics['grad_norm'], color='orange', linewidth=2, marker='s', markersize=3, alpha=0.7)
            ax2.set_title('æ¢¯åº¦èŒƒæ•° (Gradient Norm)', fontsize=12)
            ax2.set_xlabel('æ­¥æ•° (Steps)')
            ax2.set_ylabel('Grad Norm')
            ax2.grid(True, alpha=0.3)
            # æ·»åŠ æœ€æ–°å€¼æ ‡æ³¨
            latest_grad_norm = metrics['grad_norm'][-1]
            ax2.annotate(f'æœ€æ–°: {latest_grad_norm:.4f}', 
                        xy=(steps[-1], latest_grad_norm), xytext=(0.7, 0.9),
                        textcoords='axes fraction', fontsize=10,
                        bbox=dict(boxstyle='round,pad=0.3', facecolor='lightsalmon', alpha=0.7))
        
        # å­å›¾3: å­¦ä¹ ç‡
        if metrics['learning_rate']:
            ax3.plot(steps, metrics['learning_rate'], color='green', linewidth=2, marker='^', markersize=3, alpha=0.7)
            ax3.set_title('å­¦ä¹ ç‡ (Learning Rate)', fontsize=12)
            ax3.set_xlabel('æ­¥æ•° (Steps)')
            ax3.set_ylabel('Learning Rate')
            ax3.grid(True, alpha=0.3)
            ax3.ticklabel_format(style='scientific', axis='y', scilimits=(0,0))
            # æ·»åŠ æœ€æ–°å€¼æ ‡æ³¨
            latest_lr = metrics['learning_rate'][-1]
            ax3.annotate(f'æœ€æ–°: {latest_lr:.2e}', 
                        xy=(steps[-1], latest_lr), xytext=(0.7, 0.9),
                        textcoords='axes fraction', fontsize=10,
                        bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgreen', alpha=0.7))
        
        # å­å›¾4: Epochè¿›åº¦
        if metrics['epoch']:
            ax4.plot(steps, metrics['epoch'], color='red', linewidth=2, marker='d', markersize=3, alpha=0.7)
            ax4.set_title('è®­ç»ƒè½®æ•° (Epoch)', fontsize=12)
            ax4.set_xlabel('æ­¥æ•° (Steps)')
            ax4.set_ylabel('Epoch')
            ax4.grid(True, alpha=0.3)
            # æ·»åŠ æœ€æ–°å€¼æ ‡æ³¨
            latest_epoch = metrics['epoch'][-1]
            ax4.annotate(f'æœ€æ–°: {latest_epoch:.3f}', 
                        xy=(steps[-1], latest_epoch), xytext=(0.7, 0.9),
                        textcoords='axes fraction', fontsize=10,
                        bbox=dict(boxstyle='round,pad=0.3', facecolor='lightcoral', alpha=0.7))
        
        plt.tight_layout()
        
        # ä½¿ç”¨æ—¶é—´æˆ³ç¡®ä¿ç¼“å­˜æ–‡ä»¶å”¯ä¸€æ€§
        plot_path = f"/tmp/training_plot_{int(current_time)}.png"
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        # åˆ é™¤æ—§çš„ç¼“å­˜æ–‡ä»¶
        if training_state.cached_plot_path and os.path.exists(training_state.cached_plot_path):
            try:
                os.remove(training_state.cached_plot_path)
            except:
                pass
        
        # æ›´æ–°ç¼“å­˜
        training_state.cached_plot_path = plot_path
        training_state.last_plot_update = current_time
        
        return plot_path
    
    except Exception as e:
        logger.error(f"ç”Ÿæˆè®­ç»ƒå›¾è¡¨å¤±è´¥: {e}")
        return _generate_sample_plot()

def _generate_sample_plot():
    """ç”Ÿæˆç¤ºä¾‹è®­ç»ƒå›¾è¡¨"""
    # æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
    steps = np.arange(1, 101)
    loss = 6.0 * np.exp(-steps/50) + 0.5 + 0.1 * np.random.randn(100)
    grad_norm = 3.0 * np.exp(-steps/60) + 0.1 + 0.05 * np.random.randn(100)
    lr = 1e-4 * np.ones(100) * np.exp(-steps/200)  # è¡°å‡çš„å­¦ä¹ ç‡
    epoch = steps / 50  # å‡è®¾50æ­¥ä¸ºä¸€ä¸ªepoch
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('è®­ç»ƒè¿›åº¦ - ç¤ºä¾‹æ•°æ®', fontsize=16)
    
    ax1.plot(steps, loss, color='blue', linewidth=2)
    ax1.set_title('è®­ç»ƒæŸå¤± (Loss)', fontsize=12)
    ax1.set_xlabel('æ­¥æ•° (Steps)')
    ax1.set_ylabel('Loss')
    ax1.grid(True, alpha=0.3)
    
    ax2.plot(steps, grad_norm, color='orange', linewidth=2)
    ax2.set_title('æ¢¯åº¦èŒƒæ•° (Gradient Norm)', fontsize=12)
    ax2.set_xlabel('æ­¥æ•° (Steps)')
    ax2.set_ylabel('Grad Norm')
    ax2.grid(True, alpha=0.3)
    
    ax3.plot(steps, lr, color='green', linewidth=2)
    ax3.set_title('å­¦ä¹ ç‡ (Learning Rate)', fontsize=12)
    ax3.set_xlabel('æ­¥æ•° (Steps)')
    ax3.set_ylabel('Learning Rate')
    ax3.grid(True, alpha=0.3)
    ax3.ticklabel_format(style='scientific', axis='y', scilimits=(0,0))
    
    ax4.plot(steps, epoch, color='red', linewidth=2)
    ax4.set_title('è®­ç»ƒè½®æ•° (Epoch)', fontsize=12)
    ax4.set_xlabel('æ­¥æ•° (Steps)')
    ax4.set_ylabel('Epoch')
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    plot_path = "/tmp/training_plot.png"
    plt.savefig(plot_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    return plot_path

def get_model_list():
    """è·å–è®­ç»ƒè¾“å‡ºç›®å½•ä¸‹çš„æ¨¡å‹æ–‡ä»¶å¤¹åˆ—è¡¨"""
    try:
        # è®­ç»ƒè¾“å‡ºç›®å½• - æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œé¿å…é‡å¤æ‰«æ
        primary_output_dir = "checkpoints/training"  # ä¸»è¦è¾“å‡ºç›®å½•
        fallback_dirs = ["checkpoints", "models", "outputs", "ckpt"]  # å¤‡ç”¨ç›®å½•
        
        models = []
        processed_folders = set()  # é¿å…é‡å¤å¤„ç†ç›¸åŒçš„æ–‡ä»¶å¤¹
        
        # é¦–å…ˆæ‰«æä¸»è¦è¾“å‡ºç›®å½•
        primary_path = Path(primary_output_dir)
        if primary_path.exists():
            logger.info(f"æ­£åœ¨æ‰«æä¸»è¦è¾“å‡ºç›®å½•: {primary_path}")
            models.extend(_scan_output_directory(primary_path, processed_folders))
        
        # å¦‚æœä¸»è¦ç›®å½•æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–‡ä»¶å¤¹ï¼Œå†æ‰«æå¤‡ç”¨ç›®å½•
        if not models:
            for output_dir in fallback_dirs:
                output_path = Path(output_dir)
                if output_path.exists():
                    logger.info(f"æ­£åœ¨æ‰«æå¤‡ç”¨ç›®å½•: {output_path}")
                    models.extend(_scan_output_directory(output_path, processed_folders))
        
        # æŒ‰ä¿®æ”¹æ—¶é—´å€’åºæ’åˆ—
        models.sort(key=lambda x: x["æ—¶é—´"], reverse=True)
        
        logger.info(f"æ‰¾åˆ° {len(models)} ä¸ªæ¨¡å‹æ–‡ä»¶å¤¹")
        
        if not models:
            models = [{"æ–‡ä»¶å¤¹åç§°": "æš‚æ— è®­ç»ƒè¾“å‡º", "è·¯å¾„": "è¯·å…ˆè¿›è¡Œæ¨¡å‹è®­ç»ƒ", "å†…å®¹": "", "å¤§å°": "", "æ—¶é—´": ""}]
        
        return pd.DataFrame(models)
        
    except Exception as e:
        logger.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        return pd.DataFrame([{"æ–‡ä»¶å¤¹åç§°": "è·å–å¤±è´¥", "è·¯å¾„": f"é”™è¯¯: {str(e)}", "å†…å®¹": "", "å¤§å°": "", "æ—¶é—´": ""}])

def _scan_output_directory(output_path: Path, processed_folders: set):
    """æ‰«æå•ä¸ªè¾“å‡ºç›®å½•ï¼Œè¿”å›æ‰¾åˆ°çš„æ¨¡å‹æ–‡ä»¶å¤¹åˆ—è¡¨"""
    models = []
    
    # éå†å­æ–‡ä»¶å¤¹
    for folder_path in output_path.iterdir():
        if folder_path.is_dir():
            folder_name = folder_path.name
            
            # è·³è¿‡æ—¥å¿—ç›®å½•å’Œå·²å¤„ç†çš„æ–‡ä»¶å¤¹
            if folder_name == "runs" or folder_name in processed_folders:
                continue
                
            # è·³è¿‡åµŒå¥—çš„è¾“å‡ºç›®å½•æœ¬èº«ï¼ˆé¿å…æ˜¾ç¤ºcheckpoints/trainingè¿™æ ·çš„è·¯å¾„ï¼‰
            if folder_name in ["training", "checkpoints", "models", "outputs", "ckpt"]:
                continue
                
            try:
                processed_folders.add(folder_name)
                stat = folder_path.stat()
                mod_time = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(stat.st_mtime))
                
                # è®¡ç®—æ–‡ä»¶å¤¹å¤§å°ï¼ˆåŒ…å«çš„æ¨¡å‹æ–‡ä»¶ï¼‰
                total_size = 0
                model_count = 0
                model_files = []
                
                # æ‰«ææ¨¡å‹æ–‡ä»¶
                for ext in ["*.pt", "*.pth", "*.ckpt", "*.bin", "*.safetensors"]:
                    for model_file in folder_path.rglob(ext):
                        if model_file.is_file():
                            total_size += model_file.stat().st_size
                            model_count += 1
                            model_files.append(model_file.name)
                
                size_mb = total_size / (1024 * 1024)
                
                # æ˜¾ç¤ºç›¸å¯¹è·¯å¾„
                relative_path = str(folder_path.relative_to(Path.cwd())) if folder_path.is_absolute() else str(folder_path)
                
                # æ„å»ºæè¿°ä¿¡æ¯
                description = f"{model_count}ä¸ªæ¨¡å‹æ–‡ä»¶" if model_count > 0 else "ç©ºæ–‡ä»¶å¤¹"
                if model_files:
                    # åªæ˜¾ç¤ºå‰3ä¸ªæ–‡ä»¶åï¼Œå¦‚æœæ›´å¤šåˆ™æ˜¾ç¤ºçœç•¥å·
                    file_names = ", ".join(sorted(set(model_files))[:3])  # å»é‡å¹¶æ’åº
                    if len(set(model_files)) > 3:
                        file_names += f" ç­‰{len(set(model_files))}ä¸ªæ–‡ä»¶"
                    description = file_names
                
                models.append({
                    "æ–‡ä»¶å¤¹åç§°": folder_name,
                    "è·¯å¾„": relative_path,
                    "å†…å®¹": description,
                    "å¤§å°": f"{size_mb:.1f} MB" if size_mb > 0 else "-",
                    "æ—¶é—´": mod_time
                })
                
            except Exception as e:
                logger.warning(f"Error reading model folder {folder_path}: {e}")
    
    return models

def load_model(model_name: str):
    """åŠ è½½æ¨¡å‹"""
    if not model_name:
        gr.Warning("è¯·é€‰æ‹©æ¨¡å‹")
        return "è¯·é€‰æ‹©æ¨¡å‹"
    
    return f"âœ… æ¨¡å‹ {model_name} åŠ è½½æˆåŠŸ"

def delete_model(folder_name: str):
    """åˆ é™¤æ¨¡å‹æ–‡ä»¶å¤¹"""
    if not folder_name:
        return "âš ï¸ è¯·é€‰æ‹©è¦åˆ é™¤çš„æ–‡ä»¶å¤¹", get_model_list()
    
    try:
        import shutil
        
        # ä»æ–‡ä»¶å¤¹åç§°ä¸­æå–è·¯å¾„ä¿¡æ¯
        if " (" in folder_name and ")" in folder_name:
            # æ ¼å¼: "folder_name (path/to/folder)"
            path_part = folder_name.split(" (")[1].rstrip(")")
            folder_path = Path(path_part)
        else:
            # å¦‚æœæ ¼å¼ä¸å¯¹ï¼Œå°è¯•åœ¨å„è¾“å‡ºç›®å½•ä¸­æŸ¥æ‰¾
            output_dirs = [
                "checkpoints/training", 
                "checkpoints", 
                "models", 
                "outputs",
                "ckpt"
            ]
            folder_path = None
            for output_dir in output_dirs:
                potential_path = Path(output_dir) / folder_name
                if potential_path.exists() and potential_path.is_dir():
                    folder_path = potential_path
                    break
        
        if folder_path and folder_path.exists() and folder_path.is_dir():
            # ç¡®è®¤ä¸æ˜¯é‡è¦çš„ç³»ç»Ÿæ–‡ä»¶å¤¹
            if folder_path.name in ["runs"]:
                return f"âš ï¸ ä¸å…è®¸åˆ é™¤ç³»ç»Ÿæ–‡ä»¶å¤¹: {folder_name}", get_model_list()
            
            # åˆ é™¤æ•´ä¸ªæ–‡ä»¶å¤¹
            shutil.rmtree(folder_path)
            logger.info(f"å·²åˆ é™¤æ¨¡å‹æ–‡ä»¶å¤¹: {folder_path}")
            return f"âœ… æ–‡ä»¶å¤¹ {folder_name} å·²åˆ é™¤", get_model_list()
        else:
            return f"âŒ æœªæ‰¾åˆ°æ–‡ä»¶å¤¹: {folder_name}", get_model_list()
    
    except Exception as e:
        logger.error(f"åˆ é™¤æ–‡ä»¶å¤¹å¤±è´¥: {e}")
        return f"âŒ åˆ é™¤å¤±è´¥: {str(e)}", get_model_list()

def update_batch_size_constraints(model_type: str):
    """æ ¹æ®æ¨¡å‹ç±»å‹æ›´æ–°batch_sizeé™åˆ¶"""
    if model_type == "llm":
        # LLMæ¨¡å‹å¿…é¡»ä½¿ç”¨batch_size=1
        return (
            gr.update(value=1, maximum=1, interactive=False),  # batch_size slider
            gr.update(visible=True)  # info message
        )
    else:
        # Flowæ¨¡å‹å¯ä»¥ä½¿ç”¨æ›´å¤§çš„batch_size
        return (
            gr.update(value=4, maximum=32, interactive=True),  # batch_size slider
            gr.update(visible=False)  # info message
        )

def update_precision_options(model_type: str):
    """æ ¹æ®æ¨¡å‹ç±»å‹æ›´æ–°ç²¾åº¦é€‰é¡¹å’Œæ¨è"""
    if model_type == "llm":
        # LLMæ¨¡å‹æ¨èBF16
        choices = [
            ("BF16ï¼ˆæ¨èï¼‰", "bf16"),
            ("FP16", "fp16")
        ]
        value = "bf16"
        info_text = "ğŸ’¡ **LLMæ¨¡å‹**: æ¨èä½¿ç”¨BF16ç²¾åº¦ä»¥è·å¾—æ›´å¥½çš„æ•°å€¼ç¨³å®šæ€§"
    else:
        # Flowæ¨¡å‹æ¨èFP16
        choices = [
            ("FP16ï¼ˆæ¨èï¼‰", "fp16"),
            ("BF16", "bf16")
        ]
        value = "fp16"
        info_text = "ğŸ’¡ **Flowæ¨¡å‹**: æ¨èä½¿ç”¨FP16ç²¾åº¦ä»¥èŠ‚çœæ˜¾å­˜å’Œæå‡é€Ÿåº¦"
    
    return (
        gr.update(choices=choices, value=value),  # precision_choice radio
        gr.update(value=info_text, visible=True)  # precision info message
    )

def create_training_tab():
    """åˆ›å»ºè®­ç»ƒtabç•Œé¢"""
    with gr.Tab("ğŸš€ æ¨¡å‹è®­ç»ƒ"):
        gr.Markdown("### TTS æ¨¡å‹è®­ç»ƒ")
        
        with gr.Row():
            with gr.Column(scale=1):
                # æ•°æ®é›†é€‰æ‹©
                gr.Markdown("#### 1. æ•°æ®é›†é…ç½®")
                dataset_file = gr.Textbox(
                    label="è®­ç»ƒæ•°æ®è·¯å¾„",
                    placeholder="è¾“å…¥è®­ç»ƒæ•°æ®è·¯å¾„ï¼Œå¦‚: data/processed/train_ds",
                    value="data/processed/train_ds"
                )
                
                # æ¨¡å‹é…ç½®
                gr.Markdown("#### 2. æ¨¡å‹é…ç½®")
                with gr.Group():
                    model_type = gr.Dropdown(
                        choices=["llm", "flow"],
                        value="llm",
                        label="æ¨¡å‹ç±»å‹"
                    )
                    model_checkpoint = gr.Textbox(
                        label="æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„",
                        value="jzx-ai-lab/HydraVox/llm.pt",
                        placeholder="é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„"
                    )
                    tokenizer_path = gr.Textbox(
                        label="åˆ†è¯å™¨è·¯å¾„",
                        value="jzx-ai-lab/HydraVox/speech_tokenizer",
                        placeholder="åˆ†è¯å™¨æ¨¡å‹è·¯å¾„"
                    )
                    output_dir = gr.Textbox(
                        label="è¾“å‡ºç›®å½•",
                        value="checkpoints/training",
                        placeholder="è®­ç»ƒè¾“å‡ºä¿å­˜ç›®å½•"
                    )
                
                # è®­ç»ƒå‚æ•°é…ç½®
                gr.Markdown("#### 3. è®­ç»ƒå‚æ•°")
                with gr.Group():
                    batch_size = gr.Slider(1, 32, value=1, step=1, label="æ‰¹æ¬¡å¤§å°", maximum=1, interactive=False)
                    batch_size_info = gr.Markdown("ğŸ’¡ **æ³¨æ„**: LLMæ¨¡å‹è®­ç»ƒæ—¶batch_sizeå¿…é¡»ä¸º1ï¼ŒFlowæ¨¡å‹å¯ä»¥ä½¿ç”¨æ›´å¤§çš„batch_size", visible=True)
                    learning_rate = gr.Number(value=1e-4, label="å­¦ä¹ ç‡", minimum=1e-6, maximum=1e-2)
                    epochs = gr.Slider(1, 100, value=10, step=1, label="è®­ç»ƒè½®æ•°")
                    save_interval = gr.Slider(1, 50, value=20, step=1, label="ä¿å­˜é—´éš”(è½®æ•°)")
                
                with gr.Group():
                    validation_split = gr.Slider(0.0, 0.3, value=0.05, step=0.01, label="éªŒè¯é›†æ¯”ä¾‹")
                    use_auto_split = gr.Checkbox(label="è‡ªåŠ¨åˆ’åˆ†éªŒè¯é›†", value=True)
                    
                # é«˜çº§é€‰é¡¹
                gr.Markdown("#### 4. é«˜çº§é€‰é¡¹")
                with gr.Group():
                    enable_lora = gr.Checkbox(label="å¯ç”¨LoRAå¾®è°ƒ", value=False)
                    precision_choice = gr.Radio(
                        choices=[
                            ("BF16ï¼ˆæ¨èï¼‰", "bf16"),
                            ("FP16", "fp16")
                        ],
                        value="bf16",
                        label="ç²¾åº¦è®¾ç½®"
                    )
                    precision_info = gr.Markdown("ğŸ’¡ **LLMæ¨¡å‹**: æ¨èä½¿ç”¨BF16ç²¾åº¦ä»¥è·å¾—æ›´å¥½çš„æ•°å€¼ç¨³å®šæ€§", visible=True)
                
                # æ§åˆ¶æŒ‰é’®
                gr.Markdown("#### 5. è®­ç»ƒæ§åˆ¶")
                start_btn = gr.Button("ğŸš€ å¼€å§‹è®­ç»ƒ", variant="primary")
                stop_btn = gr.Button("ğŸ›‘ åœæ­¢è®­ç»ƒ", variant="stop")
                refresh_log_btn = gr.Button("ğŸ”„ åˆ·æ–°æ—¥å¿—", variant="secondary")
                
            with gr.Column(scale=2):
                # è®­ç»ƒçŠ¶æ€
                gr.Markdown("#### è®­ç»ƒçŠ¶æ€ä¸æ—¥å¿—")
                training_status = gr.Textbox(
                    label="è®­ç»ƒæ—¥å¿—",
                    lines=15,
                    interactive=False,
                    value="ç­‰å¾…å¼€å§‹è®­ç»ƒ...",
                    max_lines=30
                )
                
                # è‡ªåŠ¨åˆ·æ–°æ—¥å¿— - å¢åŠ åˆ·æ–°é—´éš”ä»¥å‡å°‘é—ªçƒ
                log_timer = gr.Timer(value=5)  # æ¯5ç§’åˆ·æ–°æ—¥å¿—
                
                # è®­ç»ƒæ›²çº¿
                gr.Markdown("#### è®­ç»ƒæ›²çº¿")
                with gr.Row():
                    with gr.Column(scale=3):
                        training_plot = gr.Image(label="è®­ç»ƒæŒ‡æ ‡æ›²çº¿", value=_generate_sample_plot())
                    with gr.Column(scale=1):
                        gr.Markdown("**å›¾è¡¨è®¾ç½®**")
                        auto_refresh_plot = gr.Checkbox(label="è‡ªåŠ¨åˆ·æ–°å›¾è¡¨", value=True)
                        plot_refresh_interval = gr.Slider(
                            minimum=5, maximum=60, value=15, step=5,
                            label="åˆ·æ–°é—´éš”(ç§’)", interactive=True
                        )
                        with gr.Row():
                            refresh_plot_btn = gr.Button("ğŸ”„ ç«‹å³åˆ·æ–°", variant="secondary")
                            force_refresh_btn = gr.Button("âš¡ å¼ºåˆ¶åˆ·æ–°", variant="primary")
                
                # è‡ªåŠ¨åˆ·æ–°å›¾è¡¨å®šæ—¶å™¨
                plot_timer = gr.Timer(value=15)  # é»˜è®¤15ç§’åˆ·æ–°ä¸€æ¬¡å›¾è¡¨
        
        # æ¨¡å‹ç®¡ç†
        gr.Markdown("### æ¨¡å‹ç®¡ç†")
        with gr.Row():
            with gr.Column(scale=2):
                model_list = gr.Dataframe(
                    value=get_model_list(),
                    headers=["æ–‡ä»¶å¤¹åç§°", "è·¯å¾„", "å†…å®¹", "å¤§å°", "æ—¶é—´"],
                    label="è®­ç»ƒè¾“å‡ºæ–‡ä»¶å¤¹",
                    interactive=False
                )
                
            with gr.Column(scale=1):
                gr.Markdown("#### æ–‡ä»¶å¤¹æ“ä½œ")
                selected_model = gr.Textbox(label="é€‰æ‹©çš„æ–‡ä»¶å¤¹", placeholder="ç‚¹å‡»è¡¨æ ¼è¡Œé€‰æ‹©æ–‡ä»¶å¤¹")
                
                with gr.Row():
                    refresh_models_btn = gr.Button("ğŸ”„ åˆ·æ–°åˆ—è¡¨", variant="secondary")
                
                with gr.Row():
                    load_btn = gr.Button("ğŸ“‚ åŠ è½½æ–‡ä»¶å¤¹", variant="primary")
                    delete_btn = gr.Button("ğŸ—‘ï¸ åˆ é™¤æ–‡ä»¶å¤¹", variant="stop")
                
                model_status = gr.Textbox(
                    label="æ“ä½œçŠ¶æ€",
                    interactive=False
                )
        
        # è®­ç»ƒé…ç½®æ˜¾ç¤º
        gr.Markdown("### å½“å‰é…ç½®")
        config_display = gr.JSON(
            value=load_training_config(),
            label="è®­ç»ƒé…ç½®"
        )
        
        # äº‹ä»¶ç»‘å®š
        def update_config():
            return {
                "batch_size": batch_size.value,
                "learning_rate": learning_rate.value,
                "epochs": epochs.value,
                "save_interval": save_interval.value,
                "validation_split": validation_split.value,
                "optimizer": optimizer.value,
                "scheduler": scheduler.value
            }
        
        # ç»‘å®šè®­ç»ƒæ§åˆ¶äº‹ä»¶
        start_btn.click(
            fn=start_training,
            inputs=[
                dataset_file, model_type, model_checkpoint, tokenizer_path, output_dir,
                batch_size, learning_rate, epochs, save_interval, validation_split,
                gr.State("Adam"), gr.State("CosineAnnealingLR"),  # æš‚æ—¶å›ºå®šä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
                use_auto_split, enable_lora, precision_choice
            ],
            outputs=training_status
        )
        
        stop_btn.click(
            fn=stop_training,
            outputs=training_status
        )
        
        refresh_log_btn.click(
            fn=get_training_logs,
            outputs=training_status
        )
        
        # æ™ºèƒ½æ—¥å¿—åˆ·æ–° - åªåœ¨è®­ç»ƒæ—¶åˆ·æ–°
        def smart_log_refresh():
            """æ™ºèƒ½æ—¥å¿—åˆ·æ–°ï¼šåªåœ¨æœ‰è®­ç»ƒä»»åŠ¡æ—¶æ›´æ–°"""
            if training_state.current_training_id and training_state.is_training:
                return get_training_logs()
            elif training_state.current_training_id:
                # è®­ç»ƒå·²ç»“æŸä½†ä»æœ‰IDï¼Œè·å–æœ€ç»ˆæ—¥å¿—
                final_logs = get_training_logs()
                # å¦‚æœè®­ç»ƒå·²ç»“æŸï¼Œå¯ä»¥å‡å°‘åˆ·æ–°é¢‘ç‡
                if not training_state.is_training:
                    return final_logs
            return training_state.cached_log_text
        
        log_timer.tick(
            fn=smart_log_refresh,
            outputs=training_status
        )
        
        # å›¾è¡¨åˆ·æ–°äº‹ä»¶
        def update_plot_with_settings(auto_refresh_enabled):
            """æ ¹æ®è‡ªåŠ¨åˆ·æ–°è®¾ç½®æ›´æ–°å›¾è¡¨"""
            if auto_refresh_enabled and training_state.is_training:
                return generate_training_plot()
            elif not auto_refresh_enabled:
                # å¦‚æœå…³é—­è‡ªåŠ¨åˆ·æ–°ï¼Œè¿”å›å½“å‰ç¼“å­˜çš„å›¾è¡¨æˆ–ç”Ÿæˆæ–°çš„
                return generate_training_plot()
            else:
                # æ²¡æœ‰è®­ç»ƒæ—¶æ˜¾ç¤ºç¤ºä¾‹
                return _generate_sample_plot()
        
        def force_update_plot():
            """å¼ºåˆ¶åˆ·æ–°å›¾è¡¨ï¼Œå¿½ç•¥ç¼“å­˜"""
            return generate_training_plot(force_update=True)
        
        def update_plot_timer_interval(interval):
            """æ›´æ–°å›¾è¡¨å®šæ—¶å™¨é—´éš”"""
            training_state.plot_update_interval = interval
            return gr.update(value=interval)
        
        # ç«‹å³åˆ·æ–°æŒ‰é’®
        refresh_plot_btn.click(
            fn=lambda: generate_training_plot(),
            outputs=training_plot
        )
        
        # å¼ºåˆ¶åˆ·æ–°æŒ‰é’®  
        force_refresh_btn.click(
            fn=force_update_plot,
            outputs=training_plot
        )
        
        # åˆ·æ–°é—´éš”è®¾ç½®
        plot_refresh_interval.change(
            fn=update_plot_timer_interval,
            inputs=plot_refresh_interval,
            outputs=plot_timer
        )
        
        # è‡ªåŠ¨åˆ·æ–°å›¾è¡¨å®šæ—¶å™¨
        def auto_refresh_plot_handler():
            if auto_refresh_plot.value and training_state.is_training:
                return generate_training_plot()
            return None
        
        plot_timer.tick(
            fn=auto_refresh_plot_handler,
            outputs=training_plot
        )
        
        # åˆ·æ–°æ¨¡å‹åˆ—è¡¨
        refresh_models_btn.click(
            fn=get_model_list,
            outputs=model_list
        )
        
        # æ¨¡å‹è¡¨æ ¼é€‰æ‹©äº‹ä»¶
        def on_model_select(evt: gr.SelectData):
            if evt.index is not None and evt.index[0] >= 0:
                # è·å–é€‰ä¸­è¡Œçš„æ–‡ä»¶å¤¹ä¿¡æ¯
                model_data = get_model_list()
                if len(model_data) > evt.index[0]:
                    selected_name = model_data.iloc[evt.index[0]]["æ–‡ä»¶å¤¹åç§°"]
                    selected_path = model_data.iloc[evt.index[0]]["è·¯å¾„"]
                    return f"{selected_name} ({selected_path})"
            return ""
        
        model_list.select(
            fn=on_model_select,
            outputs=selected_model
        )
        
        load_btn.click(
            fn=load_model,
            inputs=selected_model,
            outputs=model_status
        )
        
        delete_btn.click(
            fn=delete_model,
            inputs=selected_model,
            outputs=[model_status, model_list]
        )
        
        # ç›‘å¬æ¨¡å‹ç±»å‹å˜åŒ–ï¼Œè‡ªåŠ¨è°ƒæ•´batch_sizeé™åˆ¶å’Œç²¾åº¦é€‰é¡¹
        def update_model_constraints(model_type_val):
            batch_updates = update_batch_size_constraints(model_type_val)
            precision_updates = update_precision_options(model_type_val)
            return batch_updates + precision_updates
        
        model_type.change(
            fn=update_model_constraints,
            inputs=model_type,
            outputs=[batch_size, batch_size_info, precision_choice, precision_info]
        )
       