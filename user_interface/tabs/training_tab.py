import os, gradio as gr
import json
import time
import re
import subprocess, sys, signal
from typing import Dict, Any, Optional, List, Tuple
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import torch
from pathlib import Path
import threading
import logging

# è®­ç»ƒè„šæœ¬è·¯å¾„å·¥å…·
from pathlib import Path

logger = logging.getLogger(__name__)

# å…¨å±€çŠ¶æ€ç®¡ç†
class TrainingState:
    def __init__(self):
        self.current_training_id: Optional[str] = None
        self.is_training: bool = False
        self.log_update_timer = None
        # å›¾è¡¨ç¼“å­˜ç›¸å…³
        self.last_plot_update: float = 0
        self.plot_cache_duration: float = 10.0  # ç¼“å­˜10ç§’
        self.cached_plot_path: Optional[str] = None
        self.last_log_size: int = 0  # è®°å½•ä¸Šæ¬¡æ—¥å¿—æ–‡ä»¶å¤§å°
        self.plot_update_interval: float = 5.0  # å›¾è¡¨æ›´æ–°é—´éš”ï¼ˆç§’ï¼‰
        # æ—¥å¿—æ˜¾ç¤ºç¼“å­˜
        self.cached_log_text: str = "ç­‰å¾…å¼€å§‹è®­ç»ƒ..."
        self.last_log_update: float = 0
        self.log_cache_duration: float = 2.0  # æ—¥å¿—ç¼“å­˜2ç§’
        self.last_displayed_log_count: int = 0  # ä¸Šæ¬¡æ˜¾ç¤ºçš„æ—¥å¿—è¡Œæ•°
        # å­è¿›ç¨‹ä¸æ—¥å¿—
        self.proc: Optional[subprocess.Popen] = None
        self.proc_pid: Optional[int] = None
        self.reader_thread: Optional[threading.Thread] = None
        self.log_lines: List[str] = []
        self.start_time: float = 0.0
        self.end_time: Optional[float] = None
        self.exit_code: Optional[int] = None
        self.output_dir: Optional[str] = None
        self.cmdline: List[str] = []
        self.log_file: Optional[Any] = None  # æ—¥å¿—æ–‡ä»¶å¥æŸ„
        self.logging_steps: int = 50  # é»˜è®¤æ¯50æ­¥è®°å½•ä¸€æ¬¡ï¼Œä¼šåœ¨è®­ç»ƒæ—¶æ›´æ–°
        self.eval_steps: int = 500  # é»˜è®¤æ¯500æ­¥è¯„ä¼°ä¸€æ¬¡ï¼Œä¼šåœ¨è®­ç»ƒæ—¶æ›´æ–°
        
training_state = TrainingState()

def _project_root() -> Path:
    return Path(__file__).resolve().parents[2]


def _train_script_path() -> Path:
    # è®­ç»ƒè„šæœ¬ï¼ˆä½¿ç”¨ HF Trainer å®ç°ï¼‰
    return _project_root() / "scripts/train/train_speech_model.py"


def _auto_detect_device_and_processes() -> Tuple[str, int, str]:
    """è¿”å› (device, num_processes, detail_msg). device ä¸º 'GPU' æˆ– 'CPU'ã€‚"""
    device = "CPU"
    num_proc = 1
    detail = "CUDA ä¸å¯ç”¨ï¼Œé»˜è®¤ CPU x1"
    try:
        import torch  # type: ignore
        if torch.cuda.is_available():
            n = torch.cuda.device_count() or 1
            device = "GPU"
            num_proc = n
            detail = f"CUDA å¯ç”¨ï¼ŒGPU æ•°: {n}"
    except Exception:
        pass
    return device, num_proc, detail


def _refresh_device_triplet():
    d, p, detail = _auto_detect_device_and_processes()
    return detail, p, ("GPU" if d == "GPU" else "CPU")


def save_training_config(config_dict: Dict[str, Any]):
    """ä¿å­˜è®­ç»ƒé…ç½®"""
    config_path = "/tmp/training_config.json"
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config_dict, f, indent=2, ensure_ascii=False)
    return f"é…ç½®å·²ä¿å­˜åˆ°: {config_path}"

def start_training(
    dataset_path: str, 
    model_type: str,
    model_checkpoint: str,
    tokenizer_path: str,
    output_dir: str,
    batch_size: int,
    learning_rate: float,
    epochs: int,
    save_interval: int,
    validation_split: float,
    optimizer: str,
    scheduler: str,
    use_auto_split: bool,
    enable_lora: bool,
    precision_choice: str,
    device_choice: str,
    gpu_processes: float,
    gpu_ids: str,
    logging_steps: int = 50,
    eval_steps: int = 500
):
    """ä»¥å­è¿›ç¨‹æ–¹å¼å¯åŠ¨è®­ç»ƒè„šæœ¬ï¼Œå¹¶åœ¨å½“å‰ Gradio ä¸­ç®¡ç†ç”Ÿå‘½å‘¨æœŸã€‚"""
    global training_state
    
    if training_state.is_training:
        return "âš ï¸ å·²æœ‰è®­ç»ƒä»»åŠ¡åœ¨è¿è¡Œä¸­ï¼Œè¯·å…ˆåœæ­¢å½“å‰è®­ç»ƒ"
    
    if not dataset_path:
        return "âŒ è¯·å…ˆé€‰æ‹©æ•°æ®é›†æ–‡ä»¶"
    
    # ç²¾åº¦é€‰é¡¹
    use_fp16 = (precision_choice == "fp16")
    use_bf16 = (precision_choice == "bf16")

    try:
        script_path = _train_script_path()
        if not script_path.exists():
            return f"âŒ æ‰¾ä¸åˆ°è®­ç»ƒè„šæœ¬: {script_path}"

        # è®¾ç½®è®­ç»ƒå¼€å§‹æ—¶é—´
        training_state.start_time = time.time()
        
        # ä¿å­˜çŠ¶æ€
        training_state.output_dir = output_dir
        training_state.logging_steps = logging_steps  # ä¿å­˜ logging_steps å€¼
        training_state.eval_steps = eval_steps  # ä¿å­˜ eval_steps å€¼
        training_state.log_lines = []
        training_state.cached_log_text = "æ­£åœ¨å¯åŠ¨è®­ç»ƒ..."
        training_state.last_log_update = 0
        training_state.last_displayed_log_count = 0
        training_state.last_log_size = 0
        training_state.exit_code = None
        training_state.end_time = None
        # æ¸…ç©ºè®­ç»ƒå›¾è¡¨ç¼“å­˜ï¼Œé¿å…æ˜¾ç¤ºä¸Šæ¬¡è®­ç»ƒçš„å›¾è¡¨
        training_state.cached_plot_path = None
        training_state.last_plot_update = 0
        
        # åˆ›å»ºæ—¥å¿—æ–‡ä»¶ï¼ˆç°åœ¨start_timeå·²ç»è®¾ç½®ï¼‰
        log_dir = Path("logs/training")
        log_dir.mkdir(parents=True, exist_ok=True)
        log_file_path = log_dir / f"train_{int(training_state.start_time)}.log"
        try:
            training_state.log_file = open(log_file_path, "w", encoding="utf-8")
            logger.info(f"è®­ç»ƒæ—¥å¿—å°†ä¿å­˜åˆ°: {log_file_path}")
        except Exception as e:
            logger.warning(f"æ— æ³•åˆ›å»ºæ—¥å¿—æ–‡ä»¶: {e}")
            training_state.log_file = None

        # è‡ªåŠ¨éªŒè¯é›†è·¯å¾„é€»è¾‘
        cv_data_arg = None
        if not use_auto_split:
            train_path = Path(dataset_path)
            val_path = train_path.parent / "val" / train_path.name
            if val_path.exists():
                cv_data_arg = str(val_path)
            else:
                # è‹¥æœªæ‰¾åˆ°æŒ‡å®šéªŒè¯é›†ï¼Œåˆ™è‡ªåŠ¨åˆ‡æ¢ä¸ºè‡ªåŠ¨åˆ’åˆ†
                use_auto_split = True

        # è®­ç»ƒè„šæœ¬å‚æ•°
        script_args: List[str] = [
            "--model", model_type,
            "--model_ckpt", model_checkpoint,
            "--tokenizer_path", tokenizer_path,
            "--train_data", dataset_path,
            "--output_dir", output_dir,
            "--per_device_train_batch_size", str(int(batch_size)),
            "--learning_rate", str(float(learning_rate)),
            "--num_train_epochs", str(int(epochs)),
            "--save_steps", str(int(save_interval)),
            "--logging_steps", str(int(logging_steps)),  # æ·»åŠ  logging_steps å‚æ•°
            "--eval_steps", str(int(eval_steps)),  # æ·»åŠ  eval_steps å‚æ•°
            "--val_split_ratio", str(float(validation_split)),
        ]
        
        # è®°å½•è®­ç»ƒå‚æ•°ä»¥ä¾¿è°ƒè¯•
        logger.info(f"è®­ç»ƒå‚æ•°: batch_size={batch_size}, lr={learning_rate}, epochs={epochs}, save_steps={save_interval}")
        if use_auto_split:
            script_args.append("--auto_val_split")
        else:
            if cv_data_arg:
                script_args.extend(["--cv_data", cv_data_arg])
        if enable_lora:
            script_args.append("--enable_lora")
        if use_fp16:
            script_args.append("--fp16")
        if use_bf16:
            script_args.append("--bf16")

        # è®¾å¤‡é€‰æ‹©ä¸è¿›ç¨‹æ•°
        dev_detect, max_gpus, _detail = _auto_detect_device_and_processes()
        chosen = device_choice
        if chosen == "è‡ªåŠ¨":
            chosen = "GPU" if dev_detect == "GPU" else "CPU"
        try:
            nproc = max(1, int(gpu_processes))
        except Exception:
            nproc = 1

        # mixed_precision for accelerate
        mixed_precision = "no"
        if use_bf16:
            mixed_precision = "bf16"
        elif use_fp16:
            mixed_precision = "fp16"

        # ç¯å¢ƒå˜é‡ï¼ˆé™åˆ¶å¯è§ GPUï¼‰
        env = os.environ.copy()
        cuda_ids = (gpu_ids or "").strip()
        if chosen == "GPU":
            if cuda_ids:
                env["CUDA_VISIBLE_DEVICES"] = cuda_ids
            else:
                # é»˜è®¤é€‰æ‹©ä» 0 å¼€å§‹çš„å‰ nproc å¼ å¡
                if max_gpus > 0:
                    take = max(1, min(nproc, max_gpus))
                    env["CUDA_VISIBLE_DEVICES"] = ",".join(str(i) for i in range(take))

        # ç»„è£… accelerate å¯åŠ¨å‘½ä»¤ï¼ˆç»Ÿä¸€ä½¿ç”¨ accelerateï¼‰
        cmd: List[str] = [
            sys.executable,
            "-m", "accelerate.commands.launch",
            "--num_machines", "1",
            "--num_processes", str(nproc if chosen == "GPU" else 1),
            "--mixed_precision", mixed_precision,
            str(script_path),
            *script_args,
        ]

        training_state.cmdline = cmd
        
        # è®°å½•å®Œæ•´çš„å‘½ä»¤ä»¥ä¾¿è°ƒè¯•
        logger.info(f"æ‰§è¡Œè®­ç»ƒå‘½ä»¤: {' '.join(cmd)}")

        # å¯åŠ¨å­è¿›ç¨‹ï¼ˆç‹¬ç«‹è¿›ç¨‹ç»„ï¼Œä¾¿äºåœæ­¢ï¼‰
        try:
            training_state.proc = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
                universal_newlines=True,
                preexec_fn=os.setsid if hasattr(os, "setsid") else None,
                env=env,
            )
        except Exception as e:
            return f"âŒ å¯åŠ¨å¤±è´¥: {e}"

        training_state.is_training = True
        training_state.proc_pid = training_state.proc.pid if training_state.proc else None
        training_state.current_training_id = f"local-{int(training_state.start_time)}"

        # å¯åŠ¨æ—¥å¿—è¯»å–çº¿ç¨‹
        def _reader():
            try:
                assert training_state.proc is not None
                assert training_state.proc.stdout is not None
                for raw in training_state.proc.stdout:
                    line = raw.rstrip()
                    if not line:
                        continue
                    training_state.log_lines.append(line)
                    if len(training_state.log_lines) > 2000:
                        training_state.log_lines = training_state.log_lines[-2000:]
                    # åŒæ—¶å†™å…¥æ—¥å¿—æ–‡ä»¶
                    if training_state.log_file:
                        try:
                            training_state.log_file.write(line + "\n")
                            training_state.log_file.flush()  # å®æ—¶åˆ·æ–°
                        except Exception as we:
                            logger.warning(f"å†™å…¥æ—¥å¿—æ–‡ä»¶å¤±è´¥: {we}")
                    # è½»é‡æ›´æ–°ç¼“å­˜æ–‡æœ¬æ ‡è®°æ›´æ–°æ—¶é—´
                    training_state.cached_log_text = "\n".join(training_state.log_lines[-200:])
                    training_state.last_log_update = time.time()
            except Exception as re:
                logger.warning(f"æ—¥å¿—è¯»å–çº¿ç¨‹å¼‚å¸¸: {re}")
            finally:
                try:
                    if training_state.proc is not None:
                        ret = training_state.proc.wait()
                        training_state.exit_code = ret
                except Exception:
                    pass
                training_state.is_training = False
                training_state.end_time = time.time()
                # å…³é—­æ—¥å¿—æ–‡ä»¶
                if training_state.log_file:
                    try:
                        training_state.log_file.close()
                        training_state.log_file = None
                        logger.info("è®­ç»ƒæ—¥å¿—æ–‡ä»¶å·²å…³é—­")
                    except Exception:
                        pass

        training_state.reader_thread = threading.Thread(target=_reader, daemon=True)
        training_state.reader_thread.start()

        return f"âœ… è®­ç»ƒä»»åŠ¡å·²å¯åŠ¨\nè®­ç»ƒID: {training_state.current_training_id}\nPID: {training_state.proc_pid}\nè„šæœ¬: {script_path.name}"

    except Exception as e:
        logger.error(f"å¯åŠ¨è®­ç»ƒå¤±è´¥: {e}")
        return f"âŒ è®­ç»ƒå¯åŠ¨å¤±è´¥: {str(e)}"

def stop_training():
    """åœæ­¢è®­ç»ƒï¼ˆç»ˆæ­¢å­è¿›ç¨‹ï¼‰ã€‚"""
    global training_state
    
    if not training_state.is_training or training_state.proc is None:
        return "âš ï¸ å½“å‰æ²¡æœ‰è¿è¡Œä¸­çš„è®­ç»ƒä»»åŠ¡"
    
    try:
        proc = training_state.proc
        # å…ˆå°è¯•ä¼˜é›…ç»ˆæ­¢
        try:
            if proc.poll() is None:
                if hasattr(os, "getpgid"):
                    os.killpg(os.getpgid(proc.pid), signal.SIGTERM)
                else:
                    proc.terminate()
        except Exception:
            pass
        # ç­‰å¾…æœ€å¤š5ç§’
        try:
            proc.wait(timeout=5)
        except Exception:
            try:
                if hasattr(os, "getpgid"):
                    os.killpg(os.getpgid(proc.pid), signal.SIGKILL)
                else:
                    proc.kill()
            except Exception:
                pass
        training_state.is_training = False
        training_state.current_training_id = None
        training_state.end_time = time.time()
        code = proc.returncode
        training_state.exit_code = code
        # å…³é—­æ—¥å¿—æ–‡ä»¶
        if training_state.log_file:
            try:
                training_state.log_file.close()
                training_state.log_file = None
            except Exception:
                pass
        return f"ğŸ›‘ è®­ç»ƒå·²åœæ­¢ (é€€å‡ºç : {code})"
    except Exception as e:
        logger.error(f"åœæ­¢è®­ç»ƒå¤±è´¥: {e}")
        return f"âŒ åœæ­¢è®­ç»ƒå¤±è´¥: {str(e)}"

def get_training_logs():
    """è·å–æœ¬åœ°å­è¿›ç¨‹çš„è®­ç»ƒæ—¥å¿—ï¼ˆå¸¦ç¼“å­˜ï¼‰ã€‚"""
    global training_state
    
    current_time = time.time()
    
    if not training_state.current_training_id and not training_state.is_training:
        training_state.cached_log_text = "æš‚æ— è®­ç»ƒä»»åŠ¡"
        return training_state.cached_log_text
    
    # ç¼“å­˜æ§åˆ¶
    time_since_last_update = current_time - training_state.last_log_update
    if time_since_last_update < training_state.log_cache_duration:
        return training_state.cached_log_text

    try:
        status = "running" if training_state.is_training else ("stopped" if training_state.exit_code is None else ("completed" if training_state.exit_code == 0 else "failed"))
        logs = training_state.log_lines
        training_state.last_displayed_log_count = len(logs)

        header_info: List[str] = []
        header_info.append(f"è®­ç»ƒçŠ¶æ€: {status}")
        if training_state.current_training_id:
            header_info.append(f"è®­ç»ƒID: {training_state.current_training_id}")
        if training_state.start_time:
            st = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(training_state.start_time))
            header_info.append(f"å¼€å§‹æ—¶é—´: {st}")
        if training_state.end_time:
            et = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(training_state.end_time))
            header_info.append(f"ç»“æŸæ—¶é—´: {et}")
        if logs:
            header_info.append(f"æ—¥å¿—è¡Œæ•°: {len(logs)}")
        header_info.append("=" * 50)
        header_text = "\n".join(header_info) + "\n"

        # æ˜¾ç¤ºæœ€è¿‘ 200 è¡Œ
        if len(logs) <= 200:
            displayed = logs
        else:
            displayed = logs[-200:]
        log_content = "\n".join(displayed)
        if len(logs) > len(displayed):
            log_content = f"... (çœç•¥äº†å‰{len(logs) - len(displayed)}è¡Œæ—¥å¿—) ...\n\n" + log_content

        training_state.cached_log_text = header_text + log_content
        training_state.last_log_update = current_time
        return training_state.cached_log_text
    except Exception as e:
        logger.error(f"è·å–è®­ç»ƒæ—¥å¿—å¤±è´¥: {e}")
        training_state.cached_log_text = f"è·å–æ—¥å¿—å¤±è´¥: {str(e)}"
        return training_state.cached_log_text

def parse_training_logs(log_file_path: str) -> Dict[str, List[float]]:
    """è§£æè®­ç»ƒæ—¥å¿—ï¼Œæå–è®­ç»ƒæŒ‡æ ‡"""
    metrics = {
        'steps': [],
        'loss': [],
        'grad_norm': [],
        'learning_rate': [],
        'epoch': []
    }
    
    try:
        if not os.path.exists(log_file_path):
            logger.warning(f"æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file_path}")
            return metrics
        
        with open(log_file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        step = 0
        for line in lines:
            # åŒ¹é…è®­ç»ƒæ—¥å¿—ä¸­çš„æŒ‡æ ‡ä¿¡æ¯
            # ç¤ºä¾‹æ ¼å¼: {'loss': 5.2719, 'grad_norm': 2.815345287322998, 'learning_rate': 9.891681109185442e-05, 'epoch': 0.02}
            if line.strip().startswith('{') and 'loss' in line:
                try:
                    # å°è¯•ç›´æ¥ä½¿ç”¨evalè§£æå­—å…¸ï¼ˆæ›´å®‰å…¨çš„æ–¹æ³•ï¼‰
                    line_clean = line.strip()
                    if line_clean.endswith('\n'):
                        line_clean = line_clean[:-1]
                    
                    # å°è¯•è§£æä¸ºå­—å…¸
                    try:
                        import ast
                        metrics_dict = ast.literal_eval(line_clean)
                        if isinstance(metrics_dict, dict) and 'loss' in metrics_dict:
                            step += 1
                            metrics['steps'].append(step)
                            metrics['loss'].append(float(metrics_dict['loss']))
                            metrics['grad_norm'].append(float(metrics_dict.get('grad_norm', 0)))
                            metrics['learning_rate'].append(float(metrics_dict.get('learning_rate', 0)))
                            metrics['epoch'].append(float(metrics_dict.get('epoch', 0)))
                    except (ValueError, SyntaxError):
                        # å¦‚æœast.literal_evalå¤±è´¥ï¼Œå›åˆ°æ­£åˆ™è¡¨è¾¾å¼æ–¹æ³•
                        loss_match = re.search(r"'loss':\s*([\d\.-eE]+)", line)
                        grad_norm_match = re.search(r"'grad_norm':\s*([\d\.-eE]+)", line)
                        lr_match = re.search(r"'learning_rate':\s*([\d\.-eE]+)", line)
                        epoch_match = re.search(r"'epoch':\s*([\d\.-eE]+)", line)
                        
                        if loss_match:
                            step += 1
                            metrics['steps'].append(step)
                            metrics['loss'].append(float(loss_match.group(1)))
                            
                            metrics['grad_norm'].append(
                                float(grad_norm_match.group(1)) if grad_norm_match 
                                else (metrics['grad_norm'][-1] if metrics['grad_norm'] else 0)
                            )
                            metrics['learning_rate'].append(
                                float(lr_match.group(1)) if lr_match 
                                else (metrics['learning_rate'][-1] if metrics['learning_rate'] else 0)
                            )
                            metrics['epoch'].append(
                                float(epoch_match.group(1)) if epoch_match 
                                else (metrics['epoch'][-1] if metrics['epoch'] else 0)
                            )
                
                except (ValueError, AttributeError) as e:
                    logger.debug(f"è§£ææ—¥å¿—è¡Œå¤±è´¥: {line.strip()}, é”™è¯¯: {e}")
                    continue
        
        logger.info(f"ä»æ—¥å¿—æ–‡ä»¶è§£æå‡º {len(metrics['loss'])} ä¸ªè®­ç»ƒæ­¥éª¤çš„æ•°æ®")
        
    except Exception as e:
        logger.error(f"è§£æè®­ç»ƒæ—¥å¿—å¤±è´¥: {e}")
    
    return metrics


def _parse_metrics_from_lines(lines: List[str]) -> Dict[str, List[float]]:
    """ä»å†…å­˜ä¸­çš„æ—¥å¿—è¡Œè§£ææŒ‡æ ‡ï¼ˆç”¨äºå›é€€ç»˜å›¾ï¼‰ã€‚"""
    metrics: Dict[str, List[float]] = {
        'steps': [],
        'loss': [],
        'eval_loss': [],
        'grad_norm': [],
        'learning_rate': [],
        'epoch': []
    }
    try:
        train_logs = []
        eval_logs = []
        
        for line in lines:
            s = line.strip()
            # æ¸…ç† ANSI æ§åˆ¶ç ï¼ˆå¦‚ [A ç­‰ï¼‰
            import re
            s = re.sub(r'\x1b\[[A-Za-z0-9;]*[A-Za-z]', '', s)  # ç§»é™¤ANSI escape sequences
            s = re.sub(r'\[A', '', s)  # ç§»é™¤ [A æ§åˆ¶ç 
            s = s.strip()
            
            if not s or not s.startswith('{'):
                continue
                
            try:
                import ast
                d = ast.literal_eval(s)
                if isinstance(d, dict):
                    if 'loss' in d:  # è®­ç»ƒæ—¥å¿—
                        train_logs.append(d)
                    elif 'eval_loss' in d:  # è¯„ä¼°æ—¥å¿—
                        eval_logs.append(d)
                    continue
            except Exception:
                pass
            
            # å›é€€åˆ°æ­£åˆ™è¡¨è¾¾å¼
            if 'loss' in s and "'loss'" in s:
                try:
                    import ast
                    d = ast.literal_eval(s)
                    if isinstance(d, dict):
                        if 'loss' in d:
                            train_logs.append(d)
                        elif 'eval_loss' in d:
                            eval_logs.append(d)
                except Exception:
                    # æœ€åçš„å›é€€ï¼šæ­£åˆ™è¡¨è¾¾å¼
                    loss_match = re.search(r"'loss':\s*([\d\.-eE]+)", s)
                    if loss_match:
                        d = {'loss': float(loss_match.group(1))}
                        grad_norm_match = re.search(r"'grad_norm':\s*([\d\.-eE]+)", s)
                        lr_match = re.search(r"'learning_rate':\s*([\d\.-eE]+)", s)
                        epoch_match = re.search(r"'epoch':\s*([\d\.-eE]+)", s)
                        if grad_norm_match:
                            d['grad_norm'] = float(grad_norm_match.group(1))
                        if lr_match:
                            d['learning_rate'] = float(lr_match.group(1))
                        if epoch_match:
                            d['epoch'] = float(epoch_match.group(1))
                        train_logs.append(d)
                    
                    eval_loss_match = re.search(r"'eval_loss':\s*([\d\.-eE]+)", s)
                    if eval_loss_match:
                        eval_logs.append({'eval_loss': float(eval_loss_match.group(1))})
        
        # æ„å»ºè®­ç»ƒæ•°æ®
        for i, d in enumerate(train_logs):
            metrics['steps'].append(i + 1)
            metrics['loss'].append(float(d.get('loss', 0)))
            metrics['grad_norm'].append(float(d.get('grad_norm', 0)))
            metrics['learning_rate'].append(float(d.get('learning_rate', 0)))
            metrics['epoch'].append(float(d.get('epoch', 0)))
        
        # æ„å»ºè¯„ä¼°æ•°æ®
        for d in eval_logs:
            metrics['eval_loss'].append(float(d.get('eval_loss', 0)))
        
        logger.info(f"ğŸ” ä»æ—¥å¿—è¡Œè§£æ: train_logs={len(train_logs)}, eval_logs={len(eval_logs)}")
        if eval_logs:
            logger.info(f"ğŸ” æ—¥å¿—è¡Œä¸­æ‰¾åˆ°çš„ eval_logs æ ·æœ¬: {eval_logs[0] if eval_logs else 'None'}")
        if train_logs:
            logger.info(f"ğŸ” æ—¥å¿—è¡Œä¸­æ‰¾åˆ°çš„ train_logs æ ·æœ¬: {train_logs[0] if train_logs else 'None'}")
        
    except Exception as e:
        logger.warning(f"è§£ææ—¥å¿—è¡Œå¤±è´¥: {e}")
        
    return metrics

def generate_training_plot(force_update: bool = False):
    """ç”Ÿæˆè®­ç»ƒæ›²çº¿å›¾ï¼Œä¼˜å…ˆè§£æ Trainer çš„ trainer_state.jsonã€‚"""
    global training_state
    
    current_time = time.time()
    
    # ç¼“å­˜æ§åˆ¶ - ç®€åŒ–é€»è¾‘ï¼Œé¿å…ç¼“å­˜é—®é¢˜
    if not force_update and training_state.cached_plot_path and os.path.exists(training_state.cached_plot_path):
        time_since_last_update = current_time - training_state.last_plot_update
        # åªæœ‰åœ¨æ²¡æœ‰æ–°æ•°æ®æ—¶æ‰ä½¿ç”¨ç¼“å­˜
        if time_since_last_update < training_state.plot_cache_duration and not training_state.is_training:
            logger.debug(f"ä½¿ç”¨ç¼“å­˜çš„è®­ç»ƒå›¾è¡¨ï¼Œè·ç¦»ä¸Šæ¬¡æ›´æ–° {time_since_last_update:.1f} ç§’")
            return training_state.cached_plot_path

    # æ²¡æœ‰ä»»åŠ¡æ—¶è¿”å›ç©º
    if not training_state.output_dir or not training_state.current_training_id:
        return None

    try:
        steps: List[int] = []
        loss: List[float] = []
        eval_loss: List[float] = []
        learning_rate: List[float] = []
        epoch: List[float] = []
        grad_norm: List[float] = []

        # ä¼˜å…ˆè§£æ trainer_state.json
        state_file = os.path.join(training_state.output_dir, "trainer_state.json")
        if os.path.exists(state_file):
            try:
                with open(state_file, "r", encoding="utf-8") as f:
                    st = json.load(f)
                logs = st.get("log_history", []) or []
                
                # åˆ†åˆ«å¤„ç†è®­ç»ƒå’Œè¯„ä¼°æ—¥å¿—
                train_logs = []
                eval_logs = []
                
                for entry in logs:
                    if not isinstance(entry, dict):
                        continue
                    # æ³¨æ„ï¼ševal_loss æ¡ç›®é€šå¸¸ä¹ŸåŒ…å«å…¶ä»–å­—æ®µï¼Œéœ€è¦å‡†ç¡®è¯†åˆ«
                    if "eval_loss" in entry:  # è¯„ä¼°æ—¥å¿— - ä¼˜å…ˆæ£€æŸ¥
                        eval_logs.append(entry)
                    elif "loss" in entry and "eval_loss" not in entry:  # è®­ç»ƒæ—¥å¿—
                        train_logs.append(entry)
                
                # å¤„ç†è®­ç»ƒæ—¥å¿—
                for i, entry in enumerate(train_logs):
                    s = entry.get("step")
                    if s is not None:
                        steps.append(int(s))
                        loss.append(float(entry.get("loss", 0)))
                        grad_norm.append(float(entry.get("grad_norm", 0)))
                        learning_rate.append(float(entry.get("learning_rate", 0)))
                        epoch.append(float(entry.get("epoch", 0)))
                
                # å¤„ç†è¯„ä¼°æ—¥å¿—ï¼ˆç‹¬ç«‹å¤„ç†ï¼‰
                for entry in eval_logs:
                    eval_loss.append(float(entry.get("eval_loss", 0)))
                
                logger.info(f"ğŸ” ä» trainer_state.json è§£æ: train_logs={len(train_logs)}, eval_logs={len(eval_logs)}")
                if eval_logs:
                    logger.info(f"ğŸ” æ‰¾åˆ°çš„ eval_logs æ ·æœ¬: {eval_logs[0] if eval_logs else 'None'}")
                
            except Exception as e:
                logger.warning(f"è§£æ trainer_state.json å¤±è´¥: {e}")
                # è¯»å–å¤±è´¥åˆ™é€€å›æ—¥å¿—è§£æ
                steps = []

        # å¦‚æœ trainer_state.json ä¸ºç©ºæˆ–ä¸å­˜åœ¨ï¼Œå›é€€åˆ°å†…å­˜æ—¥å¿—è§£æ
        if not steps and training_state.log_lines:
            m = _parse_metrics_from_lines(training_state.log_lines)
            steps = m['steps']
            loss = m['loss']
            eval_loss = m['eval_loss']
            learning_rate = m['learning_rate']
            epoch = m['epoch']
            grad_norm = m['grad_norm']

        # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œè¿”å›ç©º
        if not steps:
            return None
            
        # è°ƒè¯•ä¿¡æ¯ï¼šè®°å½•æ•°æ®æ•°é‡
        valid_eval_count = len([v for v in eval_loss if v > 0])
        logger.info(f"ğŸ¯ ç»˜å›¾æ•°æ®ç»Ÿè®¡: steps={len(steps)}, loss={len(loss)}, eval_loss={len(eval_loss)}, valid_eval_loss={valid_eval_count}")
        logger.info(f"ğŸ“Š å®Œæ•´ eval_loss æ•°ç»„: {eval_loss}")  # æ˜¾ç¤ºå®Œæ•´æ•°ç»„
        if eval_loss:
            logger.info(f"ğŸ“Š eval_loss æ ·æœ¬: {eval_loss[:5]}...")  # æ˜¾ç¤ºå‰5ä¸ªå€¼
            logger.info(f"ğŸ“Š eval_loss æ•°æ®ç±»å‹: {[type(v) for v in eval_loss[:3]]}")
        if valid_eval_count > 0:
            logger.info(f"âœ… å‘ç°æœ‰æ•ˆ eval_loss æ•°æ®ï¼Œåº”è¯¥ä¼šæ˜¾ç¤ºeval lossæ›²çº¿")
        else:
            logger.warning(f"âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„ eval_loss æ•°æ®ï¼åŸå§‹æ•°æ®: {eval_loss[:10]}")

        # ç»Ÿä¸€é•¿åº¦ï¼ˆç®€å•å¯¹é½ï¼Œç¼ºå¤±ç”¨ None è·³è¿‡ç»˜å›¾ï¼‰
        import matplotlib.pyplot as plt
        import matplotlib.ticker as ticker
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        title_id = training_state.current_training_id or "local"
        fig.suptitle(f'Training Progress - {title_id}', fontsize=16)
        
        # è‡ªé€‚åº”æ¨ªåæ ‡å‡½æ•°
        def format_x_axis(ax, steps_data):
            if not steps_data:
                return
            max_steps = max(steps_data)
            # æ ¹æ®æ­¥æ•°èŒƒå›´è‡ªåŠ¨è°ƒæ•´åˆ»åº¦é—´éš”
            if max_steps < 50:
                interval = 5
            elif max_steps < 100:
                interval = 10
            elif max_steps < 1000:
                interval = 100
            elif max_steps < 10000:
                interval = 1000
            elif max_steps < 100000:
                interval = 5000
            else:
                interval = 10000
            
            ax.xaxis.set_major_locator(ticker.MultipleLocator(interval))
            # æ ¼å¼åŒ–å¤§æ•°å­—æ˜¾ç¤º
            if max_steps >= 10000:
                ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, p: f'{int(x/1000)}K' if x >= 1000 else f'{int(x)}'))
            # æ—‹è½¬æ ‡ç­¾é¿å…é‡å 
            ax.tick_params(axis='x', rotation=45)

        # Train Loss (å·¦ä¸Šè§’)
        if loss:
            # è¿‡æ»¤æ‰ä¸º0çš„losså€¼
            valid_loss = [(i, v) for i, v in enumerate(loss) if v > 0]
            if valid_loss:
                loss_indices, loss_values = zip(*valid_loss)
                actual_steps = [i * training_state.logging_steps for i in loss_indices]
                ax1.plot(actual_steps, loss_values, color='blue', linewidth=2, marker='o', markersize=3, alpha=0.7, label='train loss')
        ax1.set_title('Train Loss', fontsize=12)
        ax1.set_xlabel('Steps')
        ax1.set_ylabel('Loss')
        ax1.grid(True, alpha=0.3)
        # åº”ç”¨è‡ªé€‚åº”æ¨ªåæ ‡æ ¼å¼ï¼ˆåªè€ƒè™‘è®­ç»ƒæŸå¤±ï¼‰
        if loss:
            valid_loss = [(i, v) for i, v in enumerate(loss) if v > 0]
            if valid_loss:
                loss_indices, _ = zip(*valid_loss)
                actual_steps = [i * training_state.logging_steps for i in loss_indices]
                format_x_axis(ax1, actual_steps)
        if loss:
            ax1.legend()

        # Gradient Norm (æ ¹æ®logging_stepsè®°å½•é—´éš”æ˜¾ç¤ºçœŸå®æ­¥æ•°)
        if grad_norm and any(x > 0 for x in grad_norm):  # åªæœ‰åœ¨æœ‰æœ‰æ•ˆæ•°æ®æ—¶æ‰ç»˜åˆ¶
            actual_steps_grad = [s * training_state.logging_steps for s in range(len(grad_norm))]
            ax2.plot(actual_steps_grad, grad_norm, color='orange', linewidth=2, marker='s', markersize=3, alpha=0.7)
        ax2.set_title('Gradient Norm', fontsize=12)
        ax2.set_xlabel('Steps')
        ax2.set_ylabel('Grad Norm')
        ax2.grid(True, alpha=0.3)
        if not grad_norm or not any(x > 0 for x in grad_norm):
            ax2.text(0.5, 0.5, 'No Data', transform=ax2.transAxes, ha='center', va='center', alpha=0.5)
        else:
            format_x_axis(ax2, actual_steps_grad)

        # Learning Rate (æ ¹æ®logging_stepsè®°å½•é—´éš”æ˜¾ç¤ºçœŸå®æ­¥æ•°)
        if learning_rate:
            actual_steps_lr = [s * training_state.logging_steps for s in range(len(learning_rate))]
            ax3.plot(actual_steps_lr, learning_rate, color='green', linewidth=2, marker='^', markersize=3, alpha=0.7)
        ax3.set_title('Learning Rate', fontsize=12)
        ax3.set_xlabel('Steps')
        ax3.set_ylabel('Learning Rate')
        ax3.grid(True, alpha=0.3)
        ax3.ticklabel_format(style='scientific', axis='y', scilimits=(0,0))
        if learning_rate:
            format_x_axis(ax3, actual_steps_lr)

        # Eval Loss (æ ¹æ®eval_stepsè®°å½•é—´éš”æ˜¾ç¤ºçœŸå®æ­¥æ•°)
        if eval_loss:
            # è¿‡æ»¤æ‰ä¸º0çš„eval_losså€¼
            valid_eval_loss = [(i, v) for i, v in enumerate(eval_loss) if v > 0]
            if valid_eval_loss:
                eval_indices, eval_values = zip(*valid_eval_loss)
                # eval_loss ä»ç¬¬1æ¬¡è¯„ä¼°å¼€å§‹ï¼Œæ‰€ä»¥æ­¥æ•°æ˜¯ (i+1) * eval_steps
                actual_steps_eval = [(i + 1) * training_state.eval_steps for i in eval_indices]
                ax4.plot(actual_steps_eval, eval_values, color='red', linewidth=2, marker='s', markersize=4, alpha=0.7, label='eval loss')
                format_x_axis(ax4, actual_steps_eval)
                logger.info(f"ğŸ¨ ç»˜åˆ¶ eval_loss æ›²çº¿: {len(eval_values)} ä¸ªç‚¹ï¼Œæ­¥æ•°èŒƒå›´ {min(actual_steps_eval)}-{max(actual_steps_eval)}")
            else:
                ax4.text(0.5, 0.5, 'No Eval Data', transform=ax4.transAxes, ha='center', va='center', alpha=0.5)
        else:
            ax4.text(0.5, 0.5, 'No Eval Data', transform=ax4.transAxes, ha='center', va='center', alpha=0.5)
        ax4.set_title('Eval Loss', fontsize=12)
        ax4.set_xlabel('Steps')
        ax4.set_ylabel('Eval Loss')
        ax4.grid(True, alpha=0.3)
        if eval_loss:
            ax4.legend()

        plt.tight_layout()
        
        # å°†å›¾è¡¨ä¿å­˜åˆ°è®­ç»ƒè¾“å‡ºç›®å½•ä¸‹çš„figureæ–‡ä»¶å¤¹
        if training_state.output_dir:
            figure_dir = os.path.join(training_state.output_dir, "figure")
            os.makedirs(figure_dir, exist_ok=True)
            # åªä¿å­˜ä¸€ä¸ªå›ºå®šåç§°çš„å›¾ç‰‡ï¼Œé¿å…äº§ç”Ÿå¤§é‡æ–‡ä»¶
            plot_path = os.path.join(figure_dir, "training_plot.png")
        else:
            plot_path = f"/tmp/training_plot_{int(current_time)}.png"
        
        try:
            plt.savefig(plot_path, dpi=150, bbox_inches='tight', facecolor='white')
            logger.debug(f"è®­ç»ƒå›¾è¡¨å·²æ›´æ–°: {plot_path}")
        except Exception as save_error:
            logger.error(f"ä¿å­˜è®­ç»ƒå›¾è¡¨å¤±è´¥: {save_error}")
        finally:
            plt.close()

        # æ›´æ–°ç¼“å­˜
        training_state.cached_plot_path = plot_path
        training_state.last_plot_update = current_time
        return plot_path
    except Exception as e:
        logger.error(f"ç”Ÿæˆè®­ç»ƒå›¾è¡¨å¤±è´¥: {e}")
        return None

# å·²åˆ é™¤ç¤ºä¾‹å›¾è¡¨ç”Ÿæˆå‡½æ•°

def get_model_list(which: str = "llm"):
    """è·å–è®­ç»ƒè¾“å‡ºç›®å½•ä¸‹çš„æ¨¡å‹æ–‡ä»¶å¤¹åˆ—è¡¨ï¼ˆæŒ‰æ¨¡å‹ç±»å‹åŒºåˆ†ï¼‰
    
    Args:
        which: "llm" æˆ– "flow"ï¼Œç”¨äºé€‰æ‹©é¦–è¦æ‰«æç›®å½•
    """
    try:
        # è®­ç»ƒè¾“å‡ºç›®å½• - æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œé¿å…é‡å¤æ‰«æ
        primary_output_dir = f"checkpoints/training_{which}"  # ä¸»è¦è¾“å‡ºç›®å½•
        fallback_dirs = [
            "checkpoints/training_llm",
            "checkpoints/training_flow", 
            "checkpoints/training",
            "checkpoints", 
            "models", 
            "outputs", 
            "ckpt"
        ]  # å¤‡ç”¨ç›®å½•
        
        models = []
        processed_folders = set()  # é¿å…é‡å¤å¤„ç†ç›¸åŒçš„æ–‡ä»¶å¤¹
        
        # é¦–å…ˆæ‰«æä¸»è¦è¾“å‡ºç›®å½•
        primary_path = Path(primary_output_dir)
        if primary_path.exists():
            logger.info(f"æ­£åœ¨æ‰«æä¸»è¦è¾“å‡ºç›®å½•: {primary_path}")
            models.extend(_scan_output_directory(primary_path, processed_folders))
        
        # å¦‚æœä¸»è¦ç›®å½•æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–‡ä»¶å¤¹ï¼Œå†æ‰«æå¤‡ç”¨ç›®å½•
        if not models:
            for output_dir in fallback_dirs:
                output_path = Path(output_dir)
                if output_path.exists():
                    logger.info(f"æ­£åœ¨æ‰«æå¤‡ç”¨ç›®å½•: {output_path}")
                    models.extend(_scan_output_directory(output_path, processed_folders))
        
        # æŒ‰ä¿®æ”¹æ—¶é—´å€’åºæ’åˆ—
        models.sort(key=lambda x: x["æ—¶é—´"], reverse=True)
        
        logger.info(f"æ‰¾åˆ° {len(models)} ä¸ªæ¨¡å‹æ–‡ä»¶å¤¹")
        
        if not models:
            models = [{"æ–‡ä»¶å¤¹åç§°": "æš‚æ— è®­ç»ƒè¾“å‡º", "è·¯å¾„": "è¯·å…ˆè¿›è¡Œæ¨¡å‹è®­ç»ƒ", "å†…å®¹": "", "å¤§å°": "", "æ—¶é—´": ""}]
        
        return pd.DataFrame(models)
        
    except Exception as e:
        logger.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        return pd.DataFrame([{"æ–‡ä»¶å¤¹åç§°": "è·å–å¤±è´¥", "è·¯å¾„": f"é”™è¯¯: {str(e)}", "å†…å®¹": "", "å¤§å°": "", "æ—¶é—´": ""}])

def _scan_output_directory(output_path: Path, processed_folders: set):
    """æ‰«æå•ä¸ªè¾“å‡ºç›®å½•ï¼Œè¿”å›æ‰¾åˆ°çš„æ¨¡å‹æ–‡ä»¶å¤¹åˆ—è¡¨"""
    models = []
    
    # éå†å­æ–‡ä»¶å¤¹
    for folder_path in output_path.iterdir():
        if folder_path.is_dir():
            folder_name = folder_path.name
            
            # è·³è¿‡æ—¥å¿—ç›®å½•ã€å›¾è¡¨ç›®å½•å’Œå·²å¤„ç†çš„æ–‡ä»¶å¤¹
            if folder_name in ["runs", "logs", "figure"] or folder_name in processed_folders:
                continue
                
            # è·³è¿‡åµŒå¥—çš„è¾“å‡ºç›®å½•æœ¬èº«ï¼ˆé¿å…æ˜¾ç¤ºcheckpoints/trainingè¿™æ ·çš„è·¯å¾„ï¼‰
            if folder_name in ["training", "checkpoints", "models", "outputs", "ckpt"]:
                continue
                
            try:
                processed_folders.add(folder_name)
                stat = folder_path.stat()
                mod_time = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(stat.st_mtime))
                
                # è®¡ç®—æ–‡ä»¶å¤¹å¤§å°ï¼ˆåŒ…å«çš„æ¨¡å‹æ–‡ä»¶ï¼‰
                total_size = 0
                model_count = 0
                model_files = []
                
                # æ‰«ææ¨¡å‹æ–‡ä»¶
                for ext in ["*.pt", "*.pth", "*.ckpt", "*.bin", "*.safetensors"]:
                    for model_file in folder_path.rglob(ext):
                        if model_file.is_file():
                            total_size += model_file.stat().st_size
                            model_count += 1
                            model_files.append(model_file.name)
                
                size_mb = total_size / (1024 * 1024)
                
                # æ˜¾ç¤ºç›¸å¯¹è·¯å¾„
                relative_path = str(folder_path.relative_to(Path.cwd())) if folder_path.is_absolute() else str(folder_path)
                
                # æ„å»ºæè¿°ä¿¡æ¯
                description = f"{model_count}ä¸ªæ¨¡å‹æ–‡ä»¶" if model_count > 0 else "ç©ºæ–‡ä»¶å¤¹"
                if model_files:
                    # åªæ˜¾ç¤ºå‰3ä¸ªæ–‡ä»¶åï¼Œå¦‚æœæ›´å¤šåˆ™æ˜¾ç¤ºçœç•¥å·
                    file_names = ", ".join(sorted(set(model_files))[:3])  # å»é‡å¹¶æ’åº
                    if len(set(model_files)) > 3:
                        file_names += f" ç­‰{len(set(model_files))}ä¸ªæ–‡ä»¶"
                    description = file_names
                
                models.append({
                    "æ–‡ä»¶å¤¹åç§°": folder_name,
                    "è·¯å¾„": relative_path,
                    "å†…å®¹": description,
                    "å¤§å°": f"{size_mb:.1f} MB" if size_mb > 0 else "-",
                    "æ—¶é—´": mod_time
                })
                
            except Exception as e:
                logger.warning(f"Error reading model folder {folder_path}: {e}")
    
    return models

def load_model(model_name: str):
    """åŠ è½½æ¨¡å‹"""
    if not model_name:
        gr.Warning("è¯·é€‰æ‹©æ¨¡å‹")
        return "è¯·é€‰æ‹©æ¨¡å‹"
    
    return f"âœ… æ¨¡å‹ {model_name} åŠ è½½æˆåŠŸ"

def delete_model(folder_name: str):
    """åˆ é™¤æ¨¡å‹æ–‡ä»¶å¤¹"""
    if not folder_name:
        return "âš ï¸ è¯·é€‰æ‹©è¦åˆ é™¤çš„æ–‡ä»¶å¤¹", get_model_list()
    
    try:
        import shutil
        
        # ç›´æ¥å°†è¾“å…¥è§†ä¸ºè·¯å¾„ï¼›å…¼å®¹æ—§æ ¼å¼ "name (path)"
        folder_path: Optional[Path] = None
        if " (" in folder_name and ")" in folder_name:
            path_part = folder_name.split(" (")[1].rstrip(")")
            folder_path = Path(path_part)
        else:
            p = Path(folder_name)
            if p.exists() and p.is_dir():
                folder_path = p
            else:
                # å›é€€åœ¨å„è¾“å‡ºç›®å½•ä¸­æŸ¥æ‰¾åŒåå­ç›®å½•
                output_dirs = [
                    "checkpoints/training", 
                    "checkpoints", 
                    "models", 
                    "outputs",
                    "ckpt"
                ]
                for output_dir in output_dirs:
                    potential_path = Path(output_dir) / folder_name
                    if potential_path.exists() and potential_path.is_dir():
                        folder_path = potential_path
                        break
        
        if folder_path and folder_path.exists() and folder_path.is_dir():
            # ç¡®è®¤ä¸æ˜¯é‡è¦çš„ç³»ç»Ÿæ–‡ä»¶å¤¹
            if folder_path.name in ["runs", "logs", "figure"]:
                return f"âš ï¸ ä¸å…è®¸åˆ é™¤ç³»ç»Ÿæ–‡ä»¶å¤¹: {folder_name}", get_model_list()
            
            # åˆ é™¤æ•´ä¸ªæ–‡ä»¶å¤¹
            shutil.rmtree(folder_path)
            logger.info(f"å·²åˆ é™¤æ¨¡å‹æ–‡ä»¶å¤¹: {folder_path}")
            return f"âœ… æ–‡ä»¶å¤¹ {folder_name} å·²åˆ é™¤", get_model_list()
        else:
            return f"âŒ æœªæ‰¾åˆ°æ–‡ä»¶å¤¹: {folder_name}", get_model_list()
    
    except Exception as e:
        logger.error(f"åˆ é™¤æ–‡ä»¶å¤¹å¤±è´¥: {e}")
        return f"âŒ åˆ é™¤å¤±è´¥: {str(e)}", get_model_list()


def convert_checkpoint_to_pt(folder_path_str: str):
    """å°†è·¯å¾„ä¸‹çš„ pytorch_model.bin è½¬æ¢ä¸º model.ptï¼ˆbf16ï¼‰ã€‚"""
    if not folder_path_str:
        return "âš ï¸ è¯·å…ˆåœ¨è¡¨æ ¼ä¸­é€‰æ‹©ä¸€ä¸ªè·¯å¾„"
    try:
        base = Path(folder_path_str)
        if not base.exists() or not base.is_dir():
            return f"âŒ è·¯å¾„æ— æ•ˆ: {base}"

        bin_path = base / "pytorch_model.bin"
        if not bin_path.exists():
            found = list(base.rglob("pytorch_model.bin"))
            if found:
                bin_path = found[0]
            else:
                return f"âŒ æœªæ‰¾åˆ° pytorch_model.bin äº: {base}"

        # åˆ†ç‰‡ç´¢å¼•ä¸æ”¯æŒ
        if (base / "pytorch_model.bin.index.json").exists():
            return "âŒ æš‚ä¸æ”¯æŒåˆ†ç‰‡æƒé‡ï¼ˆ.bin.index.jsonï¼‰ï¼Œè¯·å…ˆåˆå¹¶å†è½¬æ¢"

        state = torch.load(str(bin_path), map_location="cpu")
        if not isinstance(state, dict):
            return "âŒ æƒé‡æ–‡ä»¶æ ¼å¼ä¸ç¬¦åˆé¢„æœŸï¼ˆéstate_dictï¼‰"

        def to_bf16_tensor(val):
            if isinstance(val, torch.Tensor) and val.is_floating_point():
                try:
                    return val.to(torch.bfloat16)
                except Exception:
                    return val
            return val

        if "core_model" in state and isinstance(state["core_model"], dict):
            state = state["core_model"]

        normalized = {}
        for key, value in state.items():
            if key == "core_model":
                continue
            if isinstance(key, str) and key.startswith("core_model."):
                key = key[len("core_model.") :]
            normalized[key] = value

        converted = {k: to_bf16_tensor(v) for k, v in normalized.items()}
        out_path = base / "model.pt"
        torch.save(converted, str(out_path))
        return f"âœ… è½¬æ¢å®Œæˆ: {bin_path.name} â†’ {out_path} (bf16)"
    except Exception as e:
        return f"âŒ è½¬æ¢å¤±è´¥: {e}"

def update_batch_size_constraints(model_type: str):
    """æ ¹æ®æ¨¡å‹ç±»å‹æ›´æ–°batch_sizeæ¨èå€¼"""
    if model_type == "llm":
        # LLMæ¨¡å‹æ¨èä½¿ç”¨è¾ƒå°çš„batch_size
        return gr.update(value=2, maximum=32, interactive=True)  # batch_size slider
    else:
        # Flowæ¨¡å‹å¯ä»¥ä½¿ç”¨æ›´å¤§çš„batch_size
        return gr.update(value=8, maximum=32, interactive=True)  # batch_size slider

def update_precision_options(model_type: str):
    """æ ¹æ®æ¨¡å‹ç±»å‹æ›´æ–°ç²¾åº¦é€‰é¡¹å’Œæ¨è"""
    if model_type == "llm":
        # LLMæ¨¡å‹æ¨èBF16
        choices = [
            ("BF16ï¼ˆæ¨èï¼‰", "bf16"),
            ("FP16", "fp16")
        ]
        value = "bf16"
        info_text = "ğŸ’¡ **LLMæ¨¡å‹**: æ¨èä½¿ç”¨BF16ç²¾åº¦ä»¥è·å¾—æ›´å¥½çš„æ•°å€¼ç¨³å®šæ€§"
    else:
        # Flowæ¨¡å‹æ¨èFP16
        choices = [
            ("FP16ï¼ˆæ¨èï¼‰", "fp16"),
            ("BF16", "bf16")
        ]
        value = "fp16"
        info_text = "ğŸ’¡ **Flowæ¨¡å‹**: æ¨èä½¿ç”¨FP16ç²¾åº¦ä»¥èŠ‚çœæ˜¾å­˜å’Œæå‡é€Ÿåº¦"
    
    return (
        gr.update(choices=choices, value=value),  # precision_choice radio
        gr.update(value=info_text, visible=True)  # precision info message
    )

def create_training_tab():
    """åˆ›å»ºè®­ç»ƒtabç•Œé¢"""
    with gr.Tab("ğŸš€ æ¨¡å‹è®­ç»ƒ"):
        gr.Markdown("### TTS æ¨¡å‹è®­ç»ƒ")
        # è®¾å¤‡é»˜è®¤å€¼
        device_default, proc_default, device_detail = _auto_detect_device_and_processes()
        
        with gr.Row():
            with gr.Column(scale=1):
                # æ•°æ®é›†é€‰æ‹©
                gr.Markdown("#### 1. æ•°æ®é›†é…ç½®")
                dataset_file = gr.Textbox(
                    label="è®­ç»ƒæ•°æ®è·¯å¾„",
                    placeholder="è¾“å…¥è®­ç»ƒæ•°æ®è·¯å¾„ï¼Œå¦‚: data/processed/train_ds",
                    value="data/processed/train_ds"
                )
                
                # æ¨¡å‹é…ç½®
                gr.Markdown("#### 2. æ¨¡å‹é…ç½®")
                with gr.Group():
                    model_type = gr.Dropdown(
                        choices=["llm", "flow"],
                        value="llm",
                        label="æ¨¡å‹ç±»å‹"
                    )
                    model_checkpoint = gr.Textbox(
                        label="æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„",
                        value="jzx-ai-lab/HydraVox-CV3/llm.pt",
                        placeholder="é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„"
                    )
                    tokenizer_path = gr.Textbox(
                        label="åˆ†è¯å™¨è·¯å¾„",
                        value="jzx-ai-lab/HydraVox-CV3/CosyVoice-BlankEN",
                        placeholder="åˆ†è¯å™¨æ¨¡å‹è·¯å¾„"
                    )
                    output_dir = gr.Textbox(
                        label="è¾“å‡ºç›®å½•",
                        value="checkpoints/training_llm",
                        placeholder="è®­ç»ƒè¾“å‡ºä¿å­˜ç›®å½•"
                    )
                
                # è®­ç»ƒå‚æ•°é…ç½®
                gr.Markdown("#### 3. è®­ç»ƒå‚æ•°")
                with gr.Group():
                    batch_size = gr.Slider(1, 32, value=4, step=1, label="æ‰¹æ¬¡å¤§å°", maximum=1, interactive=True)
                    learning_rate = gr.Number(value=1e-5, label="å­¦ä¹ ç‡", minimum=1e-6, maximum=1e-2)
                    epochs = gr.Slider(1, 100, value=5, step=1, label="è®­ç»ƒè½®æ•°")
                    save_interval = gr.Slider(100, 10000, value=1000, step=100, label="ä¿å­˜é—´éš”(æ­¥æ•°)")
                    logging_steps = gr.Slider(10, 500, value=50, step=10, label="æ—¥å¿—è®°å½•é—´éš”(æ­¥æ•°)")
                    eval_steps = gr.Slider(50, 2000, value=500, step=50, label="è¯„ä¼°é—´éš”(æ­¥æ•°)")
                
                with gr.Group():
                    validation_split = gr.Slider(0.00, 0.3, value=0.05, step=0.01, label="éªŒè¯é›†æ¯”ä¾‹")
                    use_auto_split = gr.Checkbox(label="è‡ªåŠ¨åˆ’åˆ†éªŒè¯é›†", value=True)
                    
                # é«˜çº§é€‰é¡¹
                gr.Markdown("#### 4. é«˜çº§é€‰é¡¹")
                with gr.Group():
                    enable_lora = gr.Checkbox(label="å¯ç”¨LoRAå¾®è°ƒ", value=False)
                    precision_choice = gr.Radio(
                        choices=[
                            ("BF16ï¼ˆæ¨èï¼‰", "bf16"),
                            ("FP16", "fp16")
                        ],
                        value="bf16",
                        label="ç²¾åº¦è®¾ç½®"
                    )
                    precision_info = gr.Markdown("ğŸ’¡ **LLMæ¨¡å‹**: æ¨èä½¿ç”¨BF16ç²¾åº¦ä»¥è·å¾—æ›´å¥½çš„æ•°å€¼ç¨³å®šæ€§", visible=True)

                # è®¡ç®—èµ„æºè®¾ç½®
                gr.Markdown("#### 5. è®¡ç®—èµ„æºè®¾ç½®")
                with gr.Group():
                    with gr.Row():
                        device_choice = gr.Dropdown(
                            choices=["è‡ªåŠ¨", "CPU", "GPU"],
                            value=("GPU" if device_default == "GPU" else "CPU"),
                            label="ğŸ’» è®¡ç®—è®¾å¤‡"
                        )
                        gpu_processes = gr.Number(value=proc_default, label="ğŸ”„ å¹¶è¡Œè¿›ç¨‹æ•° (GPUæ•°)")
                    with gr.Row():
                        gpu_ids = gr.Textbox(label="ğŸ¯ GPU IDs (å¯é€‰)", placeholder="ä¾‹å¦‚: 0,1")
                        detect_btn = gr.Button("ğŸ”„ åˆ·æ–°è®¾å¤‡æ£€æµ‹", variant="secondary")
                    device_info = gr.Textbox(value=device_detail, label="â„¹ï¸ è®¾å¤‡æ£€æµ‹ä¿¡æ¯", interactive=False)

                # æ§åˆ¶æŒ‰é’®
                gr.Markdown("#### 6. è®­ç»ƒæ§åˆ¶")
                start_btn = gr.Button("ğŸš€ å¼€å§‹è®­ç»ƒ", variant="primary")
                stop_btn = gr.Button("ğŸ›‘ åœæ­¢è®­ç»ƒ", variant="stop")
                refresh_log_btn = gr.Button("ğŸ”„ åˆ·æ–°æ—¥å¿—", variant="secondary")
                
            with gr.Column(scale=2):
                # è®­ç»ƒçŠ¶æ€
                gr.Markdown("#### è®­ç»ƒçŠ¶æ€ä¸æ—¥å¿—")
                training_status = gr.Textbox(
                    label="è®­ç»ƒæ—¥å¿—",
                    lines=15,
                    interactive=False,
                    value="ç­‰å¾…å¼€å§‹è®­ç»ƒ...",
                    max_lines=30
                )
                
                # è‡ªåŠ¨åˆ·æ–°æ—¥å¿— - å¢åŠ åˆ·æ–°é—´éš”ä»¥å‡å°‘é—ªçƒ
                log_timer = gr.Timer(value=5)  # æ¯5ç§’åˆ·æ–°æ—¥å¿—
                
                # è®­ç»ƒæ›²çº¿
                gr.Markdown("#### è®­ç»ƒæ›²çº¿")
                with gr.Row():
                    with gr.Column(scale=3):
                        training_plot = gr.Image(label="è®­ç»ƒæŒ‡æ ‡æ›²çº¿", value=None)
                    with gr.Column(scale=1):
                        gr.Markdown("**å›¾è¡¨è®¾ç½®**")
                        auto_refresh_plot = gr.Checkbox(label="è‡ªåŠ¨åˆ·æ–°å›¾è¡¨", value=True)
                        plot_refresh_interval = gr.Slider(
                            minimum=5, maximum=60, value=15, step=5,
                            label="åˆ·æ–°é—´éš”(ç§’)", interactive=True
                        )
                        with gr.Row():
                            refresh_plot_btn = gr.Button("ğŸ”„ ç«‹å³åˆ·æ–°", variant="secondary")
                            force_refresh_btn = gr.Button("âš¡ å¼ºåˆ¶åˆ·æ–°", variant="primary")
                        
                        plot_save_info = gr.Markdown(
                            """
                            **ğŸ’¾ å›¾è¡¨å­˜å‚¨ä½ç½®**  
                            è®­ç»ƒå›¾è¡¨ä¼šå®æ—¶æ›´æ–°å¹¶ä¿å­˜åˆ°ï¼š  
                            `checkpoints/training/figure/training_plot.png`  
                            """,
                            elem_classes=["tiny-muted"]
                        )
                
                # è‡ªåŠ¨åˆ·æ–°å›¾è¡¨å®šæ—¶å™¨
                plot_timer = gr.Timer(value=15)  # é»˜è®¤15ç§’åˆ·æ–°ä¸€æ¬¡å›¾è¡¨
        
        # æ¨¡å‹ç®¡ç†
        gr.Markdown("### æ¨¡å‹ç®¡ç†")
        with gr.Row():
            with gr.Column(scale=2):
                # ä»…æ˜¾ç¤ºè·¯å¾„ä¸€çº§ï¼ˆæŒ‰æ¨¡å‹ç±»å‹æ˜¾ç¤ºï¼Œåˆå§‹ä¸º llmï¼‰
                _df_paths = get_model_list("llm")[ ["è·¯å¾„"] ]
                model_list = gr.Dataframe(
                    value=_df_paths,
                    headers=["è·¯å¾„"],
                    label="è®­ç»ƒè¾“å‡ºè·¯å¾„",
                    interactive=False
                )
                
            with gr.Column(scale=1):
                gr.Markdown("#### æ–‡ä»¶å¤¹æ“ä½œ")
                selected_model = gr.Textbox(label="é€‰æ‹©çš„æ–‡ä»¶å¤¹", placeholder="ç‚¹å‡»è¡¨æ ¼è¡Œé€‰æ‹©æ–‡ä»¶å¤¹")
                
                with gr.Row():
                    refresh_models_btn = gr.Button("ğŸ”„ åˆ·æ–°åˆ—è¡¨", variant="secondary")
                
                with gr.Row():
                    load_btn = gr.Button("ğŸ“‚ åŠ è½½è·¯å¾„", variant="primary")
                    delete_btn = gr.Button("ğŸ—‘ï¸ åˆ é™¤è·¯å¾„", variant="stop")
                with gr.Row():
                    convert_btn = gr.Button("ğŸ” è½¬æ¢ä¸º model.pt (bf16)", variant="primary")
                
                model_status = gr.Textbox(
                    label="æ“ä½œçŠ¶æ€",
                    interactive=False
                )
        
        
        # åŠ¨æ€æ›´æ–°å›¾è¡¨å­˜å‚¨ä½ç½®æç¤º
        def update_plot_save_info(output_dir_value):
            return f"""
            **ğŸ’¾ å›¾è¡¨å­˜å‚¨ä½ç½®**  
            è®­ç»ƒå›¾è¡¨ä¼šå®æ—¶æ›´æ–°å¹¶ä¿å­˜åˆ°ï¼š  
            `{output_dir_value}/figure/training_plot.png`  
            """
        
        output_dir.change(
            fn=update_plot_save_info,
            inputs=output_dir,
            outputs=plot_save_info
        )
        
        # ç»‘å®šè®­ç»ƒæ§åˆ¶äº‹ä»¶
        start_btn.click(
            fn=start_training,
            inputs=[
                dataset_file, model_type, model_checkpoint, tokenizer_path, output_dir,
                batch_size, learning_rate, epochs, save_interval, validation_split,
                gr.State("Adam"), gr.State("CosineAnnealingLR"),  # æš‚æ—¶å›ºå®šä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
                use_auto_split, enable_lora, precision_choice,
                device_choice, gpu_processes, gpu_ids, logging_steps, eval_steps
            ],
            outputs=training_status
        )
        
        stop_btn.click(
            fn=stop_training,
            outputs=training_status
        )
        
        refresh_log_btn.click(
            fn=get_training_logs,
            outputs=training_status
        )
        
        # æ™ºèƒ½æ—¥å¿—åˆ·æ–° - åªåœ¨è®­ç»ƒæ—¶åˆ·æ–°
        def smart_log_refresh():
            """æ™ºèƒ½æ—¥å¿—åˆ·æ–°ï¼šåªåœ¨æœ‰è®­ç»ƒä»»åŠ¡æ—¶æ›´æ–°"""
            if training_state.current_training_id and training_state.is_training:
                return get_training_logs()
            elif training_state.current_training_id:
                # è®­ç»ƒå·²ç»“æŸä½†ä»æœ‰IDï¼Œè·å–æœ€ç»ˆæ—¥å¿—
                final_logs = get_training_logs()
                # å¦‚æœè®­ç»ƒå·²ç»“æŸï¼Œå¯ä»¥å‡å°‘åˆ·æ–°é¢‘ç‡
                if not training_state.is_training:
                    return final_logs
            return training_state.cached_log_text
        
        log_timer.tick(
            fn=smart_log_refresh,
            outputs=training_status
        )
        
        # å›¾è¡¨åˆ·æ–°äº‹ä»¶
        
        def force_update_plot():
            """å¼ºåˆ¶åˆ·æ–°å›¾è¡¨ï¼Œå¿½ç•¥ç¼“å­˜"""
            return generate_training_plot(force_update=True)
        
        def update_plot_timer_interval(interval):
            """æ›´æ–°å›¾è¡¨å®šæ—¶å™¨é—´éš”"""
            training_state.plot_update_interval = interval
            return gr.update(value=interval)
        
        # ç«‹å³åˆ·æ–°æŒ‰é’®
        refresh_plot_btn.click(
            fn=lambda: generate_training_plot(),
            outputs=training_plot
        )
        
        # å¼ºåˆ¶åˆ·æ–°æŒ‰é’®  
        force_refresh_btn.click(
            fn=force_update_plot,
            outputs=training_plot
        )
        
        # åˆ·æ–°é—´éš”è®¾ç½®
        plot_refresh_interval.change(
            fn=update_plot_timer_interval,
            inputs=plot_refresh_interval,
            outputs=plot_timer
        )
        
        # è‡ªåŠ¨åˆ·æ–°å›¾è¡¨å®šæ—¶å™¨
        def auto_refresh_plot_handler(auto_refresh_enabled):
            if auto_refresh_enabled and training_state.is_training:
                return generate_training_plot()
            elif training_state.current_training_id and not training_state.is_training:
                # è®­ç»ƒåœæ­¢åä¹Ÿå±•ç¤ºæœ€åçš„å›¾è¡¨
                return generate_training_plot()
            return gr.update()  # ä¸æ›´æ–°
        
        plot_timer.tick(
            fn=auto_refresh_plot_handler,
            inputs=auto_refresh_plot,
            outputs=training_plot
        )
        
        # åˆ·æ–°æ¨¡å‹åˆ—è¡¨ï¼ˆæŒ‰æ¨¡å‹ç±»å‹ï¼‰
        def _list_model_paths(which: str):
            try:
                return get_model_list(which)[["è·¯å¾„"]]
            except Exception:
                return get_model_list(which)

        refresh_models_btn.click(
            fn=_list_model_paths,
            inputs=model_type,
            outputs=model_list
        )
        
        # æ¨¡å‹è¡¨æ ¼é€‰æ‹©äº‹ä»¶ï¼ˆæŒ‰æ¨¡å‹ç±»å‹ï¼‰
        def on_model_select(evt: gr.SelectData, which: str):
            if evt.index is not None and evt.index[0] >= 0:
                model_data = get_model_list(which)
                if len(model_data) > evt.index[0]:
                    selected_path = model_data.iloc[evt.index[0]]["è·¯å¾„"]
                    return f"{selected_path}"
            return ""
        
        model_list.select(
            fn=on_model_select,
            inputs=model_type,
            outputs=selected_model
        )
        
        load_btn.click(
            fn=load_model,
            inputs=selected_model,
            outputs=model_status
        )
        
        # åˆ é™¤åæŒ‰å½“å‰æ¨¡å‹ç±»å‹åˆ·æ–°åˆ—è¡¨
        def _delete_and_refresh(folder_name: str, which: str):
            status, _ = delete_model(folder_name)
            return status, _list_model_paths(which)

        delete_btn.click(
            fn=_delete_and_refresh,
            inputs=[selected_model, model_type],
            outputs=[model_status, model_list]
        )

        convert_btn.click(
            fn=convert_checkpoint_to_pt,
            inputs=selected_model,
            outputs=model_status
        )
        
        # ç›‘å¬æ¨¡å‹ç±»å‹å˜åŒ–ï¼Œè‡ªåŠ¨è°ƒæ•´batch_sizeé™åˆ¶å’Œç²¾åº¦é€‰é¡¹
        def update_model_constraints(model_type_val):
            batch_update = update_batch_size_constraints(model_type_val)
            precision_updates = update_precision_options(model_type_val)
            out_dir_value = "checkpoints/training_llm" if model_type_val == "llm" else "checkpoints/training_flow"
            ckpt_value = "jzx-ai-lab/HydraVox-CV3/llm.pt" if model_type_val == "llm" else "jzx-ai-lab/HydraVox-CV3/flow.pt"
            return (batch_update,) + precision_updates + (gr.update(value=out_dir_value), gr.update(value=ckpt_value))
        
        model_type.change(
            fn=update_model_constraints,
            inputs=model_type,
            outputs=[batch_size, precision_choice, precision_info, output_dir, model_checkpoint]
        )

        # åˆ·æ–°è®¾å¤‡æ£€æµ‹
        detect_btn.click(
            fn=_refresh_device_triplet,
            inputs=[],
            outputs=[device_info, gpu_processes, device_choice]
        )
       
