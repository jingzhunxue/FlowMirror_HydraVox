#!/usr/bin/env python3
# scripts/preprocess/extract_speech_token_dataset.py
"""
æ‰¹é‡å¤„ç† HuggingFace Datasetï¼Œæå– CosyVoice speech_token + CampPlus spk_embeddingã€‚

ç”¨æ³•ï¼š
python extract_speech_token_dataset.py \
        --input data/processed/asr_ds_gpu \
        --output data/processed/token_ds \
        --device cuda           # æˆ– cpu
        --num-proc 8            # map å¹¶å‘è¿›ç¨‹
        --slice 0 50000         # è£å‰ª [start, end) å¯é€‰
"""

import argparse
import os
from pathlib import Path
from typing import Dict, Any

import numpy as np
import torch
import torchaudio
from datasets import load_from_disk
from tqdm import tqdm

from audio import mel_spectrogram

import whisper

# ----------- i18n -------------
_TRANSLATIONS = {
    "âœ… CampPlus æ¨¡å‹å·²å­˜åœ¨: {path}": {"en": "âœ… CampPlus model already exists: {path}"},
    "âš ï¸ æ£€æŸ¥æœ¬åœ°æ¨¡å‹æ—¶å‡ºé”™: {error}": {"en": "âš ï¸ Failed to check local model: {error}"},
    "ğŸ“¥ æ­£åœ¨ä¸‹è½½ CampPlus æ¨¡å‹åˆ°: {path}": {"en": "ğŸ“¥ Downloading CampPlus model to: {path}"},
    "âœ… åˆ›å»ºè½¯é“¾æ¥: {dst} -> {src}": {"en": "âœ… Created symlink: {dst} -> {src}"},
    "âœ… å¤åˆ¶æ¨¡å‹æ–‡ä»¶åˆ°: {path}": {"en": "âœ… Copied model files to: {path}"},
    "âœ… CampPlus æ¨¡å‹å‡†å¤‡å®Œæˆ: {path}": {"en": "âœ… CampPlus model ready: {path}"},
    "âŒ ä¸‹è½½ CampPlus æ¨¡å‹å¤±è´¥: {error}": {"en": "âŒ Failed to download CampPlus model: {error}"},
    "ğŸ’¡ å›é€€åˆ°åœ¨çº¿æ¨¡å¼...": {"en": "ğŸ’¡ Falling back to online mode..."},
    "âš ï¸ è·³è¿‡è¶…é•¿éŸ³é¢‘æ ·æœ¬ (rank {rank}): {duration:.1f}s > 30s": {
        "en": "âš ï¸ Skipping overlong audio sample (rank {rank}): {duration:.1f}s > 30s"
    },
    "âš ï¸ å¤„ç†æ ·æœ¬æ—¶å‡ºé”™ (rank {rank}): {error}": {
        "en": "âš ï¸ Failed to process sample (rank {rank}): {error}"
    },
    "HF dataset è·¯å¾„": {"en": "HF dataset path"},
    "ä¿å­˜è·¯å¾„": {"en": "Output path"},
    "cpu / cuda": {"en": "cpu / cuda"},
    "datasets.map å¹¶å‘": {"en": "datasets.map workers"},
    "è£å‰ª start end (é—­å¼€åŒºé—´)": {"en": "Slice start end (half-open interval)"},
    "è·³è¿‡æ•°æ®æ¸…æ´—æ­¥éª¤ï¼Œä¿ç•™æ‰€æœ‰æ ·æœ¬ï¼ˆåŒ…æ‹¬é—®é¢˜æ ·æœ¬ï¼‰": {
        "en": "Skip data cleaning and keep all samples (including problematic ones)"
    },
    "ğŸ”„ æ£€æŸ¥å¹¶ä¸‹è½½ CampPlus æ¨¡å‹...": {"en": "ğŸ”„ Checking and downloading CampPlus model..."},
    "å·²åŠ è½½æ•°æ®é›†: {count} æ¡æ ·æœ¬": {"en": "Loaded dataset: {count} examples"},
    "ğŸš€ å¼€å§‹æå– speech tokenï¼Œä½¿ç”¨ {num_proc} ä¸ªè¿›ç¨‹...": {
        "en": "ğŸš€ Extracting speech tokens with {num_proc} processes..."
    },
    "âœ… Token æå–å®Œæˆï¼Œå…±å¤„ç† {count} ä¸ªæ ·æœ¬": {"en": "âœ… Token extraction done, processed {count} samples"},
    "âŒ Token æå–å¤±è´¥: {error}": {"en": "âŒ Token extraction failed: {error}"},
    "ğŸ’¡ å»ºè®®:": {"en": "ğŸ’¡ Suggestions:"},
    "   1. å‡å°‘ --num-proc å‚æ•°å€¼": {"en": "   1. Reduce the --num-proc value"},
    "   2. æ£€æŸ¥ GPU å†…å­˜æ˜¯å¦å……è¶³": {"en": "   2. Check if GPU memory is sufficient"},
    "   3. æ£€æŸ¥è¾“å…¥æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®": {"en": "   3. Check whether input data format is correct"},
    "ğŸ§¹ å¼€å§‹æ¸…æ´—æ•°æ®ï¼Œè¿‡æ»¤é—®é¢˜æ ·æœ¬...": {"en": "ğŸ§¹ Cleaning data and filtering problematic samples..."},
    "ğŸ“Š æ•°æ®æ¸…æ´—å®Œæˆ:": {"en": "ğŸ“Š Data cleaning completed:"},
    "   â€¢ åŸå§‹æ ·æœ¬æ•°: {count}": {"en": "   â€¢ Original samples: {count}"},
    "   â€¢ æœ‰æ•ˆæ ·æœ¬æ•°: {count}": {"en": "   â€¢ Valid samples: {count}"},
    "   â€¢ è¿‡æ»¤æ ·æœ¬æ•°: {count} ({ratio:.1f}%)": {"en": "   â€¢ Filtered samples: {count} ({ratio:.1f}%)"},
    "ğŸ” é—®é¢˜æ ·æœ¬ç»Ÿè®¡:": {"en": "ğŸ” Problem sample stats:"},
    "   â€¢ {problem_type}: {count} ä¸ª": {"en": "   â€¢ {problem_type}: {count}"},
    "âŒ æ¸…æ´—åæ²¡æœ‰æœ‰æ•ˆæ ·æœ¬ï¼Œè¯·æ£€æŸ¥è¾“å…¥æ•°æ®å’Œå¤„ç†é€»è¾‘": {
        "en": "âŒ No valid samples after cleaning; check input data and logic"
    },
    "âš ï¸ è·³è¿‡æ•°æ®æ¸…æ´—æ­¥éª¤ï¼Œä¿ç•™æ‰€æœ‰æ ·æœ¬ï¼ˆåŒ…æ‹¬é—®é¢˜æ ·æœ¬ï¼‰": {
        "en": "âš ï¸ Skipping data cleaning; keeping all samples (including problematic ones)"
    },
    "ğŸ“ˆ æ•°æ®è´¨é‡ç»Ÿè®¡:": {"en": "ğŸ“ˆ Data quality stats:"},
    "   â€¢ Token é•¿åº¦: å¹³å‡ {avg:.1f}, èŒƒå›´ [{min}, {max}]": {
        "en": "   â€¢ Token length: avg {avg:.1f}, range [{min}, {max}]"
    },
    "   â€¢ Speech feat é•¿åº¦: å¹³å‡ {avg:.1f}, èŒƒå›´ [{min}, {max}]": {
        "en": "   â€¢ Speech feat length: avg {avg:.1f}, range [{min}, {max}]"
    },
    "   â€¢ Embedding ç»´åº¦: {dim}": {"en": "   â€¢ Embedding dim: {dim}"},
    "   âš ï¸ ç»Ÿè®¡ä¿¡æ¯è®¡ç®—å¤±è´¥: {error}": {"en": "   âš ï¸ Failed to compute stats: {error}"},
    "æ¸…æ´—åçš„": {"en": "cleaned "},
    "ğŸ’¾ ä¿å­˜{suffix}æ•°æ®é›†åˆ°: {path}": {"en": "ğŸ’¾ Saving {suffix}dataset to: {path}"},
    "step 5/5: âœ… å…¨éƒ¨å®Œæˆï¼å¤„ç†åçš„æ•°æ®é›† -> {path}": {
        "en": "step 5/5: âœ… All Finished! processed dataset â†’ {path}"
    },
    "ğŸ“ˆ æœ€ç»ˆä¿å­˜ {count} ä¸ª{suffix}æ ·æœ¬": {"en": "ğŸ“ˆ Saved {count} {suffix}samples"},
    "âŒ ä¿å­˜æ•°æ®é›†å¤±è´¥: {error}": {"en": "âŒ Failed to save dataset: {error}"},
}


def _t(text: str, **kwargs: Any) -> str:
    lang = os.getenv("HYDRAVOX_LANG", os.getenv("HYDRAVOX_UI_LANG", "zh")).lower()
    if lang not in ("zh", "en"):
        lang = "zh"
    entry = _TRANSLATIONS.get(text)
    result = entry.get(lang, text) if entry else text
    if kwargs:
        try:
            return result.format(**kwargs)
        except Exception:
            return result
    return result

# ----------- æ¨¡å‹è·¯å¾„ -------------
TOKENIZER_ONNX_PATH = Path(
    "jzx-ai-lab/HydraVox-CV3/speech_tokenizer_v3.onnx"
).expanduser().resolve()

# æœ¬åœ°æ¨¡å‹è·¯å¾„
CAMPPLUS_MODEL_DIR = Path("jzx-ai-lab/speech_campplus_sv_zh-cn_16k-common").resolve()

# è‹¥éœ€è¦è‡ªå®šä¹‰ GPU æ•°ï¼Œä¿®æ”¹æ­¤å¤„
NUM_SESSIONS_PER_PROC = 1

# ----------- å…¨å±€ç¼“å­˜ -------------
SESSION_CACHE: Dict[int, Dict[str, Any]] = {}

def download_campplus_model():
    """ä¸‹è½½ CampPlus æ¨¡å‹åˆ°æœ¬åœ°"""
    try:
        if CAMPPLUS_MODEL_DIR.exists() and any(CAMPPLUS_MODEL_DIR.iterdir()):
            print(_t("âœ… CampPlus æ¨¡å‹å·²å­˜åœ¨: {path}", path=CAMPPLUS_MODEL_DIR))
            return str(CAMPPLUS_MODEL_DIR)
    except (OSError, PermissionError) as e:
        print(_t("âš ï¸ æ£€æŸ¥æœ¬åœ°æ¨¡å‹æ—¶å‡ºé”™: {error}", error=e))
    
    print(_t("ğŸ“¥ æ­£åœ¨ä¸‹è½½ CampPlus æ¨¡å‹åˆ°: {path}", path=CAMPPLUS_MODEL_DIR))
    try:
        from modelscope import snapshot_download
        
        # åˆ›å»ºæ¨¡å‹ç›®å½•
        CAMPPLUS_MODEL_DIR.parent.mkdir(parents=True, exist_ok=True)
        
        # ä¸‹è½½æ¨¡å‹åˆ°æŒ‡å®šç›®å½•
        model_path = snapshot_download(
            model_id="iic/speech_campplus_sv_zh-cn_16k-common",
            revision="v1.0.0",
            cache_dir=str(CAMPPLUS_MODEL_DIR.parent / "modelscope_cache")
        )
        
        # å¦‚æœä¸‹è½½è·¯å¾„ä¸ç›®æ ‡è·¯å¾„ä¸åŒï¼Œåˆ›å»ºè½¯é“¾æ¥æˆ–å¤åˆ¶
        import shutil
        if Path(model_path).resolve() != CAMPPLUS_MODEL_DIR.resolve():
            if CAMPPLUS_MODEL_DIR.exists():
                shutil.rmtree(CAMPPLUS_MODEL_DIR)
            
            # å°è¯•åˆ›å»ºè½¯é“¾æ¥ï¼Œå¦‚æœå¤±è´¥åˆ™å¤åˆ¶
            try:
                CAMPPLUS_MODEL_DIR.symlink_to(Path(model_path).resolve())
                print(_t("âœ… åˆ›å»ºè½¯é“¾æ¥: {dst} -> {src}", dst=CAMPPLUS_MODEL_DIR, src=model_path))
            except (OSError, NotImplementedError):
                shutil.copytree(model_path, CAMPPLUS_MODEL_DIR)
                print(_t("âœ… å¤åˆ¶æ¨¡å‹æ–‡ä»¶åˆ°: {path}", path=CAMPPLUS_MODEL_DIR))
        
        print(_t("âœ… CampPlus æ¨¡å‹å‡†å¤‡å®Œæˆ: {path}", path=CAMPPLUS_MODEL_DIR))
        return str(CAMPPLUS_MODEL_DIR)
        
    except Exception as e:
        print(_t("âŒ ä¸‹è½½ CampPlus æ¨¡å‹å¤±è´¥: {error}", error=e))
        print(_t("ğŸ’¡ å›é€€åˆ°åœ¨çº¿æ¨¡å¼..."))
        return "iic/speech_campplus_sv_zh-cn_16k-common"

def get_multi_sessions(rank: int, device: str):
    """
    ä¸º datasets.map æ¯ä¸ªè¿›ç¨‹ç¼“å­˜ onnx session & speaker verification pipeline
    """
    # æ ¹æ® rank è®¡ç®—å…·ä½“çš„ GPU è®¾å¤‡ ID
    if device.startswith("cuda"):
        num_gpus = torch.cuda.device_count()
        device_id = rank % num_gpus
        specific_device = f"cuda:{device_id}"
    else:
        specific_device = device
        device_id = 0
    
    key = (rank, device)
    if key not in SESSION_CACHE:
        import onnxruntime as ort
        so = ort.SessionOptions()
        so.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
        so.intra_op_num_threads = 1

        providers = (
            [("CUDAExecutionProvider", {"device_id": device_id})]
            if device.startswith("cuda")
            else ["CPUExecutionProvider"]
        )

        tokenizer_sessions = [
            ort.InferenceSession(TOKENIZER_ONNX_PATH.as_posix(),
                                 sess_options=so,
                                 providers=providers)
            for _ in range(NUM_SESSIONS_PER_PROC)
        ]

        # è·å–æœ¬åœ°æ¨¡å‹è·¯å¾„æˆ–åœ¨çº¿æ¨¡å‹ID
        try:
            model_exists = CAMPPLUS_MODEL_DIR.exists() and any(CAMPPLUS_MODEL_DIR.iterdir())
        except (OSError, PermissionError):
            model_exists = False
        model_path = str(CAMPPLUS_MODEL_DIR) if model_exists else "iic/speech_campplus_sv_zh-cn_16k-common"

        from modelscope.pipelines import pipeline
        sv_pipe = pipeline(
            task="speaker-verification",
            model=model_path,
            model_revision="v1.0.0" if not model_exists else None,
            device=specific_device,  # ä½¿ç”¨å…·ä½“çš„è®¾å¤‡ ID
        )

        SESSION_CACHE[key] = {
            "tokenizers": tokenizer_sessions,
            "sv_pipeline": sv_pipe,
            "counter": 0,
        }
    return SESSION_CACHE[key]

# ----------- map å›è°ƒ -------------
def extract_speech_token(example, rank: int, device: str):
    """
    example: {'audio': {'array': np.ndarray, 'sampling_rate': 16000}}
    è¿”å›ï¼šspeech_token (list[int]), spk_embedding (np.ndarray[float32])
    """
    try:
        sessions = get_multi_sessions(rank, device)
        tk_list = sessions["tokenizers"]
        sv_pipe = sessions["sv_pipeline"]

        tk_session = tk_list[sessions["counter"] % len(tk_list)]
        sessions["counter"] += 1

        arr = example["array"]
        sr = example["sampling_rate"]

        # torch å¼ é‡ï¼Œä¿è¯ mono & 16k
        wav = torch.from_numpy(arr).float().unsqueeze(0)  # (1, T)
        if sr != 16000:
            wav = torchaudio.functional.resample(wav, sr, 16000)
        if wav.shape[0] > 1:
            wav = wav.mean(dim=0, keepdim=True)

        # é•¿åº¦ä¸Šé™ï¼š30 s
            duration_sec = wav.shape[1] / 16000
            if duration_sec > 30:
                # è¿”å›ç©ºå€¼ï¼Œä½†ä¿æŒå­—æ®µç»“æ„ä¸€è‡´
                print(_t("âš ï¸ è·³è¿‡è¶…é•¿éŸ³é¢‘æ ·æœ¬ (rank {rank}): {duration:.1f}s > 30s", rank=rank, duration=duration_sec))
                return {
                    "speech_token": [], 
                    "speech_token_len": 0,
                    "speech_feat": np.array([], dtype=np.float32).reshape(0, 80),  # ä¿æŒæ­£ç¡®çš„ç»´åº¦
                    "speech_feat_len": 0,
                    "embedding": np.array([], dtype=np.float32)
                }

        # --- speech tokenizer ---
        mel = whisper.log_mel_spectrogram(wav, n_mels=128)  # (1, 128, T')
        ort_inputs = {
            tk_session.get_inputs()[0].name: mel.cpu().numpy(),
            tk_session.get_inputs()[1].name: np.array([mel.shape[2]], dtype=np.int32),
        }
        speech_token = tk_session.run(None, ort_inputs)[0].flatten().tolist()
        speech_token_len = len(speech_token)
            
        # --- speaker embedding ---
        sv_out = sv_pipe([arr], output_emb=True)
        emb = np.array(sv_out["embs"][0], dtype=np.float32)

        resample_rate = 24000
        audio_resampled = torchaudio.transforms.Resample(orig_freq=16000, new_freq=resample_rate)(wav)
        # é¢„ä¼°è¾“å‡ºé•¿åº¦å¹¶è°ƒæ•´éŸ³é¢‘ä½¿å…¶äº§ç”Ÿå¶æ•°é•¿åº¦çš„melç‰¹å¾
        estimated_frames = (audio_resampled.shape[-1] - 480) // 480 + 1
        if estimated_frames % 2 == 1:
            # å¦‚æœé¢„ä¼°é•¿åº¦æ˜¯å¥‡æ•°ï¼Œè°ƒæ•´éŸ³é¢‘é•¿åº¦
            padding_needed = 480  # æ·»åŠ ä¸€ä¸ªhop_sizeçš„é•¿åº¦
            audio_resampled = torch.nn.functional.pad(audio_resampled, (0, padding_needed))
        
        mel_feat = mel_spectrogram(audio_resampled, 1920, 80, resample_rate, 480, 1920, 0, 8000, False)
        mel_feat = mel_feat.squeeze(0).transpose(0, 1).cpu().numpy()
        mel_feat_len = len(mel_feat)

        return {
            "speech_token": speech_token, 
            "speech_token_len": speech_token_len, 
            "speech_feat": mel_feat, 
            "speech_feat_len": mel_feat_len, 
            "embedding": emb
        }
        
    except Exception as e:
        # å‘ç”Ÿé”™è¯¯æ—¶è¿”å›ç©ºå€¼ï¼Œä½†ä¿æŒå­—æ®µç»“æ„ä¸€è‡´
        print(_t("âš ï¸ å¤„ç†æ ·æœ¬æ—¶å‡ºé”™ (rank {rank}): {error}", rank=rank, error=e))
        return {
            "speech_token": [], 
            "speech_token_len": 0,
            "speech_feat": np.array([], dtype=np.float32).reshape(0, 80),
            "speech_feat_len": 0,
            "embedding": np.array([], dtype=np.float32)
        }

# ----------- ä¸»å‡½æ•° -------------
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", type=Path, required=True, help=_t("HF dataset è·¯å¾„"))
    parser.add_argument("--output", type=Path, required=True, help=_t("ä¿å­˜è·¯å¾„"))
    parser.add_argument("--device", default="cpu", choices=["cpu", "cuda"],
                        help=_t("cpu / cuda"))
    parser.add_argument("--num-proc", type=int, default=4, help=_t("datasets.map å¹¶å‘"))
    parser.add_argument("--slice", nargs=2, type=int, metavar=("START", "END"),
                        help=_t("è£å‰ª start end (é—­å¼€åŒºé—´)"))
    parser.add_argument("--skip-cleaning", action="store_true", 
                        help=_t("è·³è¿‡æ•°æ®æ¸…æ´—æ­¥éª¤ï¼Œä¿ç•™æ‰€æœ‰æ ·æœ¬ï¼ˆåŒ…æ‹¬é—®é¢˜æ ·æœ¬ï¼‰"))
    args = parser.parse_args()

    Path(args.output).parent.mkdir(parents=True, exist_ok=True)

    # ä¸‹è½½ CampPlus æ¨¡å‹åˆ°æœ¬åœ°
    print(_t("ğŸ”„ æ£€æŸ¥å¹¶ä¸‹è½½ CampPlus æ¨¡å‹..."))
    download_campplus_model()

    ds = load_from_disk(str(args.input))
    if args.slice:
        start, end = args.slice
        ds = ds.select(range(start, end))

    print(_t("å·²åŠ è½½æ•°æ®é›†: {count} æ¡æ ·æœ¬", count=len(ds)))

    # datasets.map å¸¦ rank
    try:
        print(_t("ğŸš€ å¼€å§‹æå– speech tokenï¼Œä½¿ç”¨ {num_proc} ä¸ªè¿›ç¨‹...", num_proc=args.num_proc))
        ds_out = ds.map(
            lambda ex, rank=0: extract_speech_token(ex, rank=rank, device=args.device),
            with_rank=True,
            num_proc=args.num_proc,
            desc="Extracting tokens & embeddings",
            input_columns=["audio"],
        )
        print(_t("âœ… Token æå–å®Œæˆï¼Œå…±å¤„ç† {count} ä¸ªæ ·æœ¬", count=len(ds_out)))
    except Exception as e:
        print(_t("âŒ Token æå–å¤±è´¥: {error}", error=e))
        print(_t("ğŸ’¡ å»ºè®®:"))
        print(_t("   1. å‡å°‘ --num-proc å‚æ•°å€¼"))
        print(_t("   2. æ£€æŸ¥ GPU å†…å­˜æ˜¯å¦å……è¶³"))
        print(_t("   3. æ£€æŸ¥è¾“å…¥æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®"))
        raise

    # æ¸…æ´—æ•°æ®ï¼šè¿‡æ»¤æ‰é—®é¢˜æ ·æœ¬
    if not args.skip_cleaning:
        print(_t("ğŸ§¹ å¼€å§‹æ¸…æ´—æ•°æ®ï¼Œè¿‡æ»¤é—®é¢˜æ ·æœ¬..."))
        original_count = len(ds_out)
        
        # ç»Ÿè®¡å„ç±»é—®é¢˜æ ·æœ¬
        stats = {
            "empty_token": 0,
            "empty_embedding": 0, 
            "empty_speech_feat": 0,
            "invalid_token_range": 0,
            "invalid_embedding_dim": 0
        }
        
        def is_valid_sample(example):
            """æ£€æŸ¥æ ·æœ¬æ˜¯å¦æœ‰æ•ˆï¼Œå¹¶ç»Ÿè®¡é—®é¢˜ç±»å‹"""
            # æ£€æŸ¥ speech_token
            speech_token = example.get("speech_token", [])
            speech_token_len = example.get("speech_token_len", 0)
            if len(speech_token) == 0 or speech_token_len == 0:
                stats["empty_token"] += 1
                return False
                
            # æ£€æŸ¥ token å€¼æ˜¯å¦åœ¨åˆç†èŒƒå›´å†… (é€šå¸¸åº”è¯¥æ˜¯æ­£æ•´æ•°)
            if len(speech_token) > 0:
                try:
                    if min(speech_token) < 0 or max(speech_token) > 100000:  # è®¾ç½®åˆç†çš„ä¸Šä¸‹é™
                        stats["invalid_token_range"] += 1
                        return False
                except (ValueError, TypeError):
                    stats["invalid_token_range"] += 1
                    return False
            
            # æ£€æŸ¥ embedding
            embedding = example.get("embedding", [])
            if len(embedding) == 0:
                stats["empty_embedding"] += 1
                return False
                
            # æ£€æŸ¥ embedding ç»´åº¦ (CampPlus é€šå¸¸æ˜¯ 192 ç»´)
            if len(embedding) != 192:
                stats["invalid_embedding_dim"] += 1
                return False
            
            # æ£€æŸ¥ speech_feat
            speech_feat = example.get("speech_feat", [])
            speech_feat_len = example.get("speech_feat_len", 0)
            if len(speech_feat) == 0 or speech_feat_len == 0:
                stats["empty_speech_feat"] += 1
                return False
                
            # æ£€æŸ¥ speech_feat ç»´åº¦ (melç‰¹å¾é€šå¸¸æ˜¯ 80 ç»´)
            try:
                if len(speech_feat) > 0 and len(speech_feat[0]) != 80:
                    stats["empty_speech_feat"] += 1
                    return False
            except (IndexError, TypeError):
                stats["empty_speech_feat"] += 1
                return False
                
            return True
        
        # è¿‡æ»¤æœ‰æ•ˆæ ·æœ¬
        ds_clean = ds_out.filter(is_valid_sample, desc="Filtering valid samples")
        cleaned_count = len(ds_clean)
        filtered_count = original_count - cleaned_count
        
        print(_t("ğŸ“Š æ•°æ®æ¸…æ´—å®Œæˆ:"))
        print(_t("   â€¢ åŸå§‹æ ·æœ¬æ•°: {count}", count=original_count))
        print(_t("   â€¢ æœ‰æ•ˆæ ·æœ¬æ•°: {count}", count=cleaned_count))
        print(_t("   â€¢ è¿‡æ»¤æ ·æœ¬æ•°: {count} ({ratio:.1f}%)", count=filtered_count, ratio=filtered_count/original_count*100))
        
        if filtered_count > 0:
            print(_t("ğŸ” é—®é¢˜æ ·æœ¬ç»Ÿè®¡:"))
            for problem_type, count in stats.items():
                if count > 0:
                    print(_t("   â€¢ {problem_type}: {count} ä¸ª", problem_type=problem_type, count=count))
        
        if cleaned_count == 0:
            print(_t("âŒ æ¸…æ´—åæ²¡æœ‰æœ‰æ•ˆæ ·æœ¬ï¼Œè¯·æ£€æŸ¥è¾“å…¥æ•°æ®å’Œå¤„ç†é€»è¾‘"))
            return
    else:
        print(_t("âš ï¸ è·³è¿‡æ•°æ®æ¸…æ´—æ­¥éª¤ï¼Œä¿ç•™æ‰€æœ‰æ ·æœ¬ï¼ˆåŒ…æ‹¬é—®é¢˜æ ·æœ¬ï¼‰"))
        ds_clean = ds_out
        cleaned_count = len(ds_out)

    # æ•°æ®è´¨é‡ç»Ÿè®¡
    if cleaned_count > 0:
        print(_t("ğŸ“ˆ æ•°æ®è´¨é‡ç»Ÿè®¡:"))
        try:
            # éšæœºé‡‡æ ·ä¸€äº›æ ·æœ¬è¿›è¡Œç»Ÿè®¡
            sample_size = min(100, cleaned_count)
            sample_ds = ds_clean.select(range(sample_size))
            
            token_lengths = [len(ex["speech_token"]) for ex in sample_ds]
            feat_lengths = [ex["speech_feat_len"] for ex in sample_ds]
            
            print(_t(
                "   â€¢ Token é•¿åº¦: å¹³å‡ {avg:.1f}, èŒƒå›´ [{min}, {max}]",
                avg=sum(token_lengths)/len(token_lengths),
                min=min(token_lengths),
                max=max(token_lengths),
            ))
            print(_t(
                "   â€¢ Speech feat é•¿åº¦: å¹³å‡ {avg:.1f}, èŒƒå›´ [{min}, {max}]",
                avg=sum(feat_lengths)/len(feat_lengths),
                min=min(feat_lengths),
                max=max(feat_lengths),
            ))
            print(_t("   â€¢ Embedding ç»´åº¦: {dim}", dim=len(sample_ds[0]['embedding'])))
        except Exception as e:
            print(_t("   âš ï¸ ç»Ÿè®¡ä¿¡æ¯è®¡ç®—å¤±è´¥: {error}", error=e))

    try:
        suffix = _t("æ¸…æ´—åçš„") if not args.skip_cleaning else ""
        print(_t("ğŸ’¾ ä¿å­˜{suffix}æ•°æ®é›†åˆ°: {path}", suffix=suffix, path=args.output))
        ds_clean.save_to_disk(str(args.output))
        print(_t("step 5/5: âœ… å…¨éƒ¨å®Œæˆï¼å¤„ç†åçš„æ•°æ®é›† -> {path}", path=args.output))
        suffix = _t("æ¸…æ´—åçš„") if not args.skip_cleaning else ""
        print(_t("ğŸ“ˆ æœ€ç»ˆä¿å­˜ {count} ä¸ª{suffix}æ ·æœ¬", count=cleaned_count, suffix=suffix))
    except Exception as e:
        print(_t("âŒ ä¿å­˜æ•°æ®é›†å¤±è´¥: {error}", error=e))
        raise

if __name__ == "__main__":
    main()
