#!/usr/bin/env python3
# scripts/preprocess/extract_speech_token_dataset.py
"""
æ‰¹é‡å¤„ç† HuggingFace Datasetï¼Œæå– CosyVoice speech_token + CampPlus spk_embeddingã€‚

ç”¨æ³•ï¼š
python extract_speech_token_dataset.py \
        --input data/processed/asr_ds_gpu \
        --output data/processed/token_ds \
        --device cuda           # æˆ– cpu
        --num-proc 8            # map å¹¶å‘è¿›ç¨‹
        --slice 0 50000         # è£å‰ª [start, end) å¯é€‰
"""

import argparse
import os
from pathlib import Path
from typing import Dict, Any

import numpy as np
import torch
import torchaudio
from datasets import load_from_disk
from tqdm import tqdm

from audio import mel_spectrogram

import whisper

# ----------- æ¨¡å‹è·¯å¾„ -------------
TOKENIZER_ONNX_PATH = Path(
    "models/CosyVoice2-0.5B/speech_tokenizer_v2.onnx"
).expanduser().resolve()

# æœ¬åœ°æ¨¡å‹è·¯å¾„
CAMPPLUS_MODEL_DIR = Path("models/speech_campplus_sv_zh-cn_16k-common").resolve()

# è‹¥éœ€è¦è‡ªå®šä¹‰ GPU æ•°ï¼Œä¿®æ”¹æ­¤å¤„
NUM_SESSIONS_PER_PROC = 1

# ----------- å…¨å±€ç¼“å­˜ -------------
SESSION_CACHE: Dict[int, Dict[str, Any]] = {}

def download_campplus_model():
    """ä¸‹è½½ CampPlus æ¨¡å‹åˆ°æœ¬åœ°"""
    try:
        if CAMPPLUS_MODEL_DIR.exists() and any(CAMPPLUS_MODEL_DIR.iterdir()):
            print(f"âœ… CampPlus æ¨¡å‹å·²å­˜åœ¨: {CAMPPLUS_MODEL_DIR}")
            return str(CAMPPLUS_MODEL_DIR)
    except (OSError, PermissionError) as e:
        print(f"âš ï¸ æ£€æŸ¥æœ¬åœ°æ¨¡å‹æ—¶å‡ºé”™: {e}")
    
    print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½ CampPlus æ¨¡å‹åˆ°: {CAMPPLUS_MODEL_DIR}")
    try:
        from modelscope import snapshot_download
        
        # åˆ›å»ºæ¨¡å‹ç›®å½•
        CAMPPLUS_MODEL_DIR.parent.mkdir(parents=True, exist_ok=True)
        
        # ä¸‹è½½æ¨¡å‹åˆ°æŒ‡å®šç›®å½•
        model_path = snapshot_download(
            model_id="iic/speech_campplus_sv_zh-cn_16k-common",
            revision="v1.0.0",
            cache_dir=str(CAMPPLUS_MODEL_DIR.parent / "modelscope_cache")
        )
        
        # å¦‚æœä¸‹è½½è·¯å¾„ä¸ç›®æ ‡è·¯å¾„ä¸åŒï¼Œåˆ›å»ºè½¯é“¾æ¥æˆ–å¤åˆ¶
        import shutil
        if Path(model_path).resolve() != CAMPPLUS_MODEL_DIR.resolve():
            if CAMPPLUS_MODEL_DIR.exists():
                shutil.rmtree(CAMPPLUS_MODEL_DIR)
            
            # å°è¯•åˆ›å»ºè½¯é“¾æ¥ï¼Œå¦‚æœå¤±è´¥åˆ™å¤åˆ¶
            try:
                CAMPPLUS_MODEL_DIR.symlink_to(Path(model_path).resolve())
                print(f"âœ… åˆ›å»ºè½¯é“¾æ¥: {CAMPPLUS_MODEL_DIR} -> {model_path}")
            except (OSError, NotImplementedError):
                shutil.copytree(model_path, CAMPPLUS_MODEL_DIR)
                print(f"âœ… å¤åˆ¶æ¨¡å‹æ–‡ä»¶åˆ°: {CAMPPLUS_MODEL_DIR}")
        
        print(f"âœ… CampPlus æ¨¡å‹å‡†å¤‡å®Œæˆ: {CAMPPLUS_MODEL_DIR}")
        return str(CAMPPLUS_MODEL_DIR)
        
    except Exception as e:
        print(f"âŒ ä¸‹è½½ CampPlus æ¨¡å‹å¤±è´¥: {e}")
        print("ğŸ’¡ å›é€€åˆ°åœ¨çº¿æ¨¡å¼...")
        return "iic/speech_campplus_sv_zh-cn_16k-common"

def get_multi_sessions(rank: int, device: str):
    """
    ä¸º datasets.map æ¯ä¸ªè¿›ç¨‹ç¼“å­˜ onnx session & speaker verification pipeline
    """
    # æ ¹æ® rank è®¡ç®—å…·ä½“çš„ GPU è®¾å¤‡ ID
    if device.startswith("cuda"):
        num_gpus = torch.cuda.device_count()
        device_id = rank % num_gpus
        specific_device = f"cuda:{device_id}"
    else:
        specific_device = device
        device_id = 0
    
    key = (rank, device)
    if key not in SESSION_CACHE:
        import onnxruntime as ort
        so = ort.SessionOptions()
        so.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
        so.intra_op_num_threads = 1

        providers = (
            [("CUDAExecutionProvider", {"device_id": device_id})]
            if device.startswith("cuda")
            else ["CPUExecutionProvider"]
        )

        tokenizer_sessions = [
            ort.InferenceSession(TOKENIZER_ONNX_PATH.as_posix(),
                                 sess_options=so,
                                 providers=providers)
            for _ in range(NUM_SESSIONS_PER_PROC)
        ]

        # è·å–æœ¬åœ°æ¨¡å‹è·¯å¾„æˆ–åœ¨çº¿æ¨¡å‹ID
        try:
            model_exists = CAMPPLUS_MODEL_DIR.exists() and any(CAMPPLUS_MODEL_DIR.iterdir())
        except (OSError, PermissionError):
            model_exists = False
        model_path = str(CAMPPLUS_MODEL_DIR) if model_exists else "iic/speech_campplus_sv_zh-cn_16k-common"

        from modelscope.pipelines import pipeline
        sv_pipe = pipeline(
            task="speaker-verification",
            model=model_path,
            model_revision="v1.0.0" if not model_exists else None,
            device=specific_device,  # ä½¿ç”¨å…·ä½“çš„è®¾å¤‡ ID
        )

        SESSION_CACHE[key] = {
            "tokenizers": tokenizer_sessions,
            "sv_pipeline": sv_pipe,
            "counter": 0,
        }
    return SESSION_CACHE[key]

# ----------- map å›è°ƒ -------------
def extract_speech_token(example, rank: int, device: str):
    """
    example: {'audio': {'array': np.ndarray, 'sampling_rate': 16000}}
    è¿”å›ï¼šspeech_token (list[int]), spk_embedding (np.ndarray[float32])
    """
    try:
        sessions = get_multi_sessions(rank, device)
        tk_list = sessions["tokenizers"]
        sv_pipe = sessions["sv_pipeline"]

        tk_session = tk_list[sessions["counter"] % len(tk_list)]
        sessions["counter"] += 1

        arr = example["array"]
        sr = example["sampling_rate"]

        # torch å¼ é‡ï¼Œä¿è¯ mono & 16k
        wav = torch.from_numpy(arr).float().unsqueeze(0)  # (1, T)
        if sr != 16000:
            wav = torchaudio.functional.resample(wav, sr, 16000)
        if wav.shape[0] > 1:
            wav = wav.mean(dim=0, keepdim=True)

        # é•¿åº¦ä¸Šé™ï¼š30 s
            duration_sec = wav.shape[1] / 16000
            if duration_sec > 30:
                # è¿”å›ç©ºå€¼ï¼Œä½†ä¿æŒå­—æ®µç»“æ„ä¸€è‡´
                print(f"âš ï¸ è·³è¿‡è¶…é•¿éŸ³é¢‘æ ·æœ¬ (rank {rank}): {duration_sec:.1f}s > 30s")
                return {
                    "speech_token": [], 
                    "speech_token_len": 0,
                    "speech_feat": np.array([], dtype=np.float32).reshape(0, 80),  # ä¿æŒæ­£ç¡®çš„ç»´åº¦
                    "speech_feat_len": 0,
                    "embedding": np.array([], dtype=np.float32)
                }

        # --- speech tokenizer ---
        mel = whisper.log_mel_spectrogram(wav, n_mels=128)  # (1, 128, T')
        ort_inputs = {
            tk_session.get_inputs()[0].name: mel.cpu().numpy(),
            tk_session.get_inputs()[1].name: np.array([mel.shape[2]], dtype=np.int32),
        }
        speech_token = tk_session.run(None, ort_inputs)[0].flatten().tolist()
        speech_token_len = len(speech_token)
            
        # --- speaker embedding ---
        sv_out = sv_pipe([arr], output_emb=True)
        emb = np.array(sv_out["embs"][0], dtype=np.float32)

        resample_rate = 24000
        audio_resampled = torchaudio.transforms.Resample(orig_freq=16000, new_freq=resample_rate)(wav)
        # é¢„ä¼°è¾“å‡ºé•¿åº¦å¹¶è°ƒæ•´éŸ³é¢‘ä½¿å…¶äº§ç”Ÿå¶æ•°é•¿åº¦çš„melç‰¹å¾
        estimated_frames = (audio_resampled.shape[-1] - 480) // 480 + 1
        if estimated_frames % 2 == 1:
            # å¦‚æœé¢„ä¼°é•¿åº¦æ˜¯å¥‡æ•°ï¼Œè°ƒæ•´éŸ³é¢‘é•¿åº¦
            padding_needed = 480  # æ·»åŠ ä¸€ä¸ªhop_sizeçš„é•¿åº¦
            audio_resampled = torch.nn.functional.pad(audio_resampled, (0, padding_needed))
        
        mel_feat = mel_spectrogram(audio_resampled, 1920, 80, resample_rate, 480, 1920, 0, 8000, False)
        mel_feat = mel_feat.squeeze(0).transpose(0, 1).cpu().numpy()
        mel_feat_len = len(mel_feat)

        return {
            "speech_token": speech_token, 
            "speech_token_len": speech_token_len, 
            "speech_feat": mel_feat, 
            "speech_feat_len": mel_feat_len, 
            "embedding": emb
        }
        
    except Exception as e:
        # å‘ç”Ÿé”™è¯¯æ—¶è¿”å›ç©ºå€¼ï¼Œä½†ä¿æŒå­—æ®µç»“æ„ä¸€è‡´
        print(f"âš ï¸ å¤„ç†æ ·æœ¬æ—¶å‡ºé”™ (rank {rank}): {e}")
        return {
            "speech_token": [], 
            "speech_token_len": 0,
            "speech_feat": np.array([], dtype=np.float32).reshape(0, 80),
            "speech_feat_len": 0,
            "embedding": np.array([], dtype=np.float32)
        }

# ----------- ä¸»å‡½æ•° -------------
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", type=Path, required=True, help="HF dataset è·¯å¾„")
    parser.add_argument("--output", type=Path, required=True, help="ä¿å­˜è·¯å¾„")
    parser.add_argument("--device", default="cpu", choices=["cpu", "cuda"],
                        help="cpu / cuda")
    parser.add_argument("--num-proc", type=int, default=4, help="datasets.map å¹¶å‘")
    parser.add_argument("--slice", nargs=2, type=int, metavar=("START", "END"),
                        help="è£å‰ª start end (é—­å¼€åŒºé—´)")
    parser.add_argument("--skip-cleaning", action="store_true", 
                        help="è·³è¿‡æ•°æ®æ¸…æ´—æ­¥éª¤ï¼Œä¿ç•™æ‰€æœ‰æ ·æœ¬ï¼ˆåŒ…æ‹¬é—®é¢˜æ ·æœ¬ï¼‰")
    args = parser.parse_args()

    Path(args.output).parent.mkdir(parents=True, exist_ok=True)

    # ä¸‹è½½ CampPlus æ¨¡å‹åˆ°æœ¬åœ°
    print("ğŸ”„ æ£€æŸ¥å¹¶ä¸‹è½½ CampPlus æ¨¡å‹...")
    download_campplus_model()

    ds = load_from_disk(str(args.input))
    if args.slice:
        start, end = args.slice
        ds = ds.select(range(start, end))

    print(f"Loaded dataset: {len(ds)} examples")

    # datasets.map å¸¦ rank
    try:
        print(f"ğŸš€ å¼€å§‹æå– speech tokenï¼Œä½¿ç”¨ {args.num_proc} ä¸ªè¿›ç¨‹...")
        ds_out = ds.map(
            lambda ex, rank=0: extract_speech_token(ex, rank=rank, device=args.device),
            with_rank=True,
            num_proc=args.num_proc,
            desc="Extracting tokens & embeddings",
            input_columns=["audio"],
        )
        print(f"âœ… Token æå–å®Œæˆï¼Œå…±å¤„ç† {len(ds_out)} ä¸ªæ ·æœ¬")
    except Exception as e:
        print(f"âŒ Token æå–å¤±è´¥: {e}")
        print("ğŸ’¡ å»ºè®®:")
        print("   1. å‡å°‘ --num-proc å‚æ•°å€¼")
        print("   2. æ£€æŸ¥ GPU å†…å­˜æ˜¯å¦å……è¶³")
        print("   3. æ£€æŸ¥è¾“å…¥æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®")
        raise

    # æ¸…æ´—æ•°æ®ï¼šè¿‡æ»¤æ‰é—®é¢˜æ ·æœ¬
    if not args.skip_cleaning:
        print(f"ğŸ§¹ å¼€å§‹æ¸…æ´—æ•°æ®ï¼Œè¿‡æ»¤é—®é¢˜æ ·æœ¬...")
        original_count = len(ds_out)
        
        # ç»Ÿè®¡å„ç±»é—®é¢˜æ ·æœ¬
        stats = {
            "empty_token": 0,
            "empty_embedding": 0, 
            "empty_speech_feat": 0,
            "invalid_token_range": 0,
            "invalid_embedding_dim": 0
        }
        
        def is_valid_sample(example):
            """æ£€æŸ¥æ ·æœ¬æ˜¯å¦æœ‰æ•ˆï¼Œå¹¶ç»Ÿè®¡é—®é¢˜ç±»å‹"""
            # æ£€æŸ¥ speech_token
            speech_token = example.get("speech_token", [])
            speech_token_len = example.get("speech_token_len", 0)
            if len(speech_token) == 0 or speech_token_len == 0:
                stats["empty_token"] += 1
                return False
                
            # æ£€æŸ¥ token å€¼æ˜¯å¦åœ¨åˆç†èŒƒå›´å†… (é€šå¸¸åº”è¯¥æ˜¯æ­£æ•´æ•°)
            if len(speech_token) > 0:
                try:
                    if min(speech_token) < 0 or max(speech_token) > 100000:  # è®¾ç½®åˆç†çš„ä¸Šä¸‹é™
                        stats["invalid_token_range"] += 1
                        return False
                except (ValueError, TypeError):
                    stats["invalid_token_range"] += 1
                    return False
            
            # æ£€æŸ¥ embedding
            embedding = example.get("embedding", [])
            if len(embedding) == 0:
                stats["empty_embedding"] += 1
                return False
                
            # æ£€æŸ¥ embedding ç»´åº¦ (CampPlus é€šå¸¸æ˜¯ 192 ç»´)
            if len(embedding) != 192:
                stats["invalid_embedding_dim"] += 1
                return False
            
            # æ£€æŸ¥ speech_feat
            speech_feat = example.get("speech_feat", [])
            speech_feat_len = example.get("speech_feat_len", 0)
            if len(speech_feat) == 0 or speech_feat_len == 0:
                stats["empty_speech_feat"] += 1
                return False
                
            # æ£€æŸ¥ speech_feat ç»´åº¦ (melç‰¹å¾é€šå¸¸æ˜¯ 80 ç»´)
            try:
                if len(speech_feat) > 0 and len(speech_feat[0]) != 80:
                    stats["empty_speech_feat"] += 1
                    return False
            except (IndexError, TypeError):
                stats["empty_speech_feat"] += 1
                return False
                
            return True
        
        # è¿‡æ»¤æœ‰æ•ˆæ ·æœ¬
        ds_clean = ds_out.filter(is_valid_sample, desc="Filtering valid samples")
        cleaned_count = len(ds_clean)
        filtered_count = original_count - cleaned_count
        
        print(f"ğŸ“Š æ•°æ®æ¸…æ´—å®Œæˆ:")
        print(f"   â€¢ åŸå§‹æ ·æœ¬æ•°: {original_count}")
        print(f"   â€¢ æœ‰æ•ˆæ ·æœ¬æ•°: {cleaned_count}")
        print(f"   â€¢ è¿‡æ»¤æ ·æœ¬æ•°: {filtered_count} ({filtered_count/original_count*100:.1f}%)")
        
        if filtered_count > 0:
            print(f"ğŸ” é—®é¢˜æ ·æœ¬ç»Ÿè®¡:")
            for problem_type, count in stats.items():
                if count > 0:
                    print(f"   â€¢ {problem_type}: {count} ä¸ª")
        
        if cleaned_count == 0:
            print("âŒ æ¸…æ´—åæ²¡æœ‰æœ‰æ•ˆæ ·æœ¬ï¼Œè¯·æ£€æŸ¥è¾“å…¥æ•°æ®å’Œå¤„ç†é€»è¾‘")
            return
    else:
        print("âš ï¸ è·³è¿‡æ•°æ®æ¸…æ´—æ­¥éª¤ï¼Œä¿ç•™æ‰€æœ‰æ ·æœ¬ï¼ˆåŒ…æ‹¬é—®é¢˜æ ·æœ¬ï¼‰")
        ds_clean = ds_out
        cleaned_count = len(ds_out)

    # æ•°æ®è´¨é‡ç»Ÿè®¡
    if cleaned_count > 0:
        print(f"ğŸ“ˆ æ•°æ®è´¨é‡ç»Ÿè®¡:")
        try:
            # éšæœºé‡‡æ ·ä¸€äº›æ ·æœ¬è¿›è¡Œç»Ÿè®¡
            sample_size = min(100, cleaned_count)
            sample_ds = ds_clean.select(range(sample_size))
            
            token_lengths = [len(ex["speech_token"]) for ex in sample_ds]
            feat_lengths = [ex["speech_feat_len"] for ex in sample_ds]
            
            print(f"   â€¢ Token é•¿åº¦: å¹³å‡ {sum(token_lengths)/len(token_lengths):.1f}, "
                  f"èŒƒå›´ [{min(token_lengths)}, {max(token_lengths)}]")
            print(f"   â€¢ Speech feat é•¿åº¦: å¹³å‡ {sum(feat_lengths)/len(feat_lengths):.1f}, "
                  f"èŒƒå›´ [{min(feat_lengths)}, {max(feat_lengths)}]")
            print(f"   â€¢ Embedding ç»´åº¦: {len(sample_ds[0]['embedding'])}")
        except Exception as e:
            print(f"   âš ï¸ ç»Ÿè®¡ä¿¡æ¯è®¡ç®—å¤±è´¥: {e}")

    try:
        print(f"ğŸ’¾ ä¿å­˜{'æ¸…æ´—åçš„' if not args.skip_cleaning else ''}æ•°æ®é›†åˆ°: {args.output}")
        ds_clean.save_to_disk(str(args.output))
        print(f"step 5/5: âœ… All Finished! processed dataset â†’ {args.output}")
        print(f"ğŸ“ˆ æœ€ç»ˆä¿å­˜ {cleaned_count} ä¸ª{'æœ‰æ•ˆ' if not args.skip_cleaning else ''}æ ·æœ¬")
    except Exception as e:
        print(f"âŒ ä¿å­˜æ•°æ®é›†å¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    main()
